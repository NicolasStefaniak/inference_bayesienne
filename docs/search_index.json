[["index.html", "Initiation à l’approche bayésienne du traitement des données ", " Initiation à l’approche bayésienne du traitement des données Nicolas Stefaniak 2025-07-03 "],["remerciements.html", "Remerciements", " Remerciements La création de ce document a été un véritable challenge à relever à la fois pour sa conception technique que pour la réflexion qu’impliquait le fait de rendre l’approche bayésienne accessible et compréhensible. Ce document n’aurait jamais pu voir le jour sans des personnes qui ont contribué, consciemment ou non,à sa conception. Je tiens tout d’abord à avoir une pensée particulière pour me femme et mon fils qui sont une infinie source de joie et de bonheur au quotidien. Partager ma vie avec vous me pousse à être chaque jour meilleur que la veille. Ce document n’aurait sans doute jamais vu le jour sans le groupe R que nous avions formé avec Philippe Regnault et Frédéric Blanchard qui m’ont fait découvrir Rmarkdown. Je ne peux décemment pas négliger Zoltan Dienes qui, par son livre, a profondément impacté ma manière de penser la recherche et a permis de m’initier à l’approche bayésienne. Ce fut donc une joie quand Olivier Klein m’a proposé de participé à la traduction de cet ouvrage et je le remercie de me l’avoir proposé. Ce document ne serait encore qu’une idée de ce que je dois faire un jour si le comité organisateurs des journées thématiques de l’ADRIPS ne m’avaient pas proposé que je fasse un atelier. Je tiens à leur présenter mes plus sincères remerciements d’avoir été l’étincelle qui a mis le feu au poudre de ce document. Merci à Daniel Priolo d’avoir généreusement mis ses données à disposition pour les exercices et d’avoir pris le temps de me briefer sur leur organisation. Enfin, je remercie toutes les personnes qui lisent ce document, qui le trouve inspirant pour changer leur approche du traitement des données et qui ont le sentiment d’avoir compris la philosphie inhérente à l’approche bayésienne. "],["introduction.html", "Chapter 1 Introduction 1.1 Êtes-vous un·e bayésien·ne dans l’âme ? 1.2 Me concernant 1.3 Prérequis souhaitables 1.4 Prérequis indispensables 1.5 Ce que nous allons faire", " Chapter 1 Introduction 1.1 Êtes-vous un·e bayésien·ne dans l’âme ? Beaucoup de personnes pourraient assister à cet atelier sans trop d’attente, juste pour voir, juste pour nourrir leur curiosité car ils ou elles sont intrigué·es par ce que cela peut bien signifier de faire des inférences bayésiennes. Mais peut-être que vous avez l’âme d’un·e bayésien·ne qui s’ignore. Pour le savoir, nous allons commencer cette séance en questionnant quelques-unes de vos connaissances et/ou de vos intuitions concernant les statitiques mais avant de commencer, j’aimerais faire un pari avec vous. Je suis convaincu de pouvoir modifier de manière radicale la manière dont vous pensez les statistiques et la manière dont vous menez vos recherches. La question qui se pose donc est de savoir si vous pensez que, dans les 3 heures qui me sont allouées, je serai en mesure de changer la manière dont vous penserez les statistiques et vos recherches à l’avenir. De mon côté, j’en suis convaincu et je suis disposé à vous donner 50 euros si ce n’est pas le cas, De votre côté, combien êtes-vous prêt à me donner si c’est le cas ? 1.2 Me concernant Après une thèse à l’université de Liège (en Belgique), je suis arrivé à Reims en 2009 avec un poste d’ATER avant d’obtenir un poste de maître de conférence en 2011 Spécialisé en neuropsychologie, j’ai été recruté pour assurer des cours de méthodologie et de statistiques. Dans le cadre de ces cours et de mon initiation à R, j’ai développé une interface graphique permettant d’utiliser R directement dans l’environnement de R, permettant de produire des scripts reproductibles facilement. Depuis plusieurs années, je m’intéresse à l’approche bayésienne dans le traitement des données que j’ai commencé à utiliser dans le cadre de mes recherches (Batselé et al., 2019; Drouillet et al., 2018; Hamaoui et al., 2022; Stefaniak et al., 2021) avant d’être impliqué dans la traduction du livre de Zoltan Dienes (2008) (understanding psychology as a science) (à paraître) et de développer des outils basés sur l’approche bayésienne à destination des neuropsychologues cliniciens (Henry et al., 2023). 1.3 Prérequis souhaitables avoir installé Rstudio être en mesure d’exécuter des lignes de commande R avoir installé les packages suivants : bayestestR pwr dplyr ggplot2 plotly devtools changeofevidence MASS tidyverse 1.4 Prérequis indispensables savoir ce qu’est une distribution normale être à l’aise avec un logiciel de traitement des données parmi R, Jamovi ou JASP connaître les notions suivantes : moyenne écart-type erreur-type coefficient de régression seuil de significativité échantillonnage Si vous utilisez R, il est attendu que vous sachiez : - importer les données - faire des manipulations basiques (filtrer, sélectionner des variables, passer d’un format large à un format long) - soyez en mesure de faire les analyses basiques en utilisant l’approche fréquentiste. 1.5 Ce que nous allons faire Expliquer ce que signifie la formule de Bayes Faire un rappel sur les probabilités et l’approche fréquentiste Apprendre à définir une ditribution a priori Comprendre la vraisemblance et son calcul Expliquer ce qu’est la distribution a posteriori et l’intervalle de crédibilité Présenter le facteur de Bayes Comparer l’approche fréquentiste avec l’approche bayésienne Faire des mises en application Conclure. References Batselé, E., Stefaniak, N., &amp; Fantini-Hauwel, C. (2019). Resting heart rate variability moderates the relationship between trait emotional competencies and depression. Personality and Individual Differences, 138, 69–74. https://doi.org/10.1016/j.paid.2018.09.020 Dienes, Z. (2008). Understanding psychology as a science: An introduction to scientific and statistical inference (1st ed., p. 184). Bloomsbury Academic / Red Globe Press. Drouillet, L., Stefaniak, N., Declercq, C., &amp; Obert, A. (2018). Role of implicit learning abilities in metaphor understanding. Consciousness and Cognition, 61, 13–23. https://doi.org/10.1016/j.concog.2018.03.015 Hamaoui, J., Stefaniak, N., &amp; Segond, H. (2022). The influence of vestibular system and fetal presentation on handedness, cognitive and motor development: A comparison between cephalic and breech presentation. Developmental Science, 26(3). https://doi.org/10.1111/desc.13317 Henry, A., Stefaniak, N., Schmid, F., Kwiatkowski, A., Hautecoeur, P., &amp; Lenne, B. (2023). Assessing cognitive changes in multiple sclerosis: Criteria for a reliable decision. Journal of Clinical and Experimental Neuropsychology, 45(4), 321–344. https://doi.org/10.1080/13803395.2023.2232122 Stefaniak, N., Baltazart, V., &amp; Declercq, C. (2021). Processing verb meanings and the declarative/procedural model: A developmental study. Frontiers in Psychology, 12. https://doi.org/10.3389/fpsyg.2021.714523 "],["le-théorème-de-bayes.html", "Chapter 2 Le théorème de Bayes", " Chapter 2 Le théorème de Bayes “Le statisticien ne peut pas se soustraire à l’obligation d’être au clair quant aux principes de l’inférence scientifique, mais de même, aucune autre personne censée ne peut se soustraire à une telle obligation.” — Sir Ronald Fisher Le théorème de Bayes a été imaginé par Thomas Bayes [1702 - 1761], un prêtre non conformiste qui était également membre de la Royal Society. Cependant, il n’a été publié que deux ans après sa mort, grâce à Richard Price à qui Bayes avait laissé ses manuscrits inachevés. Il sembla à Price que ces manuscrits étaient d’une telle importance qu’il prit l’initiative d’envoyer le manuscrit à la Royal Society en 1763 (Bayes &amp; Price, 1763). Ce théorème, qui a été redecouvert de manière indépendante par Laplace (LaPlace, 1814), permettait de savoir comment les données modifiait la probabilité d’une hypothèse. En langage mathématique, le théorème de Bayes se définit par l’équation (2.1) : \\[\\begin{equation} P\\left(H|D\\right) =\\frac{P\\left(D|H\\right) \\times P\\left(D\\right)}{P\\left(H\\right)} \\tag{2.1} \\end{equation}\\] Cette équation signifie que la probabilité d’une hypothèse étant donné les données, P(H|D), est proportionnelle à la probabilité des données étant donné une hypothèse, P(D|H), multiplié par la probabilité de l’hypothèse, le tout divisé par la probabilité des données, P(H). La probabilité d’une hypothèse étant donné les données est ce qu’on appelle la probabilité a posteriori. La probabilité de l’hypothèse est ce qu’on appelle la probabilité a priori et la probabilité des données étant donné l’hypothèse est la vraisemblance. Il n’est pas nécessaire de s’attarder sur la probabilité des données car ce facteur va se simplifier lorsqu’on voudra appliquer le théorème de Bayes à l’inférence statistique. Sans en identifier encore tous les tenants et aboutissants, on peut intuitivement comprendre plusieurs points importants. Les différents points seront présentés du plus facile au plus difficile à comprendre : La probabilité d’un événement change quand on accumule des informations ; Quelques notions élémentaires des probabilités sont indispensables à la compréhension de ce théorème pour pouvoir l’appliquer. On doit connaître la probabilité de l’hypothèse avant d’avoir reccueilli les données pour arriver à appliquer le théorème. Il faut comprendre ce que signifie la vraisemblance. Le théorème de Bayes informe sur la probabilité d’une hypothèse. Dans cette section, nous allons commencer par aborder ces 4 points avant d’entrer un peu plus dans les détails de l’inférence bayésienne. References Bayes, T., &amp; Price, R. (1763). An essay towards solving a problem in the doctrine of chances. Philosophical Transactions of the Royal Society of London, 53, 370–418. https://doi.org/10.1098/rstl.1763.0053 LaPlace, P. S. (1814). Essai philosophique sur les probabilités. Courcier. http://eudml.org/doc/203193 "],["accumuler-les-informations..html", "Chapter 3 Accumuler les informations.", " Chapter 3 Accumuler les informations. On peut comprendre assez intuitivement que les probabilités changent quand on accumule des informations au travers d’un exemple simple : vous partez en vacance et pour vos vacances, vous avez loué une superbe villa avec piscine dans un endroit paradisiaque (qui se trouve évidemment en France puisque vous êtes éco-responsable). Vous arrivez vers 19.30 dans le logement et après avoir fait le tour du propriétaire, vous ouvrez le frigo. Á l’intérieur, une boite hermétique avec de la nourriture dedans. Vous avez lu dans les commentaires de la location que, pour le confort des invités, les propriétaires amenaient le premier repas faits de produits frais et locaux aux vacanciers vu qu’ils n’avaient pas encore eu le temps de faire les courses. Vous vous demandez s’il s’agit du repas que les propriétaires offrent aux locataires ou s’il s’agit d’un repas oublié par les locataires précédents qui n’aurait pas été enlevé du frigidaire par mégarde. Le reste du frigo est parfaitement propre. Au travers de cet exemple, on se rend compte que votre opinion a évolué en fonction des informations qui se sont accumulées. Ainsi, la probabilité d’un évenement dépend des informations que nous avons de cet événement. "],["les-axiomes-des-probabilités.html", "Chapter 4 Les axiomes des probabilités", " Chapter 4 Les axiomes des probabilités Les statistiques, et les méthodes d’inférences sont intimement liées aux probabilités et aux théories sous-jacentes à celles-ci. Dans cette section, on va commencer par présenter quelques axiomes des probabilités, en particulier ceux dont nous aurons besoin pour comprendre l’inférence bayésienne, on évoquera dans le chapitre suivant ce que signifie (ou non) les probabilités dans l’inférence de Neyman-Person (1933), et on terminera les chapitres sur les probabilités en se questionnant la nature objective ou subjective des probabilités. Dans ce chapitre, il ne s’agit pas de faire une présentation avancée de ce que sont les probabilités mais de rappeler les contraintes des axiomes probabilistes qui vont contraindre l’application de Bayes. Pour le formuler autrement, l’application du théorème de Bayes doit respecter les axiomes des probabilités pour que son application ait du sens. Cela ne semble pas déraisonnable comme contrainte. Ainsi, il est bon de se rappeler que : La valeur d’une probabilité est toujours située entre 0 et 1 La probabilité que l’événement A ou B survienne, en admettant que A et B ne peuvent pas survenir en même temps, est égal à la somme de leur probabilité respective, P(A)+P(B). Par exemple, on ne peut pas avoir pile et face en même temps et la probabilité d’avoir pile ou face est bien égale à 1 si on attribue une probabilité de 0,5 à chacun des deux événements. P(A \\(\\cap\\) B) = P(A) × P(B|A). P(A \\(\\cap\\) B) est la probabilité que A et B surviennent en même temps tandis que P(B|A) est la probabilité de B lorsqu’on connait A, c’est-à-dire la probabilité de B si A est vrai. Prenons le cas d’un d’un jeu de cartes de 52 cartes et nous voulons déterminer la probabilité d’obtenir l’as de coeur. Une solution simple est de considérer qu’il y a un seul as de coeur sur les 52 cartes, ce qui signifie que cette probabilité vaut 1/52. Une version alternative est de considérer que, dans un jeu de cartes, il y a 4 as sur 52, ce qui signifie que la probabilité d’obtenir un as est de 1/13, que la probabilité d’avoir une carte rouge est de 1/2 et que, parmi les cartes rouges, il y a 1 chance sur 2 que ce soit du coeur. (#fig:Fig2.1)Représentation visuelle des probabilités conjointes. Aini, en décomposant le calcul, on obtient : \\[ \\frac{1}{13} \\times \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{52} \\approx 0.019\\] Cette illustration, très simple, montre que le raisonnement qu’on peut appliquer pour P(A \\(\\cap\\) B) est également valable pour des plus complexes ou on aurait par exemple P(A \\(\\cap\\) B \\(\\cap\\) C \\(\\cap\\) D). Ces quelques notions suffiront pour pouvoir comprendre comment on applique le théorème de Bayes dans le cadre des inférences statistiques. Tout References Neyman, J., &amp; Pearson, E. S. (1933). Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231(694–706), 289–337. https://doi.org/10.1098/rsta.1933.0009 "],["quelques-rappels-sur-lapproche-de-neyman-pearson.html", "Chapter 5 Quelques rappels sur l’approche de Neyman-Pearson 5.1 Que signifie la valeur p ? 5.2 Quand un effet négligeable est significatif 5.3 Quand la règle d’arrêt vient tout changer", " Chapter 5 Quelques rappels sur l’approche de Neyman-Pearson Si vous avez ce support entre les mains (ou sur votre écran), c’est que vous souhaitez sans doute pouvoir appliquer l’approche bayésienne au traitement de vos données et vous êtes certainement impatient·e de comprendre comment on peut concrètement appliquer la formule (2.1) pour traiter des données. Il est également possible que vous ayez pratiqué l’approche de Neyman-Person (1933) (aussi connus sous les noms d’approche fréquentiste ou tests d’hypothèse nulle) et que vous ne soyez pa totalement satisfait·e de cett manière de traiter les données. Dans tous les cas, puisque l’approche de Neyman-Person (1933) est l’approche dominante, il est indispensable de connaitre les tenants et les aboutissants de cette approche. Ainsi, pour pouvoir mettre plus aisément en évidence les différences épistémologiques entre les deux approches, nous vous invitons à répondre au questionnaire ci-dessous qui permettra à la fois de savoir si vous avez une bonne compréhension de l’approche de Neyman-Person (1933) mais aussi si vous êtes bayésien dans l’âme. Quand nou réalisons une analyse fréquentiste, appelée aussi approche ou tests d’hypothèse nulle, nous savons si nous pouvons ou non exclure le 0 parmi l’ensemble des différences qui existent ainsi que le taux d’erreur de Type I qu’on va observer à long terme. 5.1 Que signifie la valeur p ? La logique sous-jacente à l’approche de Neyman-Person (1933) est de pouvoir contrôler un niveau d’erreur à long terme. Cela signifie qu’un événement particulier n’a pas de probabilité qui lui est associée. Prenons un exemple simple : vous avez un dé et vous voulez savoir s’il est pipé ou non. Vous lancez le dé une seule fois, vous obtenez 5. Pouvez-vous dire s’il est pipé ? Bein sûr que non. Vous le lancez 3 fois, vous obtenez 5, 4,5, êtes-vous plus informé·e ? Pas vraiment. Pour savoir s’il est pipé, il faudrait lancer le dé un grand nombre de fois, disons 6000 fois, et vérifier si on obtient un peu près 1000 fois la face 1, 1000 fois la face 2 … Lorsque vous mené une expérimentation, vous avez lancé le dé une fois, ce qui signifie que la probabilité renvoyée par les logiciels de statistiques n’apporte pas d’autre information qu’indiquer si un effet est significatif ou non. Si Fisher (1955) avait une conception des probabilités qui suggérait que la probabilité obtenue était informative1, il y a consensus à l’heure actuelle pour considérer que la conception de Fisher était erronée. Pour beaucoup de chercheurs et de chercheuses, cette affirmation va tellement à l’encontre de ce qui est profondément ancré dans la manière dont ils et elles font des statitiques, que cela peut entre être déboussolant. Si des doutes persistent, il peut être utile de pouvoir bénéficier d’une petite démonstration. Reprenons l’exemple du questionnaire, vous menez une expérimentation dans laquelle vous comparez deux conditions. L’analyse statistique qu’on va mener pour comparer ces deux conditions est un t de Student (Student, 1908) pour échantillon indépendants. Pour simuler les données, on peut utiliser la fonction rnorm qui simule des données ayant une ditribution normale. Par exemple, si on veut simuler un échantillon de 20 personnes ayant une moyenne de 100 et un écart-type de 15, on peut faire : echantillon&lt;-rnorm(n = 20, # nombre de personnes mean = 100, # la moyenne sd = 15 ) # l&#39;écart-type echantillon ## [1] 90.66872 95.77036 111.79263 131.89775 109.34698 88.62617 111.44237 ## [8] 93.06225 79.21628 96.79964 91.62468 107.44620 130.48756 109.68773 ## [15] 80.29742 108.39075 107.24018 104.10306 113.24073 110.44404 Evidemment la moyenne n’aura pas exactement la valeur de 100, ni l’écart-type une valeur de 15. Ces valeurs pourront être plus ou moins éloignées en fonction des aléas de l’échantillonnage. Pour notre échantillon, nous obtenons : mean(echantillon) ## [1] 103.5793 sd(echantillon) ## [1] 14.15041 Grâce à cette fonction, nous allons pouvoir simuler un grand nombre de t de student grâce à al fonction t.test et obtenir les probabilités associées à ces analyses. Le code ci-dessous va illustrer cette opération lorsqu’on ne fait qu’un seul t de Student où les deux échantillons ont la même moyenne. # on fait une comparaison de deux populations dont les moyennes sont strictement égales t.out&lt;-t.test(rnorm(n = 20, # taille de l&#39;échantillon 1 mean = 0, # moyenne du groupe 1 sd = 1), # écart-type de l&#39;échantillon 1 rnorm(n = 20, # taille de l&#39;échantillon 2 mean = 0,# moyenne du groupe 2 sd = 1) ) # écart-type de l&#39;échantillon 2 t.out ## ## Welch Two Sample t-test ## ## data: rnorm(n = 20, mean = 0, sd = 1) and rnorm(n = 20, mean = 0, sd = 1) ## t = -0.063289, df = 37.045, p-value = 0.9499 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.6197579 0.5822122 ## sample estimates: ## mean of x mean of y ## 0.2547591 0.2735319 Nous allons faire cela à présent un grand nombre de fois (à savoir 200 000) avec deux types de situations : une situation où on compare deux échantillons issus de la même population (condition absence de différence) et une situation où on compare deux échantillons issus de deux populations dont la différence est de 0.2 écarts-types (condition différence). Le code pour reproduire cette simulation est présenté ci-dessous. Cette simulation représente 200 000 études qui sont réalisées, dont l’hypothèse est fondée pour la moitié d’entre elles et non fondée pour l’autre moitié. set.seed(1234) # le fait de mettre une graine assure une reproductibilité des résultats # on va créer une fonction qui compare deux moyennes qui sont strictement égales lorsque la condition vaut 0 et # dont les moyennes se différencient de 0,2 écart-type (d = 0.2) quand la condition vaut 1 # La fonction renvoie la probabilité du test t F1&lt;-function(cond = 0){ if(cond==0){ # on fait une comparaison de deux populations dont les moyennes sont strictement égales t.out&lt;-t.test(rnorm(n = 20, # taille de l&#39;échantillon 1 mean = 0, # moyenne du groupe 1 sd = 1), # écart-type de l&#39;échantillon 1 rnorm(n = 20, # taille de l&#39;échantillon 2 mean = 0,# moyenne du groupe 2 sd = 1) )# écart-type de l&#39;échantillon 2 }else{ t.out&lt;-t.test(rnorm(n = 20, # taille de l&#39;échantillon 1 mean = 0, # moyenne du groupe 1 sd = 1), # écart-type de l&#39;échantillon 1 rnorm(n = 20, # taille de l&#39;échantillon 2 mean = 0.2,# moyenne du groupe 2 sd = 1) ) # écart-type de l&#39;échantillon 2 } return(c(t.out$p.value)) # renvoie la probabilité du test t } # on crée des données (200 000) oour créer de manière aléatoire nos conditions. Elles sont au nombre de 200 000 # ici l&#39;échantillonnage se fait de manière équiprobable avec approximativement autant de situations pour la # condition différence qu&#39;absence de différence df&lt;-data.frame(condition = sample(0:1, 200000, replace=T )) # on applique la fonction F pour chacune des lignes du jeu de données (variable condition) df$p.value&lt;-apply(df, 1, F1) Nous sommes à présent en mesure de nous mettre dans la peau du chercheur ou de la chercheuse qui est face à ses données. La première chose que nous allons décider est notre seuil \\(\\alpha\\), le seuil de décision statistique. Nous allons adopter une position simple et prendre comme seuil de décision 5%. Ce seuil est le pourcentage de faux positif que vous êtes prêt·e à tolérer à long terme, c’est-à-dire si vous deviez refaire un grand nombre de fois la même expérience où vous devriez tolérer l’hypothèse nulle. Deux questions se posent ici : 1) est-ce que le nombre de situations où la probabilité est inférieure seuil \\(\\alpha\\) correspond effectivement à 5% ; 2) quel est le pourcentage de situations où j’ai rejeté l’hypothèse nulle dans la condition **différence*. Par commodité, nous allons répondre aux deux questions en même temps. library(dplyr) df$sign&lt;-if_else(df$p.value&lt;.05, &quot;oui&quot;, &quot;non&quot;) # créer une colonne qui indique si c&#39;est significatif ou non T1&lt;-table(df$condition, df$sign) # on fai une table T1 ## ## non oui ## 0 94686 5004 ## 1 90975 9335 round(prop.table(T1, 1),4)*100 # on obtient les proportions par ligne ## ## non oui ## 0 94.98 5.02 ## 1 90.69 9.31 Le premier constat est que, quand on répète la même expérimentation un grand nombre de fois, nous obtenons effectivement 5% de rejet de l’hypothèse nulle alors qu’elle devrait être tolérée. Concernant les situations où nous devrions rejeter l’hypothèse nulle car la différence est réelle, nous observons que l’effet est significatif dans 9% des situations. Cette valeur correspond à la puissance statistique, qu’on peut vérifier aisément avec le package pwr (Champely, 2020) qui contient la fonction power.t.test. Cette fonction nous indique que la puissance est effectivement de 9% library(pwr) pwr.t.test(n = 20,# la taille de l&#39;échantillon dans chacun des groupes d =0.2, # la taille d&#39;effet type=&quot;two.sample&quot;) # le type de test de Student ## ## Two-sample t test power calculation ## ## n = 20 ## d = 0.2 ## sig.level = 0.05 ## power = 0.09456733 ## alternative = two.sided ## ## NOTE: n is number in *each* group Le résultats de la simulation correspondent assez bien à ce que nous étions censés obtenir de manière théorique. Encart 1. Á propos des paramètres de la simulation. Il faut comprendre que nous aurions pu mener notre simulation avec d’autres paramètres. Nous aurions pu augmenter la puissance statistique de la situation de différence en augmentant la taille d’échantillon dans chacun de nos échantillons, mais nous aurions pu également changer le rapport entre les situations où nous devrions observer une différence par rapport à celles où ce n’est pas le cas. Si la puissance est particulièrement faible dans cette simulation, jusqu’à ces dernières années, ce n’était pas si rare d’observer des études avec une vingtaine de participants par groupe (voire moins, (Szucs &amp; Ioannidis, 2017)) et une taille d’effet de 0,2 représente environ 36% des tailles d’effet en psychologie et neurosciences (Szucs &amp; Ioannidis, 2017). Un autre paramètre qu’il est possible de modifier est la proportion d’hypothèses testées qui ont du sens par rapport à celles qui en ont moins. Dans notre exemple, nous avons autant d’expérimentation dans la condition présence d’une différence que dans la condition absence de différence. Cependant, cette vision est favorable au raisonnement selon lequel, si la valeur p est égale à 0.0001, on a plus de chances que la différence soit réelle. Néanmoins, Ioannidis (2005) avancent que la plupart des hypothèses testées ne devraient pas l’être car elles manquent de fondements justifiant de tester l’hypothèse. Il donne comme exmeple une étude qui ferait une analyse sur les 100 000 polymorphismes génomiques afin d’identifier ceux susceptibles d’être associés à un risque de schizophrénie, si seuls une dizaine d’entre eux sont associés à la schizophrénie, alors on comprend que, sur les 100 000 analyses réalisées, le risque d’avoir des effets significatifs est beaucoup plus élevé pour les polymorphismes qui ne sont pas associés à la schizophrénie que pour ceux qui le sont (n’oubliez pas qu’il y a aussi un risque de faux négatifs). Vous pouvez faire des simulations différentes en changeant la répartition entre les conditions différences par rapport à absence de différence. Par exemple, si on imagine que pour une bonne idée, deux idées ne sont pas satisfaisantes, alors vous pourriez utiliser la ligne de commande suivante : df&lt;-data.frame(condition = sample(0:1, 200000, replace=T, prob=c(2/3, 1/3) )) Le problème est que le chercheur ou la chercheuse n’a pas accès à l’ensemble des échantillons possibles des populations. Il ou elle mène une expérimentation et doit prendre une décision sur la base d’une seule et unique expérimentation. Imaginons que l’expérimentation qui a été menée, c’est l’expérimentation 15454, voici les résultats de cette étude particulière (en arrondissant à la \\(4^{ème}\\) décimale) : df$p.rond&lt;-round(df$p.value, 4) df$p.rond[15454] ## [1] 0.0001 La probabilité est de 0.0001, l’effet est significatif. Si vous aviez eu une probabilité de 0.03, est-ce que vous auriez dit autre chose ? Non, dans les deux cas, c’est significatif. Vous avez fixé le seuil à 5% avant de mener votre expérimentation, vous ne pouvez pas le changer une fois que vous obtenez vos résultats. Dans notre simulation, nous avons 21 situations où la probabilité vaut exactement 0.03 (quand elle est arrondie à la \\(4^{ème}\\) décimale) pour la condition différence et il y en a 5 pour la condition non différence. Il y en a donc 4,2 fois plus. dim(df[which(df$condition==1 &amp; df$p.rond==.030),]) ## [1] 21 4 .cl-60f4cd14{}.cl-60ebadd8{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-60ef4100{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-60ef410a{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-60ef5c8a{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-60ef5c8b{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-60ef5c94{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-60ef5c95{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-60ef5c96{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-60ef5c9e{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 5.1: Expérimentations pour lesquelles la probabilité vaut exactement 0.03 dans la condition différence. conditionp.valuesignp.rond10.03003133oui0.0310.03003270oui0.0310.03003281oui0.0310.02995552oui0.0310.03001438oui0.0310.02997408oui0.0310.02999383oui0.0310.03002244oui0.0310.02997382oui0.0310.02998753oui0.0310.02996546oui0.0310.03001263oui0.0310.02997350oui0.0310.03002785oui0.0310.03000106oui0.0310.02996308oui0.0310.02995004oui0.0310.02996229oui0.0310.03002986oui0.0310.03004315oui0.0310.02997314oui0.03 .cl-0cd5f4ea{}.cl-0cc578a4{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-0ccba1fc{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0ccba210{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-0ccbcdee{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0ccbce02{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0ccbce03{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0ccbce0c{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0ccbce0d{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-0ccbce16{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 5.2: Expérimentations pour lesquelles la probabilité vaut exactement 0.03 dans la condition absence de différence. conditionp.valuesignp.rond00.03003216oui0.0300.03002575oui0.0300.02998427oui0.0300.02997384oui0.0300.02998068oui0.03 Intuitivement, vous vous dites que vous avez donc 4,2 fois plus de chances que cette expérimentation soit issue de la condition différence. Qu’en est-il à présent pour les situations où la probabilité arrondie vaut exactement 0.0001. Cela représente 40 situations. .cl-c0ba02c2{}.cl-c0afc302{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-c0b2ee60{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-c0b2ee74{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-c0b315b6{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c0b315c0{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c0b315c1{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c0b315ca{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c0b315cb{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c0b315cc{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 5.3: Expérimentations pour lesquelles la probabilité vaut exactement 0.0001 dans la condition différence. conditionp.valuesignp.rond10.00014968727oui0.000110.00005884055oui0.000100.00006646775oui0.000110.00011611656oui0.000100.00006901200oui0.000110.00006868364oui0.000110.00012318743oui0.000110.00010176068oui0.000110.00010612005oui0.000110.00006607349oui0.000110.00005853225oui0.000110.00006131283oui0.000110.00006595854oui0.000110.00005909742oui0.000110.00005850616oui0.000110.00013808667oui0.000100.00006449358oui0.000110.00010922188oui0.000100.00006024203oui0.000110.00009713865oui0.000100.00014927947oui0.000100.00008221906oui0.000110.00014962026oui0.000110.00007810776oui0.000110.00011908708oui0.000110.00008400170oui0.000110.00009411372oui0.000100.00012101431oui0.000100.00009521599oui0.000110.00006910508oui0.000110.00012642834oui0.000110.00007243453oui0.000110.00013643819oui0.000110.00006174456oui0.000110.00012684684oui0.000110.00008282673oui0.000110.00012626133oui0.000110.00007654101oui0.000100.00005962663oui0.000100.00009698696oui0.0001 Parmi ces 40 situations, il y en a 10 qui proviennent de la condition absence de différence et 30 de la condition différence. table(df2$condition) ## ## 0 1 ## 10 30 Par rapport à la situation où on s’intéressait à une probabilité de 0,03, le rapport entre les deux conditions a diminué : vous n’avez à présent plus que 3 fois plus de chances que votre effet soit issu de la condition différence par rapport à la condition pas de différence. On se rend compte ici que le raisonnement qui suppose que l’effet est plus significatif parce que la probabilité est plus faible ne tient pas. Néanmoins, nous allons continuer le raisonnement. Précédemment, nous avons établi que les résultats de votre expérimentation étaient ceux de l’expérimentation 15454. La question qui se pose est de savoir à quelle condition est-ce que cela appartient ? Maintenant, que vous savez qu’il y a 10 expérimentations sur les 40 qui ont une probabilité égale à 0.0001 qui sont issues de la condition **absence de différence*, vous ne pouvez pas dire avec certitude la condition à laquelle elle appartient. Vous pourriez utiliser la stratégie de dire systématiquement “cela provient de la condition différence” parce que vous savez que sur le long terme, toutes choses étant égales par ailleurs, la condition différence sera plus souvent représentée. Vous auriez en partie raison sur ce point : sur le long terme, votre raisonnement tient mais ce n’est pas le cas pour une analyse isolée. Pour les résultats de votre expérimentation, il s’agit de la condition absence de différence. Néanmoins, dans ce cas, votre seuil de décision ne serait plus de 5% mais de 0,01% et il faudrait avoir décider de cette règle avant d’avoir recueillié (ou du moins analysé) les données. df[15454,] ## condition p.value sign p.rond ## 15454 0 0.00006646775 oui 0.0001 Il faut comprendre que, quand on prend un seuil à 5%, cela signifie qu’il va y avoir 5% des expérimentations pour lesquelles la probabilité se situation entre 0.00000000000000001 et 0.049999999999999999. On peut observer ce constat sur la Figure 5.1 qui est un échantillon de 1000 probabilités parmi les 200 000 probabilités qu’on a calculées précédemment. On observe que, sur environ 500 échantillons de la conditon absence de différence, il y a environ 25 valeurs en dessous de 0.05, réparties entre 0.000001 et 0.04999999999. Remarquez aussi que, peu importe la condition, les probabilités se répartissent sur toute la hauteur, tant quand on doit tolérer l’hypothèse nulle que lorsqu’on doit la rejeter. Si une des probabilités changeait de condition pour savoir si vous être capable d’identifier la probabilité intrue, vous ne pourriez pas le faire. Figure 5.1: Représentation de la distribution des probabilités en fonction de la condition Encart 2. Sur la reproductibilité des résultats. Vous pourriez évoquer dans ce cas le fait qu’on peut s’assurer des résultats en les répliquant puisque la reproductibilité des résultats est une propriété désirable de la science (Amir &amp; Sharon, 1990). On est ici confronter à trois problèmes : Il existe un problème de reproductibilité en psychologie (Bohannon, 2015; Open Science Collaboration, 2015), comme dans de nombreuses science, et cette crise ne semble pas beaucoup progresser (Hengartner, 2021; Klein et al., 2021). Si les résultats ne sont pas reproduits, est-ce que le problème vient de l’étude initiale ou de la réplication (Maxwell et al., 2015)? il est très difficile de publier une reproduction d’études (Clarke et al., 2024). Alors comment pouvez-vous savoir si, avec une valeur p pour une étude spécifique, vous avez eu une idée formidable ou une idée qui ne sera pas reproductible ? Vous ne pouvez pas réellement. Vous pouvez juste savoir quel sera votre taux d’erreur à long terme en connaissant les seuils de décisions et la puissance des études. Une fois qu’on a compris que, peu importe la probabilité renvoyée par le logiciel, la probabilité de rejeter à tort l’hypothèse nulle dépend du seuil de décision que nous avions initialement choisi, nous amène à comprendre qu’on ne peut pas dire qu’on a une chance sur 10 000 de se tromper en disant que l’effet est significatif alors qu’il ne l’est pas. Il est de 5%. Néanmoins, même cette vision reste erronée car on dit que l’effet est significatif dès lors que la probabilité renvoyée par le logiciel est inférieure à 0,05. Dans notre simulation, il y a 5004 fois où l’effet est significatif alors qu’il ne devrait pas l’être et 9335 fois où il est significatif et il doit l’être. Ce qui signifie que le taux d’erreur de première espèce est de : \\[100 \\times\\frac{5004}{5004+9335} = 34,90 \\%\\] Bref, même si on souhaiterait qu’elle nous apporte des informations sur la pertinence de notre hypothsèe, la probabilité dans l’approche fréquentiste ne fournit pas d’autre information que le fait de savoir si l’effet est significatif ou non au seuil de décision que nous avons fixé et que nous considérons être un seuil satisfaisant pour rejeter, à long terme, de manière erronée l’hypothèse nulle alors qu’on devrait la tolérer. 5.2 Quand un effet négligeable est significatif Un aspect qui est souvent oublié dans l’approche fréquentiste est que, si vous rejeter l’hypothèse nulle, vous n’avez rejeté qu’une seule valeur : le zéro. Cependant, il semble peu vraisemblable qu’il y ait une quelconque situation ou la différence entre deux populations soit exactement égale à zéro et si elle n’est pas exactement égale à 0, peu importe à quel point la différence est petite, il sera possible d’avoir un effet significatif dès lors que votre échantillon est suffisamment grand. Pour l’illustrer, nous allons commencer par analyser la formule du t de Student comparaison à une norme et nous ferons ensuite une petite simulation qui vous donnera le taux d’effet significatif pour en fonction de la taille de l’échantillon. \\[\\begin{equation} t =\\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}} \\tag{5.1} \\end{equation}\\] où \\(\\bar{x}\\) est la moyenne de l’échantillon, \\(\\mu\\) est la moyenne de la population, s est l’écart-type, et n est la taille de l’échantillon. Imaginons que nous tirions à chaque fois des échantillons qui soit parfaitement représentatif de la différence entre la moyenne d’un échantillon et celle de la population, et que l’écart-type soit également estimé avec exactitude. On se rend compte que plus l’échantillon augmenter, plus le dénominateur (à savoir \\(\\frac{s}{\\sqrt{n}}\\) diminue, ce qui amène au final à ce que la valeur du t augmente. Si \\(\\sqrt{n}&gt;s\\), alors la valeur est inférieure à 1 est diviser par un nombre par une valeur inférieure à 1 résulte en une valeur plus grande. Par exemple, \\(\\frac{1}{0.5}=2\\). Or, plus la valeur de la statistique est grande, plus la probabilité qui est associée à sa valeur est faible, ce qui amène donc au rejet de l’hypothèse nulle. Si vous n’êtes pas encore totalement convaincu·e, imaginons que nous testions le QI dans deux populations pour savoir laquelle est la plus intelligente et que la moyenne de la première population soit de 100 avec un écart-type de 15 et que la moyenne de la seconde population soit de 100.1, avec un écart-type de 15. D’un point de vue psychologique, si il est raisonnable de considérer que cette différence est tellement ridicule qu’on peut la négliger. Nous allons tester ce cas de figure en faisant varier la taille de l’échantillon et nous allons comptabiliser, pour chaque taille d’échantillon, le nombre de fois que l’effet sera significatif. Figure 5.2: Proportion d’effets significatifs sur 1000 essais pour différentes tailles d’échantillons La Figure 5.2 illustre que, bien que la différence soit minimale, la proportion d’effet significatif est proche de 100% dès lors que la taille de l’échantillon est suffisamment grande. Vous pourriez vous dire que la taille d’échantillon doit vraiment être considérable pour avoir quasiment à coup sûr un effet significatif mais que, dans des situations réelles, on n’observe pas des échantillons aussi grands. Pourtant, il n’est pas rare de tester quelques centaines de personnes pour valider une échelle. Ainsi, on peut observer que, dans une étude où 526 personnes ont pris part à l’étude, on peut être embêté pour interprété les résultats d’une analyse censée montrer une validité divergente2 et qu’on obtient une corrélation 0.08 qui est ignificative, comme c’est le cas dans l’étude de Dalagi (2024). L’interprétation qu’en donne les auteures : il y a une corrélation mais elle est très modérée. Nous verrons comment, dans une telle situation, une approche baésienne peut apporter un éclairage différent. Cet exemple illustre ce que nous évoquions précédemment : dans un contexte de recherche, penser qu’une variable indépendante n’a absolument aucun effet sur une variable dépendante ou qu’une corrélation entre deux variables vaut exactement 0 ne fait en effet généralement pas sens. Même lorsque la théorie est fausse, il y a forcément d’autres raisons pour lesquelles il existe une relation, ne fût-ce que minime, entre les variables (Dienes, 2008). 5.3 Quand la règle d’arrêt vient tout changer Vous avez sans doute déjà entendu parlé de p hacking ou de triturage des données, cette pratique consistant à réanalyser les données de différentes manière jusqu’à l’obtention d’un effet significatif. Cette pratique fait partie de ce qu’on appelle les pratique de recherche questionnables (par ex., Neoh et al., 2023). Cependant, dans le questionnaire que vous avez réalisé précédemment, la situation ne semblait pas révéler une intention de triturer les données pour obtenir des résultats mais simplement de faire la partie statistique d’une mémoire une année 1. Ce que l’énoncé ne dit pas, c’est qu’aurait fait notre scientifique si l’effet avait été significatif avec 35 participants. La tentation est grande de s’arrêter là : finalement pourquoi dépenser encore beaucoup d’énergie et de temps pour continuer la recueil alors que l’effet est présent et qu’on sait que, plus la taille de l’échantillon est grande, plus l’effet risque d’apparaître. Ce comportement, bien qu’il ne soit pas associée à une intention de frauder, corrspond tout à fait du p-hacking. Voyons comment le taux d’effet significatif va évoluer si on compare deux conditions avec une taille d’échantillon de 35, on s’arrête si c’est significatif, ou on ajoute 15 personnes si cela ne l’est pas. On observe ici que le taux de rejet à tort de l’hypothèse nulle n’est plus de 5% mais 9.7%. Cette valeur correspond au taux d’erreur qu’on devrait obtenir de manière théorique quand on augmente le nombre d’analyses qu’on réalise. On l’obtient grâce à l’équation (5.2) : \\[\\begin{equation} \\alpha_{famille} =1- (1-\\alpha)^n \\tag{5.2} \\end{equation}\\] où _{famille} est le taux \\(\\alpha\\) pour une famille de tests , \\(\\alpha\\) est le seuil de décision et n est le nombre d’analyses qui ont été réalisées. Dans notre exemple, deux analyses ont été réalisées, ce qui nous amène à : \\[1 - (1 - 0.05)^2= 0.0975\\] Lorsqu’on se retrouve dans cette situation, on doit corriger la probabilité pour maintenir les erreurs à rejeter à tort H0 à 5%. Cette exemple illustre une phénomène central de l’approche de Neyman-Pearson (Neyman &amp; Pearson, 1933) à savoir qu’elle est sensible aux règles d’arrêt. C’est pour cette raison que le calcul de la puissance est aussi importante (voir par ex., Cohen, 1988) et qu’on vous apprend à le faire. C’est aussi pour cette raison qu’on vous incite à pré-enregistrer vos recherches afin qu’on puisse s’assurer que la taille d’échantillon correspond à ce qui avait été annoncé (Lakens, 2019; Nosek et al., 2018; Wagenmakers et al., 2012). References Amir, Y., &amp; Sharon, I. (1990). Replication research: A \"must\" for the scientific advancement of psychology. Journal of Social Behavior &amp; Personality, 5(4), 51–69. Bohannon, J. (2015). Many psychology papers fail replication test. Science, 349(6251), 910–911. https://doi.org/10.1126/science.349.6251.910 Champely, S. (2020). Pwr: Basic functions for power analysis. https://CRAN.R-project.org/package=pwr Clarke, B., Schiavone, S., Vazire, S., Bavel, J. J. V., &amp; Chambers, C. D. (2024). The prevalence of direct replication articles in top-ranking psychology journals (2010–2021). Royal Society Open Science, 11(1), 231506. https://doi.org/10.1098/rsos.231506 Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Lawrence Erlbaum Associates. Dallagi-Belkilani, M., Olivier, M., &amp; Besche-Richard, C. (2024). Validation of the basic empathy scale in an arabic-speaking population: The BES-ar. L’Encéphale, 50(2), 149–153. https://doi.org/10.1016/j.encep.2023.04.002 Dienes, Z. (2008). Understanding psychology as a science: An introduction to scientific and statistical inference (1st ed., p. 184). Bloomsbury Academic / Red Globe Press. Fisher, R. A. (1955). Statistical methods and scientific induction. Journal of the Royal Statistical Society. Series B (Methodological), 17(1), 69–78. https://doi.org/10.2307/2983785 Hengartner, M. P. (2021). Targeting the replication crisis and improving the credibility of research findings in clinical psychology. A commentary on pittelkow et al. Clinical Psychology: Science and Practice, 28(2), 226–228. https://doi.org/10.1037/cps0000028 Ioannidis, J. P. A. (2005). Why most published research findings are false. PLoS Medicine, 2(8), e124. https://doi.org/10.1371/journal.pmed.0020124 Klein, R. A., Hardwicke, T. E., Aust, F., Breuer, J., Danielsson, H., Mohr, A. H., IJzerman, H., Nilsonne, G., Veer, A. E. van’t, Frank, M. C., &amp; Schönbrodt, F. D. (2021). Accelerating psychological science with transparency. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467. https://doi.org/10.1177/25152459211007467 Lakens, D. (2019). The value of preregistration for psychological science: A conceptual analysis. Japanese Psychological Review, 62(3), 221–230. https://doi.org/10.4992/jjpsy.62.221 Maxwell, S. E., Lau, M. Y., &amp; Howard, G. S. (2015). Is psychology suffering from a replication crisis? What does “failure to replicate” really mean? American Psychologist, 70(6), 487–498. https://doi.org/10.1037/a0039400 Neoh, J. X., Taylor, C. A., Driessen, G. W. J., &amp; Leung, J. (2023). Fifty years of research on questionable research practices in science: Quantitative analysis of co-citation patterns. Scientometrics, 128(10), 6275–6302. https://doi.org/10.1007/s11192-023-04766-1 Neyman, J., &amp; Pearson, E. S. (1933). Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231(694–706), 289–337. https://doi.org/10.1098/rsta.1933.0009 Nosek, B. A., Ebersole, C. R., DeHaven, A. C., &amp; Mellor, D. T. (2018). The preregistration revolution. Proceedings of the National Academy of Sciences, 115(11), 2600–2606. https://doi.org/10.1073/pnas.1708274114 Open Science Collaboration. (2015). Estimating the reproducibility of psychological science. Science, 349(6251). https://doi.org/10.1126/science.aac4716 Student. (1908). The probable error of a mean. Biometrika, 6(1), 1–25. https://doi.org/10.1093/biomet/6.1.1 Szucs, D., &amp; Ioannidis, J. P. A. (2017). Empirical assessment of published effect sizes and power in the recent cognitive neuroscience and psychology literature. PLOS Biology, 15(3), e2000797. https://doi.org/10.1371/journal.pbio.2000797 Wagenmakers, E.-J., Wetzels, R., Borsboom, D., Maas, H. L. J. van der, &amp; Kievit, R. A. (2012). An agenda for purely confirmatory research. Perspectives on Psychological Science, 7(6), 632–638. https://doi.org/10.1177/1745691612463078 cette conception, appelée “probabilité fiduciaire”, est une conception intermédiaire entre les probabilités objectives et subjectives, dont nous parlerons plus loin, que peu de personnes comprenaient↩︎ pour laquelle on n’est pas censé avoir de corrélation significative↩︎ "],["les-probabilités-objectif-ou-subjectif.html", "Chapter 6 Les probabilités : objectif ou subjectif", " Chapter 6 Les probabilités : objectif ou subjectif La conception des probabilités dans l’approche de Neyman-Pearson (Neyman &amp; Pearson, 1933) est une conception objective des probabilité, il s’agit du taux d’erreur à long terme. Cependant, il exist d’ autres conceptions des probabilités, notamment une conception subjective (Hájek, 2012; Rocchi &amp; Gianfagna, 2013). Il faut comprendre que ces deux approches sont radicalement différentes avec de farouches défenseurs de part et d’autres. Ainsi, certains auteurs n’adhèrent qu’à une conception purement objective des probabilités (Mises, 1957; Venn, 1876) alors que d’autres sont à l’extrême opposé et ne considère les probabilités que comme un phénomène purement subjectif (voir par ex., Finetti, 1974). Mais comment une probabilité pourrait-elle bien être subjective ? Revenons en arrière, nous sommes le 30 mai 2025, la veille de la finale de la ligue des champions. Les supporters du PSG croient durs comme fer que leur équipe va gagner ; les supporters de l’inter n’en sont pas moins convaincus que ceux du PSG. Les supporters de l’OM espèrent que l’inter l’emportera alors que les supporters de l’AC Milan soutiennent ouvertement le PSG. Les supporters du Standard de Liège (en Belgique), eux, se disent que cela va être un beau match. Bref, chacun a son opinion, sa croyance sur le fait de savoir qui va gagner. Finalement, le PSG gagne. Les croyances de beaucoup de personnes se sont avérées fausses. Même parmi les supporters du PSG qui aurait parié sur un résultat 5-0. Bien peu de personnes : la cote pour un résultat 5-0 était de 36 pour 1. Ces croyances sont omniprésentes : je pense qu’il va neiger demain, je ne crois pas qu’il va venir, je suis sûr que je peux négocier le prix de ma nouvelle voiture blanche… Tous ces exemples renvoie à une conception subjective des probabilités, c’est-à-dire la croyance qu’une personne a qu’un événement va survenir. Cette conviction qu’un événement va survenir est propre à chacun·e. Il n’y a pas de bonne réponse. La croyance que vous avez en quelque chose renvoie à la notion de probabilité a priori dans la conception bayésienne. References Finetti, B. de. (1974). Theory of probability, vol. 1. Wiley. Hájek, A. (2012). Interpretations of probability. https://plato.stanford.edu/entries/probability-interpret/. Mises, R. von. (1957). Probability, statistics and truth (Revised English edition). Macmillan. Neyman, J., &amp; Pearson, E. S. (1933). Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231(694–706), 289–337. https://doi.org/10.1098/rsta.1933.0009 Rocchi, P., &amp; Gianfagna, L. (2013). An essay on the double nature of probability. https://arxiv.org/abs/1301.5443. Venn, J. (1876). The logic of chance (2nd ed.). Macmillan. "],["la-probabilité-a-priori.html", "Chapter 7 La probabilité a priori 7.1 Une approche intuitive 7.2 Construire une distribution a priori 7.3 Envisager les priors comme des tailles d’effets. 7.4 Quelques remarques supplémentaires", " Chapter 7 La probabilité a priori Nous avons précédemment vu que le théorème de Bayes nécessitait de connaître la probabilité de l’hypothèse avant d’avoir recueilli les données. Cela peut sembler étrange à première vue à des chercheurs et chercheuses biberonné·es à l’approche fréquentiste. On ne vous a jamais demandé de réfléchir à la probabilité de votre hypothèse. Pourtant, si on y réfléchit un instant, quand on fait une analyse fréquentiste, par exemple, un t de Student, on a déjà toute une série de présupposés, comme la distribution des données suit une distribution normale, les variances sont homogènes, ou encore l’échantillon est suffisamment grand pour mettre en évidence l’effet qu’on cherche à observer. Pourquoi ne pourrait-on pas avoir un présupposé supplémentaire sur la probabilité que l’hypothèse est vraie ? La première fois qu’on est confronté à cette situation, on peut se questionner sur la manière dont il est possible d’attribuer une valeur précise à une hypothèse. On peut également être perturbé par le fait que l’inférence bayésienne requiert qu’on ait à donner une opinion sur la pertinence d’une théorie. Après tout, la science doit être objective dans le sens où quiconque essaierait de reproduire des résultats devraient obtenir les mêmes résultats (K. R. Popper, 1959). Or, si pour appliquer Bayes, on donne notre opinion, une sorte de niveau de crédit qu’on accorde à une théorie, comment une personne qui ne partagerait pas notre opinion pourrait obtenir les mêmes réultats ? Nous répondrons à cette question plus loin et commençons par nous rendre compte que, en réalité, ce n’est ni si compliqué, ni si abberant et que, en réalité, vous le faites déjà. 7.1 Une approche intuitive Un des points critiques de l’approche bayésienne est que les personnes qui souhaitent changer de pratique pour adhérer à l’approche bayéienne se retrouvent souvent perdu·e quand il s’agit de réfléchir à la probabilité a priori d’une théorie. Pourtant, si on y réfléchit un instant, demndez-vous si les scientifiques accordent vraiment la même probabilité à toutes les théories et se rendre compte que, en réalité, ce n’est pas le cas. N’y a-t-il pas des points de vue divergents sur l’explication des données ? N’y a-t-il pas des guerres de chapelle pour un peu près toute les théories de la psychologie, et de la science en général. Qu’en est-il des personnes qui affirment que les vaccins sont non seulement inefficaces mais sont à l’origine des plus graves maladies, comme les troubles du spectre autistique ? En physique, l’existence même de la théorie des cordes est controversée. Est-ce que toutes les personnes qui essaient de proposer un cadre théorique cohérent en s’appuyant sur cette théorie doivent être considérés comme des hurlubelus ? Vous-même, n’êtes-vous pas disposé·e à adhérer plus à certaines théories qu’à d’autres ? Faisons un petit exercice qui vous amènera à prendre conscience que c’est le cas. Dans cet exercice, vous devez classer des théories selon que le niveau de croyance que vous leur accordez. Il n’y a pas de bonnes ou de mauvaises réponses, c’est quelque chose de personnel. Á présent, revenons au tout début de la session. Je vous ai annoncé que je donnerais 50€3 aux personnes qui ne changeraient pas radicalement leur manière de mener leurs analyses et de mener leurs recherches. La contrepartie était de savoir combien vous seriez disposé à parier. Ainsi, si vous avez misé plus de 50€, disons 200€, cela signifie que vous êtes à peu prêt sûr·e que, peu importe ce que je vais dire dans la formation, vous ne changerez pas d’un iota. En revanche, si vous n’êtes prêt·e à miser qu’un euro, c’est que vous désirez profondément changer votre manière de faire des recherches et que vous m’accordez une confiance presque totale pour vous ouvrir la voie vers de nouvelles perspectives. On peut facilement estimer la probabilité que vous accordez à la théorie selon laquelle vous allez changer profondément votre manière de penser vos recherches grâce à ce pari. Si vous étiez prêt·e à miser 50€, cela signifie que vous accordez autant de chance au fait de pouvoir changer grâce à cette session qu’au fait de continuer à utiliser vos pratiques actuelles. Votre probabilité a priori est de 50%. Si vous étiez prêts à mettre 200 euros, c’est que vous croyez quatre fois plus dans le fait que l’hypothèse est fausse que dans le fait qu’elle soit vraie, ce qui nous donne \\(\\frac{200}{200+50}= 0.80\\). Vous accordez 80% de chances à l’hypothèse que vous ne changerez pas votre manière de penser la science, donc 20% à l’hypothèse que vous allez être chamboulé·e après cette formation. Á l’inverse, si vous n’étiez disposé·e à muser qu’un euro, cela signifie que vous accordez une probabilité de \\(\\frac{1}{1+50}= 0.019\\) au fait que vous ne changerez pas vos pratiques. Vous êtes sûr·e à 98% que cette session va profondément modifier votre manière de penser vos recherches. Vous pouvez adopter ce raisonnement avec n’importe quelle théorie. Prenez le temps de réfléchir à votre dernière recherche, ou à la prochaine. Imaginez à présent que vous deviez décider de miser soit sur la pertinence de votre théorie (dans le sens où en récoltant des données, vous allez avoir des preuves qui vont venir la soutenir) soit sur un tirage au sort. Pour le tirage au sort, vous avez un sac avec deux billes : une noire et une rouge. Le pari est de tirer rouge4. Est-ce que vous placez votre pari sur votre théorie ou sur le tirage au sort ? Si vous le placez sur le tirage au sort, alors vous accordez un crédit inférieur à 0.5 à votre théorie. Si vous misez sur votre théorie, vous lui accordez un crédit supérieur à 0.5. On peut affiner : la répartition des billes dans le sac change : vous avez deux rouges pour une noire. Préférez-vous parier sur le fait de tirer rouge ou sur votre théorie ? Si vous préférez miser sur votre théorie, c’est que vous lui accordez une probabilité supérieure à 0.66 (\\(\\frac{2}{2+1}\\)). Vous pouvez continuer à ajuster votre probabilité avec n’importe quelle répartition de billes qu’il est nécessaire pour atteindre le niveau de précision souhaité. Appliquer ce genre de raisonnement permet d’éviter d’accorder une probabilité a priori déraisonnable à votre théorie, en affirmant par exemple que vous êtes sûr·e à 99.999% que les vaccins sont la cause du trouble du spectre autistique. Vous pourriez encore vous dire que, si vous tester une théorie, c’est que vous lui accordez suffisamment de crédit pour qu’elle mérite que vous vous y intéressiez. En fait, les choses ne peuvent pas être aussi simples : certaines théories sont tellement évidentes que les tester ne sera qu’une perte de temps. Par exemple, quand je lève un bras, au bout d’un moment, j’ai mal. Il est probable que personne ne s’intéresse à cette théorie5. Á l’inverse, certaines théories peuvent avoir de grandes application mais peuvent sembler peu crédible a priori. La théorie de la relativité d’Einstein n’a pas tout de suite eu le succès retentissant qu’elle a aujourd’hui (pur une critique de cette théorie, voir par exemple Poor, 1922). Par exemple, si je vous demandais si la théorie sous-tendant l’homéopathie6 mérite d’être d’être testée, où la placeriez-vous ? 7.2 Construire une distribution a priori Arrivé à ce stade, vous avez une idée de ce que signifie la probabilité a priori d’une hypothèse et la manière dont on peut la formaliser. Cependant, ce n’est pas simple de comprendre comment on peut appliquer ce raisonnement pour arriver à mener des inférences. Un cas de figure particulièrement fréquent en psychologie est de comparer des moyennes. Comment est-il possible de passer d’une situation où on accorde une confiance à 80% à une théorie à une situation où c’est utile pour faire mon t de Student ? Une réponse précise à cette question est quelque peu technique et pourrait être rebutant. Nous allons donc aborder les choses de manière un peu plus accessible. Dans tous les cas, construire une distribution a priori est sans doute la partie la plus difficile dans l’utilisation de l’approche bayésienne. Dans cette section, l’objectif est d’expliquer la logique sous-tendant la contruction d’une distribution a priori. Dans la section suivante, nous évoquerons une manière beaucoup plus simple de le faire, mais l’exercice est utile pour comprendre ce que la logique sous-tendant la section suivante s’appuie directement de celle-ci. Concrètement, ce qu’on veut savoir, c’est dans quelle zone est que nous avons la plus forte probabilité que notre effet soit observé. Donc, tout comme dans l’approche fréquentiste où on va calculer la puissance statistique pour une taille d’effet que nous estimons raisonnablement pouvoir observer, la contruction d’une distribution a priori raisonnable requiert d’être expert du domaine dans lequel on veut mener l’étude. Si on ne se sent pas suffisamment expert, on peut regarder les effets qui sont habituellement observés dans le domaine qu’on veut investiguer en examinant par exemple des méta-analyses. On peut également se questionner sur la taille d’effet minimale qui vous amènerait à considérer que votre étude a du sens. Dans mon cas, je travaille sur l’apprentissage implicite en utilisant une tâche de temps de réaction sériel (Nissen &amp; Bullemer, 1987). Dans cette tâche, les participants doivent réagir le plus rapidement et le plus précisément possible à l’apparition d’un stimulus en fonction de sa localisation (voir Figure 7.1). Á l’insu des participants, les stimuli n’apparaissent pas de manière aléatoire mais suivent une séquence. L’apprentissage se manifeste par des temps de réaction de plus en plus courts au fur et à mesure que la séquence est répétée et augmente drastiquement lorsqu’on expose les participants à une nouvelle séquence. Figure 7.1: Illustraton d’une tâche de temps de réaction sériel. La question qu’on se pose ici est de savoir si les participants ont appris la séquence7. Pour construire la distribution a priori, il est nécessaire d’avoir des connaissances sur cette tâche : pour répondre à un stimulus en fonction de sa localisation, des personnes jeunes prennent en moyenne environ 400-450 ms par stimulus. si on demande à des personnes de répondre le plus rapidement possible à un stimulus visuel (sans notion de localisation), on obtiendrait une moyenne située entre 200 et 250 ms. les temps de réaction manquent de fiabilité et ils sont donc associés à une variance assez importante. La tâche est longue et ennuyeuse et certaines personnes peuvent se lasser et/ou se déconcentrer. Une fois qu’e nous connaissons’on connait suffisamment le protocole et les variables que nous mesurons, on va devoir se questionner sur deux points : quelle amélioration est-ce que je peux m’attendre à avoir sur les temps de réaction ; comment cette amélioration pourrait se répartir. Réfléchissons au premier point. Vu que des personnes ne peuvent pas répondre à des stimuli simples en moins de 200-250 ms, il ne semble pas raisonnable de penser que, en moyenne, les participants puissent avoir une amélioration de plus de 200 ms. Á l’inverse, si l’amélioration des temps de réaction était de l’ordre de 10 ms, on pourrait considérer que l’apprentissage ne semble pas contribuer de manière substantielle à la bonne réaliation de la tâche. Si on est moyennement optimiste sur notre procédure, un objectif raisonnable est de se dire qu’on obtiendra une amélioration d’environ 50 ms (ce qui représenterait une amélioration de 12,5% des temp de réaction \\(\\frac{400-350}{400}\\)). Si on est très optimiste, on peut imaginer une amélioration de 100 ms, donc un amélioratoin de 25% des temps de réaction. On peut choisir l’un ou l’autre, ou évntuellement couper la poire en deux et se mettre d’accord sur 75 ms. Dans la Figure Figure 7.2, la ligne verticale rouge représente les temps à 400 ms pour le premier bloc et la verticale bleue représente l’amélioration de 75 ms. Á présent qu’on a une idée de l’amélioration des temps de réaction, il ne semble pas plausible que notre procédure va permettre d’obtenir une différence d’exactement 75 ms. On peut se questionner sur les limites entre lesquelles la différence pourrait varier. On sait que les temps de réaction varient entre 200 et 250 ms pour stimuli simples et entre 400-450 pour les premiers blocs de la tâche de temps de réaction sériel. On peut donc se dire que la variabilité sera au maximum de 50 ms. Nous allons à présent vérifier si cette hypothèse tient la route. Vu que la moyenne des temps de réaction de l’ensemble des participants ne peut raisonnablement pas être inférieure à 250 ms, il s’agit de l’amélioration maximale qu’on peut envisager. Nous l’identifierons par la ligne jaune sur la Figure 7.2. On sait que 95% des observations se situent entre -1.96 et +1.96 écart-types. Donc, si on estime que l’amélioration moyenne est 75 ms, et que cette amélioration peut se situer quelque part entre -2 et +2 écart-types autour de cette amélioration moyenne (hypothétique), cela signifie que les temps de réaction qu’on pourra observer après apprentissage seront situés entre 227 ms et 423 ms. Cet intervalle est représentée par la zone verte dans la Figure 7.2. Figure 7.2: Vérification de la plausibilité des hypothèses dans la contruction d’une ditribution a priori. Dans la Figure 7.2, on observe que, au lieu d’améliorer les temps de réaction, les participants pourraient ralentir (la zone au delà de la barre verticale rouge). Cette supposition n’est pas complètement déraisonnable car la tâche est rébarbative. On peut estimer la probabilité d’observer ce phénomène avec la fonction pnorm. z&lt;-(400-325)/50 pnorm(z, lower.tail=F) ## [1] 0.0668072 On a 6.6% de chances de ne pas avoir d’apprentisagte du tout. On estimait également qu’il n’était pas raisonnable que les participants puissent répondre en moyenne en-dssous de 200-250 ms. En l’occurrence, la zone verte ne descend pas en-dessous de 200 ms, mais descend en-dessous de 250 ms. Avec les hypothèses que nous avons faites concernant les paramètres, cela signifie que cela surviendrait dans preque 7% des situations. z&lt;-(250-325)/50 pnorm(z, lower.tail=T) ## [1] 0.0668072 Ainsi, on ne l’exclut pas totalement mais on imagine que cela ne devrait pas arriver fréquemment. On doit à présent se demander si les hypothèses sont satisfaisantes ou s’il faut les ajuster. Peut-être qu’il est raisonnable de considérer qu’une absence d’apprentissage pourrait être plus fréquente que dans 7% des situations. On pourrait alors réduire l’effet d’apprentissage et revenir à l’hypothèse d’une amélioration des 50 ms, ou on pourrait augmenter l’écart-type. Dans le premier cas, cela rendrait moins probable d’avoir une amélioration qui amènerait les participants à répondre en moins de 250 ms en moyenne ; dans le second cas, cela rendrait également plus probable le fait d’avoir des temps moyens inférieurs à 250 ms. Donc, si on n’est pas totalement satisfait avec une amélioration moyenne de 75 ms, le changement qui semble le plus raisonnable est d’ajuster la moyenne. On peut évidemment ajuster la moyenne et l’écart-type. Il est indispensable de se rappeler de deux points : cette distribution a priori représente la manière dont les résultats moyens pourrait survenir et non les résultats individuels. Ce sont des hypothèses que vous faites sur les résultats qu’il est vraisemblable ou non d’obtenir. Dans tous les cas, l’avis ultime correspondra à l’opinion personnelle du psychologue et dépendra entièrement de lui. 7.3 Envisager les priors comme des tailles d’effets. Lorque nous passerons à la partie exercices, nous verrons qu’on ne devra pas réaliser cet exercice de réflexion sur les données car nous utiliserons le package BayesFactor (Morey &amp; Rouder, 2024). La logique qui sous-tend l’utilisation de ce package a été largement décrite dans des revues de psychologie (Morey &amp; Rouder, 2011; Rouder et al., 2009, 2012) et s’appuie sur la conception de Jeffreys (1961) pour établir la distribution a priori. Encart 3. Différence entre une distribution normale et une distribution Cauchy. Pour des raisons techniques, la distribution qui est utilisée dans le package BayesFactor (Morey &amp; Rouder, 2024) est une distribution Cauchy. On va de suite relativiser l’importance de cette décision en comparant les deux courbes : excepté le fait que la distribution Cauchy est plus pointue que la distribution normale, les deux courbes se ressemblent. Ce n’est que sur les valeurs extrêmes où on va observer des petites différences entre les deux distributions (voir Figure 7.3) Figure 7.3: Comparaison d’une distribution Cauchy avec une distribution normale. Dans cette manière d’envisager l’approche bayésienne, l’objectif n’est plus de se demander quelle valeur exacte on va observer, mais plutôt quelles tailles d’effet sont plausibles avant d’avoir vu les données. Concrètement, si l’on répète un grand nombre de fois la même expérience en s’attendant à une petite taille d’effet (par exemple \\(d_{\\text{Cohen}} = 0.2\\)), on pourrait observer des tailles d’effet légèrement plus grandes (par exemple 0.5), ou plus petites (comme -0.1). La distribution des tailles d’effet sous l’hypothèse alternative est alors modélisée par une loi de Cauchy centrée en 0, qui reflète notre incertitude. Cette loi est large, mais il est irréaliste que la vraie taille d’effet soit aussi extrême que 6. À l’inverse, si l’on s’attend à une grande taille d’effet (disons \\(d_{\\text{Cohen}} = 1\\)), on pourrait observer des valeurs comme 1.5 ou 0.5, mais il devient alors moins probable d’observer une valeur proche de 0. Examinez maintenant la Figure 7.4. Prenons le cas où l’on s’attend à une taille d’effet relativement grande, disons \\(d = 1\\). Si le rscale vaut 0.2 ou 0.5, la a hauteur sous la courbe est faible autour de 1 ; en revanche, cette densité augmente pour des valeurs de rscale plus élevées comme 1 ou 1.41. Il est donc préférable, dans ce cas, d’utiliser un rscale de 1 ou 1.41, car cela reflète mieux nos attentes. Inversement, si l’on pense que la taille d’effet est petite (par exemple \\(d = 0.2\\)), la hauteur de la distribution a priori est plus élevée autour de cette valeur lorsque le rscale est fixé à 0.5. Toutefois, si on choisit un rscale très faible, comme 0.2, la courbe devient très concentrée autour du zéro : on donne alors beaucoup plus de poids à l’absence d’effet qu’à la présence d’un petit effet — ce qui peut rendre difficile la détection de ce dernier. Ainsi, le choix du rscale revient à un compromis entre la hauteur du prior au point que l’on souhaite mettre en évidence (ex. d = 0.2 )) et la hauteur au niveau de l’absence d’effet (\\(d = 0\\)). Il s’agit de maximiser ce rapport, qui influence directement le Bayes factor. Rouder (2009) propose des valeurs de référence pour le rscale en fonction de la taille d’effet attendue : petite taille d’effet : rscale = 0.707 taille d’effet moyenne : rscale = 1 grande taille d’effet :rscale = 1.41 Ces valeurs sont intégrées directement dans le package BayesFactor (Morey &amp; Rouder, 2024), comme nous le verrons plus loin. ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. Figure 7.4: Priors sur une distribution Cauchy sur la taille d’effet standardisée (δ) 7.4 Quelques remarques supplémentaires Bien que la possibilité de fixer votre distribution a priori ne doit plus avoir de secrets pour vous à présent, l’idée que les résultats de vos analyses puissent dépendre de vos opinions pourrait vous gêner. Il est vrai que, si on utilise pour la ditribution a priori une très grande variance, c’est-à-dire que l’incertitude concernant la taille d’effet est très grande, alors vous pouvez artificiellement modifier les résultats. D’après Rouder (2009), cela survient quand l’incertitude concernant la taille d’effet sont supérieures à \\(\\delta &gt; 6\\). En choisissant une distribution aussi indéterminée, on privilégierait l’hypothèse nulle. Ceci s’explique par le fait que, avec une ditribution très large, la théorie qu’on souhaite tester est compatible avec une large gamme de résultats. Une théorie vague peut être compatible avec des données qui ont été obtenues, mais celles-ci la soutiennent peu si cette théorie peut s’accommoder de pratiquement n’importe quelles données. Ce phénomène s’appelle le paradoxe de Jeffreys–Lindley (Lindley, 1957). Comparez ici l’approche bayésienne avec l’approche fréquentiste. Dans l’approche fréquentiste, l’objectif est d’exclure une valeur : le 0. Dès lors que la probabilité de dépassement est inférieure à 0.05, le zéro est exclu et beaucoup en sont satisfaits, Á l’inverse, c’est le coeur de l’analyse bayésienne de punir celles et ceux dont les théories sont vagues (Dienes, 2008). Cependant, est-il vraiment raisonnable de penser qu’on puisse avoir des tailles d’effets supérieures à 6, voire même à 2 ? En vous entraînant à réaliser une distribution a priori avec vos hypothèses, non seulement vous prendrez conscience que ce n’est pas si difficile mais surtout cela vous amènera à réfléchir plus en profondeur à votre théorie et à faire des prédictions plus audacieuses. En ce sens, l’approche bayésienne rejoint l’esprit poppérien qui faisait l’apologie du risque (K. R. Popper, 1959) Le second point à avoir à l’esprit est que, si les données sont suffisantes, les données vont faire converger vers la même probabilité a posteriori, qu’importe la ditribution a priori choisie tant que les tailles d’effets envisagées sont raisonnables. L’objectif est seulement de savoir si vous avez une représentation précise de ce que vootre théorie permet de prédire (Dienes, 2008). Vous pouvez facilement savoir si vous avez recueilli assez de données en utilisant une approche robuste dans l’utilisation de l’inférence bayésienne, qui consiste à comparer les valeurs des facteurs de Bayes (nous verrons bientôt de quoi il s’agit) Évidemment, les fonction adaptées sont déjà implémentées dans R. Si cela ne vous suffit pas et que vous n’êtes toujours pas très à l’aise avec le fait de placer une probabilité sur votre hypothèse, il existe une autre alternative : placer une distribution a priori qui n’est pas informative. L’idée est de conidérer que vous n’avez aucune raison de préférer une hypothèse plutôt qu’une autre (Al-Hujaj &amp; Harney, 1997; Berger &amp; Pericchi, 2001). Dans ce cas, seule la vraisemblance des données déterminera votre probabilité a posteriori. Cette approche est ce qu’on appelle est les bayésiens objectifs Al-Hujaj &amp; Harney (1997). Cette approche est finalement assez similaire à l’école de vraisemblance (Royall, 1997) qui, avec l’approche fréquentiste et l’inférence bayésienne, représente la troisième grande école d’inférences statistiques. Si fondamentalement, les tenants de l’appproche objective ne s’oppose pas à l’approche subjective, et conidèrent même qu’être capable de fixer une distribution a priori représente la situation idéale, il y a néanmoins deux raisons qui justifient de favoriser l’approche objective. La première est celle que nous évoquons insidieusement depuis le début de cette partie : quand on mène des analyses statistiques, il peut être nécessaire de donner une apparence d’objectivité. Cette raison n’est sans doute pas la plus importante dès lors qu’on est capable de justifier le choix de la distribution a priori. La seconde raison est pragmatique : lorsque les modèles deviennent complexes, la spécifications attentives des distribution a priori subjectives pour tous les paramètres du modèle peut devenir ardu8. Il semble plus raisonnable de sélectionner des modèles avec des valeurs par défaut et, dans un second temps, préciser les distributions a priori pour le modèle sélectionner (Berger &amp; Pericchi, 2001). Pour terminer sur les distributions a priori, de manière théorique, il est envisageable de modéliser un autre distribution qu’une distribution normale. Cependant, comme l’objectif est de présenter la manière d’utiliser le package BayesFactor (Morey &amp; Rouder, 2024), et que les fonctions de packages ne requiert pas d’avoir plus qu’une idée de la taille d’effet que vous supposez pouvoir observer pour utiliser les fonctions de ce package, il ne semble ni opportun ni utile de présenter plus en détail ces cas de figures. Le lecteur intéressé pourra consulter Rossi (2005) et Dienes (Dienes, 2008). References Al-Hujaj, O.-A., &amp; Harney, H. L. (1997). Objective bayesian statistics. Annalen Der Physik, 509(1), 93–110. https://doi.org/10.1002/andp.19975090109 Berger, J. O., &amp; Pericchi, L. R. (2001). Objective bayesian methods for model selection: Introduction and comparison. In P. Lahiri (Ed.), Model selection (Vol. 38, pp. 135–207). Institute of Mathematical Statistics. Dienes, Z. (2008). Understanding psychology as a science: An introduction to scientific and statistical inference (1st ed., p. 184). Bloomsbury Academic / Red Globe Press. Jeffreys, H. (1961). Theory of probability (3rd ed.). Oxford University Press. Lindley, D. V. (1957). A statistical paradox. Biometrika, 44(1/2), 187. https://doi.org/10.2307/2333251 Morey, R. D., &amp; Rouder, J. N. (2011). Bayes factor approaches for testing interval null hypotheses. Psychological Methods, 16(4), 406–419. https://doi.org/10.1037/a0024377 Morey, R. D., &amp; Rouder, J. N. (2024). BayesFactor: Computation of bayes factors for common designs. https://CRAN.R-project.org/package=BayesFactor Nissen, M. J., &amp; Bullemer, P. (1987). Attentional requirements of learning: Evidence from performance measures. Cognitive Psychology, 19(1), 1–32. https://doi.org/10.1016/0010-0285(87)90002-8 Poor, C. L. (1922). Gravitation versus relativity. Putnam. https://archive.org/details/gravitationversu00pooruoft Popper, K. R. (1959). The logic of scientific discovery. Hutchinson. Rossi, P. E., Allenby, G. M., &amp; McCulloch, R. (2005). Bayesian statistics and marketing. In Wiley Series in Probability and Statistics. Wiley. https://doi.org/10.1002/0470863692 Rouder, J. N., Morey, R. D., Speckman, P. L., &amp; Province, J. M. (2012). Default bayes factors for ANOVA designs. Journal of Mathematical Psychology, 56(5), 356–374. https://doi.org/10.1016/j.jmp.2012.08.001 Rouder, J. N., Speckman, P. L., Sun, D., Morey, R. D., &amp; Iverson, G. (2009). Bayesian t tests for accepting and rejecting the null hypothesis. Psychonomic Bulletin &amp;Amp; Review, 16(2), 225–237. https://doi.org/10.3758/pbr.16.2.225 Royall, R. M. (1997). Statistical evidence: A likelihood paradigm. Chapman &amp; Hall. pour ceux et celles qui ne l’aurait pas compris, c’est juste un exercice de pensées pour vous amener à comprendre intuitivement l’approche bayésienne mais je ne peux en aucune manière donner 50€ à quiconque n’aurait pas changé de perspective vu que mon banquier m’a fait signer un document qui m’interdisait formellement de dépenser mon argent pendant que je travaillais↩︎ ou noir si vous préférez, cela n’a aucune importance.↩︎ formulé de cette manière. On pourrait en revanche être intéressé par la résistance à l’effort et savoir au bout de combien de temps la douleur devient insupportable.↩︎ Pour rappel, la théorie principale sous-tendant l’homéopathie est la mémoire de l’eau↩︎ l’exercice est volontairement simpliste pour favoriser la compréhension plutôt que d’utiliser un exemple réaliste qui pourrait paraître abscons à une personne néophyte dans le domaine décrit.↩︎ nous verrons néanmoins qu’il n’est pas nécessaire d’entrer autant dans les détails↩︎ "],["la-vraisemblance.html", "Chapter 8 La vraisemblance 8.1 Une explication intuitive 8.2 Définition 8.3 Un exemple simple 8.4 Vraisemblance et variable quantitative 8.5 Exercice", " Chapter 8 La vraisemblance 8.1 Une explication intuitive Vous venez de vous disputer avec une personne que vous savez être rancunière. Pourtant, le lendemain de votre dispute, cette personne vient sonner à votre porte, vous prie de l’excuser de son comportement de la veille et souhaite se faire pardonner en vous offrant un cadeau. Après avoir accepté le présent, vous vous rendez compte que quelque chose bouge à l’intérieur. Dans un premier temps, vous vous dites que c’est sans doute un mignon petit chaton. Cependant, après quelques instants de réflexion, vous vous rappelez que la personne avec laquelle vous vous êtes disputée est rancunière et vous vous demandez s’il ne s’agirait pas plutôt d’un diable de Tasmanie et que la personne vous a fait ce présent pour se débarasser définitivement de vous. Vous vous dites que vous allez introduire un morceau de viande à l’intérieur de la boîte parce que vous savez que vous avez 90% de chances que le morceau soit dévoré s’il s’agit d’un diable de Tasmanie. Vous n’oubliez tout de même pas que les chats ont carnivores et qu’il y a 10% de chances qu’un petit chaton arrive à manger le morceau de viande que vous avez introduit. Après avoir introduit le morceau de viande, vous attendez un instant, vous tirez sur la corde à laquelle le morceau était solidement attaché, plus rien. Est-ce que c’est un diable ou un chaton ? 8.2 Définition La vraisemblance est la probabilité d’observer les données pour une hypothèse donnée. La seconde partie de la phrase est particulièrement importante. La probabilité d’observer des données dépend de l’hypothèse qu’on est en train d’examiner. ## [1] 45 20 15 30 29 29 32 46 35 27 28 16 34 24 56 30 40 19 13 46 Prenons les données présentées ci-dessus. Sans faire de calcul, demandez-vous quelle pourrait être la moyenne et quel pourrait être l’écart-type. Vous faites une hypothèse concernant cette moyenne et cet écart-type, hypothèse qui pourra être plus moins proche de la réalité. Si vous êtes très proche de la réalité, la probabilité d’observer les données sera élevée, si vous l’êtes moins, cette probabilité va diminuer. Astuce Pour vous aider dans vos estimations, la valeur la plus petite est 13 et la plus grande est 56, sachant que 95% des données se situent entre -2 et +2 écart-types, cela devrait vous aider à estimer l’écart-type. Nou reviendrons au calcul précis de la vraisemblance pour ces données un peu plus loin mais commençons à expliquer le calcul de la vraisemblance par un exemple simple. 8.3 Un exemple simple Vous jouez aux dés et vous faites l’hypothèse que le dé est équilibré. Vous lancez le dé 20 fois, vous obtenez 10 fois le 6, et 2 fois chacune des autres valeurs. On peut obtenir la vraisemblance d’avoir 10 fois la valeur 6 en 20 essais en utilisant la binomiale. Dans R, on l’obtient facilement avec la fonction binom.test. binom.test(x = 10, # nombre de succès, càd. avoir 6 n = 20, # nombre d&#39;essais p = 1/6) # la probabilité d&#39;avoir 6 si le dé n&#39;est pas pipé ## ## Exact binomial test ## ## data: 10 and 20 ## number of successes = 10, number of trials = 20, p-value = 0.0005985 ## alternative hypothesis: true probability of success is not equal to 0.1666667 ## 95 percent confidence interval: ## 0.2719578 0.7280422 ## sample estimates: ## probability of success ## 0.5 La probabilité d’observer exactement 10 fois 6 sur les 20 lancers vraisemblance d’observer 0.000599. Cette probabilité est assez faible. Vous pouvez faire une nouvelle hypothèse à présent : le dé est un peut-être pipé de sorte à ce qu’il tombe 2 fois plus souvent sur le 6 que sur les autres nombres. Notre nouvelle probabilité du succès est de 2/7 pour le 6, et 1/7 pour toutes les autres faces (1/7 pour le 1, 1/7 pour 2, 1/7 pour le 3, 1/7 pour le 4, et 1/7 pour le 5). Ainsi, le chiffres 6 a deux fois plus de chances d’être observé que n’importe quelle autre face. binom.test(x = 10, # nombre de succès, càd. avoir 6 n = 20, # nombre d&#39;essais p = 2/7) # la probabilité d&#39;avoir 6 pour un dé est pipé ## ## Exact binomial test ## ## data: 10 and 20 ## number of successes = 10, number of trials = 20, p-value = 0.04563 ## alternative hypothesis: true probability of success is not equal to 0.2857143 ## 95 percent confidence interval: ## 0.2719578 0.7280422 ## sample estimates: ## probability of success ## 0.5 Dans ce cas, la vraisemblance que les chances d’avoir 6 vaut 0.045626. Cette vraisemblance est 76.1702838 plus élevée que la vraisemblance d’un dé non pipé. Le dé est sans doute pipé. Remarquez qu’ici, j’aurais pu utiliser “le dé est vraisemblablement pipé” mais j’ai évité cette formulation pour éviter l’ambiguïté entre le mot “vraisemblable” Encart 4. Á propos de l’estimation par maximum de vraisemblance. Pour quiconque ayant déjà réalisé une analye factorielle, une modélisation d’équation structurale ou encore un modèle linéaire (mixte) généralisé, le mot vraisemblance ne doit pas être étranger car un des algorithmes les plus utilisés dans ces contextes est l’estimation du maximum de vraisemblance. L’estimation du maximum de vraisemblance consiste à estimer la vraisemblance pour différentes hypothèses et d’identifier l’hypothèse pour laquelle la probabilité est la plus élevée permettra d’avoir une estimation des paramètres d’intérêt. Sans vouloir rentrer dans la rigueur mathématique pour estimer un maximum de vraisemblance, voici schématiquement ce qu’un algorithme d’estimation du maximum de vraisemblance réaliserait pour estimer la probabilité du succès pour le dé de notre exemple. .cl-9eb094d2{}.cl-9ea4114e{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9ea8a268{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9ea8c6e4{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9ea8c70c{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9ea8c70d{width:0.75in;background-color:rgba(14, 146, 92, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9ea8c716{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 8.1: Vraisemblance estimée pour différentes hypothèses de probabilité d'obtenir 6. p.succèsvraisemblance0.050.000000011340720.100.000007150904020.150.000248381989620.200.002594827400670.250.017035628882700.300.083445029629810.350.166156189823850.400.370261769406640.450.660644678101940.501.000000000000000.550.660644678101940.600.370261769406640.650.166156189823850.700.083445029629810.750.017035628882700.800.002594827400670.850.000248381989620.900.000007150904020.950.000000011340721.000.00000000000000 Sans grande surprise, la vraisemblance est maximale dans notre exemple lorsque la probabilité d’obtenir 6 est de 0.5. Néanmoins, quand il faut pouvoir estimer plusieurs paramètres simultanément, les choses sont moins triviales que cela. 8.4 Vraisemblance et variable quantitative Si dans le cas précédent, le calcul de la vraisemblance est assez simple, les choses se compliquent lorsqu’on est confronté à une variable quantiative. Pour comprendre le calcul de la vraisemblance, il est nécessaire de comprendre une notion supplémentaire : la densité de probabilité. La densité de probabilité est la hauteur sous la courbe dans une distribution. Pour une distribution normale, on peut l’obtenir avec la fonction dnorm9. Concrètement, j’ai des données dont la moyenne est de 100, l’écart-type vaut 15, la hauteur sous la courbe pour la valeur 112 est obtenue ainsi : ## [1] 0.01931277 Il est important de comprendre que, pour une variable continue, aucun score, aucune valeur n’a une denité de probabilité différente de 0. La densité est calculée pour un intervalle. Il n’est pas nécessaire de préciser cet intervalle, R va l’inférer en fonction de la valeur qu’on rentre. Figure 8.1: Représentation graphique du maximum de vraisemblance pour 1 observervation située à 112 dans une distibution dont la moyenne est supposée être à 100 et l’écart-type à 15. Nous avions déjà évoqué dans la section consacrée à l’estimation de la distribution a priori de la hauteur sous la courbe. Il s’agissait déjà de la densité de probabilité. Nous n’avions pas évoqué le concept à ce moment-là pour focaliser sur la compréhension du prior plutôt que sur la notion probabiliste. La vraisemblance pour des données quantitatives va être la probabilité conditionnelle d’avoir conjointement les densités de probabilité pour une hypothèse donnée. Nous avons vu dans les rappels sur les probabilités qu’une probabilité conjointe était le produit entre différentes probabilités lorsque certains éléments sont imposés. C’est la probabilité des données étant donné une hypothèse. Revenons à notre exemple sur le QI. Imaginons que nous mesurions le QI des personnes qui suivent cette formation. Voici les données que j’obtiens ## [1] 143 127 125 126 127 116 108 119 126 117 125 109 110 129 126 116 127 On peut obtenir la densité de probabilité pour ces valeurs pour l’hypothèse d’une moyenne à 100 et d’un écart-type à 15, c’est-à-dire l’hyopthèse selon laquelle votre QI ne dépasse celui de la moyenne de la population. ## [1] 0.0004368688 0.0052633439 0.0066318093 0.0059212307 0.0052633439 ## [6] 0.0150575218 0.0230702595 0.0119238944 0.0059212307 0.0139928197 ## [11] 0.0066318093 0.0222149735 0.0212965337 0.0041036534 0.0059212307 ## [16] 0.0150575218 0.0052633439 Le produit de toutes ces densités nous fournit la vraisemblance : ## [1] 0.0000000000000000000000000000000000009854725 De manière générale, plus il y a des valeurs, plus le produit des densités va se rapprocher de 010.Néanmoins, dans ce cas, la vraisemblance semble particulièrement faible. On pouvait s’y attendre. Si on représente graphiquement les densité de ces observations, la plupart des observations sont sur les extrémités et peu sont situées au centre. ## [1] 143 127 125 126 127 116 108 119 126 117 125 109 110 129 126 116 127 Figure 8.2: Représentation graphique densité pour l’ensemble des valeurs de QI On peut refaire la même figure mais en utilisant cette fois la moyenne et l’écart-type observé pour les valeurs de QI (voir Figure 8.3). On constate sur la Figure que la hauteur pour chaque observation est bien plus élevée que ce qu’on observait dans la Figure 8.2). Les données nous disent qu’une moyenne à 122 est bien plus probable qu’une moyenne à 100. ## [1] 143 127 125 126 127 116 108 119 126 117 125 109 110 129 126 116 127 Figure 8.3: Représentation graphique densité pour l’ensemble des valeurs de QI lorsque la moyenne et l’écart-type correspondent à la moyenne et l’écart-type des valeurs de QI. On peut comparer la vraisemblance qu’on obtient quand on utilise la bonne moyenne et le bon écart-type. La valeur qu’on obtient est bien plus élevée que celle qu’on obtenait avec une moyenne à 100 et un écart-type à 15. Vous pouvez comparer la vraisemblance qu’on a obtenue avec celle qu’on obtient en utilisant la fonction logLik. # Vraisemblance avec l&#39;hypothèse d&#39;un QI égal à la moyenne du QI # et un écart-type égal à la moyenne de l&#39;écart-type densite&lt;-dnorm(QI,mean(QI),sd(QI) ) densite ## [1] 0.002748363 0.038794592 0.042862914 0.041040758 0.038794592 0.035552856 ## [7] 0.012571736 0.042476075 0.041040758 0.038212811 0.042862914 0.014974513 ## [13] 0.017608902 0.033354098 0.041040758 0.035552856 0.038794592 vraisemblance122&lt;-prod(densite) vraisemblance122 ## [1] 0.000000000000000000000000004623054 # Comparaison avec la vraisemblance obtenue par la fonction logLik lmx &lt;- lm(QI ~ 1) # on modélise uniquement l&#39;intercept logML&lt;-logLik(lmx) # on obtient le logarithme (log Likelihood) de la vraisemblance as.numeric(exp(logML)) # en faisant l&#39;exponentiel, on obtient la même valeur que celle que nous avons calculée. ## [1] 0.000000000000000000000000004694374 Avant de passer à la section suivante, il est important de préciser que la vraisemblance atteint son maximum dans notre exemple parce que les données étaient issue d’une distribution normale et qu’il n’y avait pas de valeur influente. Quand la distribution supposée n’est pas correcte, ou qu’il y a des valeurs influentes, la valeur pour laquelle la vraisemblance est maximale peut être différente de la moyenne et de l’écart-type obtenu de manière arithmétique arithmétique. 8.5 Exercice 8.5.1 Énoncé Calculez la vraisemblance avec des données qui vous ont été présentées dans la partie définition avec la moyenne et l’écart-type que vous aviez imaginé. Comparez la différence de vraiselblance avec la moyenne et l’écart-type calculé. Pour vous aider, vous pouvez recréer le vecteur en utilisant cette ligne de commande Exo1&lt;-c(45, 20, 15, 30, 29, 29, 32, 46, 35, 27, 28, 16, 34, 24, 56, 30, 40, 19, 13, 46) Cliquez pour la solution m&lt;-35 # ma moyenne s&lt;-10 # mon écart-type densite&lt;-dnorm(Exo1,m,s) vrais&lt;-prod(densite) vrais ## [1] 0.00000000000000000000000000000000005259341 # La même chose avec la vraie moyenne m&lt;-mean(Exo1) # moyenne exo1 s&lt;-sd(Exo1) # écart-type exo1 densite&lt;-dnorm(Exo1,m,s) vrais2&lt;-prod(densite) vrais2 ## [1] 0.000000000000000000000000000000000445032 il existe des fonctions R pour obtenir la densité de probabilité pour n’importe quelle distribution mais ce n’est pas l’objet de l’explication ici↩︎ dans une distribution normale, la densité ne peut pas dépasser 1 et mutiplier des valeurs entre 0 et 1 entre elles rapproche de 0. Par exemple \\(0.1 \\times 0.1 = 0.01\\)↩︎ "],["la-probabilité-a-posteriori.html", "Chapter 9 La probabilité a posteriori 9.1 l’intervalle de crédibilité", " Chapter 9 La probabilité a posteriori Dans l’approche bayésienne, déterminer la probabilité a posteriori suffit pour se faire une opinion concernant une théorie. Selon Bayes, P(H|D) est proportionnel à \\(P(D|H) \\times P(H)\\), c’est-à-dire que l’a posteriori est donné par la vraisemblance multipliée par l’a priori. Ainsi, dans notre exemple, la probabilité a posteriori pour l’hypothèse nulle \\(P(D|H_0)\\), la probabilité a posteriori vaut \\(P(H_{QI_{100}}|D) \\text{ est proportionnel à } P(D|H_{QI_{100}}) \\times P(H_{QI_{100}})\\). De même, la probabilité a posteriori pour l’hypothèse alternative \\(P(D|H_1)\\) est égale à \\(P(H_{QI_{122}}|D) \\text{ est proportionnel à } P(D|H_{QI_{122}}) \\times P(H_{QI_{122}})\\) En créant une ditribution a priori, on formalise le fait que certaines tailles d’effet sont plus probables que d’autres. Chacune de ces tailles d’effet représente une hypothèse particulière. Nous devons multiplier chaque hypothèse de la distribution a priori par la vraisemblance pour obtenir la distribution a posteriori. Quand on a fait cela, on remarque que la distribution a posteriori est essentiellement dominée par la vraisemblance (voir Figure) qui illustre la manière dont la distribution a posteriori évolue pour différents distributions a priori en fonction de la vraisemblance des données qui atteint son maximum pour la zone où la taille d’effet est le plus probable. Figure 9.1: Représentation de la distribution a posteriori en fonction de différentes distributions a priori, de la vraisemblance et de différentes tailles d’effet Donc, même si des personnes partent avec des distribution a priori très différentess, en recueillant suffisamment de données, tant que les distributions a priori sont suffisamment étalées et autorisent une probabilité non négligeable dans la région correspondant à la valeur réelle de la population, les distributions a posteriori, étant fortement déterminées par la vraisemblance, finiront par être très similaires (Edwards et al., 1963). En ce sens, les statistiques bayésiennes soulignent la nature objective de la science : différentes opinions de départ convergeront lorsque les données seront suffisantes. La vraisemblance, qui représente les données, finit par dominer les conclusions. Résumer les résultats par une distribution a posteriori peut être déroutant pour les scientifiques habitués à l’approche fréquentiste. Avoir une probabilité, c’est bien mais qu’en fait-on ? Cela pourrait être rassurant de pouvoir se positionner par rapport à une hypothèse nulle. Nous verrons comment le faire dans la section conacrée aux Facteur de Bayes. 9.1 l’intervalle de crédibilité La Figure 9.1 va permettre d’aider à comprendre à quoi correspond l’intervalle de crédibilité, également appelé intervalle de probabilité ou région de plus haute densité (RHD). Il faut comprendre que cet intervalle n’est pas spécifique à la distribution a posteriori, Un intervalle de crédibilité est utilisé pour caractérisé une distribution probabiliste. Il s’agit de la probabilité qu’un paramètre qu’on ne peut pas directement observer ait une probabilité particulière (par exemple 95%) d’être à l’intérieur de cet intervalle. Cette notion est assez proche de l’intervalle de confiance dans l’approche fréquentiste mais s’en distingue conceptuellement sur un aspect important : dans l’approche fréquentiste, l’intervalle de confiance renvoie au fait que, si on répète un grand nombre de fois la même expérience, dans 95% des situations, la valeur de la population pour le paramètre d’intérêt sera inclus à l’intérieur des limites de l’intervalle estimé à partir de l’échantillon. Ainsi, les limites sont aléatoires dans l’intervalle de confiance alors que le paramètre est fixe. Dans l’approche bayésienne, l’idée est un peu différente car, non seulement il dépend de la distribution a priori mais aussi parce qu’on ne considère pas que ce sont les limites qui sont aléatoires mais ce qui peut changer c’est le paramètre et non l’intervalle. Imaginons que une intervalle de crédibilité entre 30 et 40, cet intervalle est centré sur la moyenne de la distribution a posteriori, c’est-à-dire 35, cela signifie qu’une valeur du paramètre égale à 35 est la valeur la plus probable, 34 et 36 sont un peu moins probables mais raisonnablement probables et il est très peu probable que le paramètre ait une valeur de 29 ou de 41. References Edwards, W., Lindman, H., &amp; Savage, L. J. (1963). Bayesian statistical inference for psychological research. Psychological Review, 70(3), 193–242. https://doi.org/10.1037/h0044139 "],["le-facteur-de-bayes.html", "Chapter 10 Le facteur de Bayes 10.1 Un peu de rigueur mathématique 10.2 Ajuster nos probabilités 10.3 Tester une hypothèse nulle 10.4 Rôle de l’a priori sur le Bayes factor", " Chapter 10 Le facteur de Bayes Dans la partie consacrée à la vraisemblance, nous avons calculé la vraisemblance pour l’hypothèse selon laquelle le QI de cette assemblée ne distinguait pas de celui de la moyenne de la population générale (l’hypothèse nulle) et pour l’hypothèse selon laquelle cette assemblée avait un QI vaut 12211. Nous avons vu que la vraisemblance était très différente pour l’hypothèse où le QI moyen de cette assemblée était de 100 et pour l’hypothèse où le QI moyen de l’assemblée était de 122. On pourrait se demander à quel point l’hypothèse selon laquelle “le QI moyen est à 122” est plus probable que l’hypothèse selon laquelle “le QI moyen est de 100”. Si on pouvait répondre à cette question, on pourrait alors savoir si nous disposons de preuves tangibles en faveur d’une hypothèse par rapport à une autre. Pour répondre à cette question, on peut simplement faire le rapport entre les deux voir l’équation (10.1). Ce rapport de vraisemblance est ce qu’on apppelle le facteur de Bayes. \\[\\begin{equation} \\frac{P\\left(H_1|D \\right)}{P\\left(H_0|D \\right)} = \\frac{P\\left(H_1\\right)}{P\\left(H_0\\right)} \\times \\frac{P\\left(D|H_1 \\right)}{P\\left(D|H_0 \\right)} \\tag{10.1} \\end{equation}\\] où, pour rappel, P(H|D) est la probabilité d’une hypothèse étant donné les données et P(D|H) est la probabilité des données étant donné une hypothèse, c’est-à-dire la vraisemblance. On peut formuler ainsi, les choses d’une autre manière : \\[\\begin{equation} \\text{Cotes a posteriori} =\\text{Cotes a priori} \\times \\text{rapport de vraisemblance} \\tag{10.2} \\end{equation}\\] Rappelez-vous qu’on a déjà évoqué les cotes en faveur d’une hypothèse par rapport à une autre, notamment quand vous avez dû parier sur le fait que cette formation changerait votre manière de penser vos recherches. Par ailleurs, nous avons déjà calculé la vraisemblance pour les deux hypothèses. Nous pouvons donc examiner le rapport de vraisemblance : FB&lt;-vraisemblance122/vraisemblance100 FB ## [1] 4691204879 Le rapport de vraisemblance est appelé le facteur de Bayes (B). Une notation \\(B_{01}\\) indique qu’on place la vraisemblance de l’hypothèse nulle au numérateur et celle de l’hypothèse alternative au dénominateur. Ainsi, une facteur de Bayes supérieur à 1 dans ce cas apporterait du soutien en faveur de l’hypothèse nulle tandis qu’un facteur de Bayes inférieur à 1 apporterait un soutien en faveur de l’hypothèse alternative. La notation \\(B_{01}\\) signifie que c’est la vraisemblance de l’hypothèse alternative qui est au numérateur. L’interprétation est donc l’inverse que celle de \\(B_{01}\\). Si B est proche de 1, alors l’expérimentation manque de sensibilité, sans doute parce que vous n’avez pas assuz de participant·es. Remarquez ici que vous pouvez distinguer les situations où votre expérimentation n’est pas assez discriminante entre l’hypothèse nulle et l’hypothèse alternative des situations où les preuves soutiennent l’hypothèse nulle. Ceci représente une différence majeure par rapport à l’approche fréquentiste où on ne peut que tolérer l’hypothèse nulle car l’absence de preuve n’est pas la preuve de l’absence (Caldwell, 2022; Lakens, 2017; voir néanmoins le packages TOSTER qui permet de tester des hypothèses nulles en utilisant une approche fréquentiste, Lakens et al., 2018). Dans notre cas, nous avons placé la vraisemblance au numérateur, cela signifie que l’hypothèse d’un QI moyen à 122 est 4691204878.88566 fois plus probable que l’hypothèse nulle. On se rend compte ici, que même avec une très faible probabilité a priori en faveur de l’hypothèse alternative, ce rapport est telle énorme que la probabilité a posteriori serait proche de 1. La question qui se pose est comment interpréter ces facteurs de Bayes dans des situations moins claires ? Est-ce qu’un FB est 1.5 est suffisamment élevé pour apporter du soutien ? Les bayésiens vous diraient que c’est à vous de décider, qu’ils se refusent à proposer des heuristiques arbitraires telle que le fameux \\(p&lt;.05\\) pour déclarer qu’un effet est significatif. Néanmoins, certains auteur (par ex., Wagenmakers et al., 2011) ont apporté des balises qui permettent aux personnes qui s’initient aux statistiques bayésiennes de se positionner. Ces balises ont été établies pour que, ce qui représente des preuves en faveur de l’hypothèse alternative, corresponde plus ou moins à un effet significatif si on avait utilisé une approche fréquentiste pour traiter les données. .cl-1c3b76e0{}.cl-1c328e2c{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-1c3604e4{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-1c361f1a{width:1.356in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1c361f24{width:4.264in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1c361f25{width:1.356in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1c361f26{width:4.264in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1c361f2e{width:1.356in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1c361f2f{width:4.264in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1c361f30{width:1.356in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-1c361f31{width:4.264in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 10.1: Balise permettant d'interpréter les facteurs de Bayes quand la vraisemblance pour l'hypothèse nulle est au numérateur (B10) FB10interprétation&gt;100Preuves extrêmes en faveur de l'hypothèse alternative&gt;30 et &lt;100Très fortes preuves en faveur de l'hypothèse alternative&gt;10 et &lt;30Fortes preuves en faveur de l'hypothèse alternative&gt;3 et &lt;10Preuves substantielles en faveur de l'hypothèse alternative&gt;1 et &lt;3Preuves anecdotiques en faveur de l'hypothèse alternative1Absence de preuve&lt;1 et &gt;1/3Preuves anecdotiques en faveur de l'hypothèse nulle&lt;1/3 et &gt;1/10Preuves substantielles en faveur de l'hypothèse nulle&lt;1/10 et &gt;1/30Fortes preuves en faveur de l'hypothèse nulle&lt;1/30 et &gt;1/100Très fortes preuves en faveur de l'hypothèse nulle&lt;1/100Preuves extrêmes en faveur de l'hypothèse nulle De ce qui vient d’être expliqué découlent deux propriétés particulièrement intéressante. D’abord, l’utilisation des facteurs de Bayes n’implique pas que deux scientifiques aient les mêmes cotes a priori en faveur d’une hypothèse. Puisque un facteur de Bayes est un rapport de vraisemblance et que ce rapport ne dépend pas (vraiment) des cotes a priori, quiconque peut mettre à jour sa cote en faveur d’une hypothèse en la multipliant par le facteur de Bayes. Le facteur de Bayes permet d’ajuster les cotes de façon continue sans devoir rejeter ou accepter une hypothèse. D’ailleurs, nous avons vu dans la tâche où il vous était demandé de classer les théories qu’il peut y avoir des une certaine part d’incertitude pour certaines théories alors qu’on est plus confiant en d’autres, même si on se laisse une petite place pour le doute. Après tout, est-ce que le faillibilisme n’est pas une propriété inhérente de la science (Peirce, 1877; K. Popper, 1963) ? Dans l’approche bayésienne, les données viennent moduler nos croyances, nos convictions, bref, le crédit que nous accordons aux théories. Le second point est que cette modulation peut se faire en faveur de l’hypothèse nulle. On peut avoir des preuves en faveur de l’hypothèse nulle, et donc la tester. Dans la suite de cette section, nous allons dans un premier temps présenter de manière plus rigoureuse la manière de calculer les facteurs de Bayes avant d’illustrer ces propriétés en reprenant une procédure assez similaire à celle que nous avons utilisée pour illutrer certaines limites de l’approche de Neyman-Pearson (Neyman &amp; Pearson, 1933). Nous terminerons en évoquant comment on peut s’assurer que notre facteur de Bayes n’a pas été influencé par le choix de la distribution a priori. 10.1 Un peu de rigueur mathématique Les calculs qui ont été réalisés jusqu’à présent pour obtenir les facteurs de Bayes ont négligé la rigueur mathématique pour favoriser l’aspect pédagogique. Ainsi, si on utilisait la fonction ttestBF (Morey &amp; Rouder, 2024) qui permet de réaliser un t de Student en utilisant l’approche bayésienne, nous aurions également des preuves substantielles en faveur de l’hypothèse alternative mais la valeur serait beaucoup moins élevée que celle que nous avons calculée. library(BayesFactor) tBF.out&lt;-ttestBF(QI, # Les données mu = 100, # la norme pour fixer l&#39;hypothèse nulle rscale = sqrt(2)) # La distribution a priori pour une distribution ultrawide (vu que la taille d&#39;effet qu&#39;on s&#39;attend à avoir est grande) tBF.out ## Bayes factor analysis ## -------------- ## [1] Alt., r=1.414 : 1144439 ±0% ## ## Against denominator: ## Null, mu = 100 ## --- ## Bayes factor type: BFoneSample, JZS La formule exacte qui est utilisée est fournie par Rouder et al. (2009) et est décrite dans l’équation (10.3) \\[\\begin{equation} B_{10} = \\frac{ \\int_{0}^{\\infty} \\left(1+Ng\\right)^{-1/2} \\times \\Bigg( 1+\\frac{t^2}{(1+Ng)\\times v}\\Bigg)^{\\left(v+1\\right)/2} \\times 2\\pi^{-1/2} \\times g^{-3/2} \\times e^{-1/(2g) \\times dg}}{\\Bigg( 1+\\frac{t^2}{v}\\Bigg)^{(v+1)/2}} \\tag{10.3} \\end{equation}\\] Dans cette équation, t représente la valeur du t de Student (selon l’approche fréquentiste), N représente la taille de l’échantillon, v représente les degrés de liberté (N-1) et g représente la densité de probabilité sur la distribution Cauchy dont nous avons parlé précédemment. Nous pouvons à présent montrer comment la valeur est réellement calculée dans le package BayesFactor (Morey &amp; Rouder, 2024). Nous allons commencer par préparer les informations les plus accessibles la valeur du t de Student selon l’approche fréquentiste. On peut obtenir cette information grâce à la fonctioin t.test. # on commence par faire un t de Student fréquentiste # on extrait la valeur t tstat &lt;- t.test(QI , mu = 100)$statistic tstat ## t ## 10.33488 On récupère la taille de l’échantillon et nous établissons le rscale # on récupère le nombre d&#39;obervations (nécssaire notamment pour les ddl) n &lt;- length(QI) rscale &lt;- sqrt(2) Dans l’équation, le dénominateur est la partie la plus simple à comprendre. Il s’agit de la densité de probabilité sous hypothèse nulle. Il s’agit pratiquement de ce que nous avons fait précédemment, avec la nuance que nous allons utiliser une distribution t plutôt qu’une distribution normale. Pour la distribution normale, la fonction était dnorm. Pour la distribution t, la fonction est dt. # fonction de densité marginale sous H0 # la fonction dt permet de calculer une densité de probabilité # pour une distribution t, comme dnorm le fait pour une distribution normale # On peut donc calculer la # densité sous H0 : p(D | H0) # ce sera le dénominateur denominator &lt;- dt(tstat, df = n - 1) denominator ## t ## 0.00000001176713 Il y a deux différences importantes entre un numérateur et le dénominateur : la première est qu’on doit réaliser une intégrale. La seconde est qu’il faut pondérer la vraisemblance conditionnelle, c’est-à-dire la vraisemblance pour une multitude de cas de tailles d’effets possibles, par la densité de probabilité de la distribution Cauchy. Vous ne serez pas surpris·e d’apprendre qu’il existe une fonction pour calculer la densité de probabilité sur une distribution Cauchy qui s’appelle dcauchy. Dans l’équation, on remarque aussi qu’une partie du numérateur correspond au dénominateur, qu’on doit appliquer dans le cadre d’une intégrale. On suppose que la taille d’effet \\(\\delta\\) suit une distribution Cauchy centrée en 0, dont la largeur dépend du paramètre rscale. On va modéliser la distribution des tailles d’effet possible en utilisant l’argument ncp avec comme valeur \\(\\delta \\times \\sqrt{n}\\) pour calculer la vraisemblance d’observer la statistique t. L’idée est de se demander quelle serait la vraisemblance d’avoir cette valeur de t si la taille d’effet avait comme valeur \\(\\delta\\) et que ce \\(\\delta\\) se distribuait en suivant une distribution Cauchy avec le paramètre rscale que nous avons choisi. Il va falloir faire l’intégrale12, c’est-à-dire envisager pratiquement tous les cas de figures possibles pour une taille d’effet variant de -=\\(\\delta = -4\\) à \\(\\delta=4\\), R requiert que la fonction permettant de faire des intégrales integrate ait comme argument principal la fonction pour laquelle on doit faire l’intégrale. Nous allons donc dans un premier créer une fonction integrand qui pourra être utilisée pour faire l’intégrale. # Il va falloir faire la même chose à présent pour H1 # il faut calculer la densité p(D | H1) # nous allons devoir préciser le paramètre de non-centralité # c&#39;est-a-dire notre prior # nous allons devoir faire l&#39;intégrale pour les différentes valeurs possibles # cette intégrale a approximativement un incrément de 1/100 entre chaque valeur entre -4 et 4 # le delta va être pondéré par la forme de la distribution Cauchy integrand &lt;- function(delta) { dt(tstat, df = n - 1, ncp = delta * sqrt(n)) * dcauchy(delta, scale = rscale) } # On peut faire l&#39;intégrale numérique de : p(D | H1) numerator &lt;- integrate(integrand, lower = -Inf, upper = Inf)$value # On peut obtenir le facteur de Bayes bf_manual &lt;- numerator / denominator bf_manual ## t ## 1144439 10.2 Ajuster nos probabilités Dans la section d’introduction aux facteurs de Bayes, nous avons évoqué le fait que le facteur de Bayes permettait d’ajuster de manière continue notre probabilité. Un outil intéressant pour à la fois comprendre cette idée mais également pour identifier la direction que prend le facteur de Bayes est de faire des analyses séquentielles. L’idée est qu’on va estimer le facteur de bayes pour un échantillon qui va d’un petit échantillon à la taille complète de l’échantillon dont on dispose, en choisissant de manière aléatoire les observations tant qu’on n’a pas atteint une taille d’échantillon N égale à la taille de l’échantillon pour lequel on a recueilli les données. Cette analyse permet de voir si le facteur de Bayes est dépendant de quelques observations où s’il s’agit d’une tendance générale qui se dessine. Nou pouvons reprendre notre exemple sur le QI pour illustrer cette idée. Pour pouvoir faire ces analsyes séquentielles, nous devons utiliser le package changeofevidence (Dechamps, 2025) qui intègre cette possibilité, ce qui à ma connaissance n’est pas le cas avec le package BayesFactor (Morey &amp; Rouder, 2024). Dans le package changeofevidence, on obtient la facteur de Bayes pour un test t avec la fonction bfttest. Il suffit ensuite de faire une représentation graphique de la sortie de résultats (voir Figure 10.1) library(changeofevidence) bf.exp &lt;- bfttest(QI, mu = 100, alternative = &quot;two.sided&quot;, prior.loc = 0, prior.r = sqrt(2)) ## | | | 0% | |===== | 7% | |========= | 13% | |============== | 20% | |=================== | 27% | |======================= | 33% | |============================ | 40% | |================================= | 47% | |===================================== | 53% | |========================================== | 60% | |=============================================== | 67% | |=================================================== | 73% | |======================================================== | 80% | |============================================================= | 87% | |================================================================= | 93% | |======================================================================| 100% plot(bf.exp) Figure 10.1: Représentation graphique des facteurs de Bayes séquentiels Pour comprendre l’intérêt de ce type d’analyse, il suffit de rajouter une observation qui serait aberrant, par exemple un QI à 40 et voir comment le facteur de Bayes évolue (voir Figure 10.2). QI2&lt;-c(QI, 40) bf.exp2 &lt;- bfttest(QI2, mu = 100, alternative = &quot;two.sided&quot;, prior.loc = 0, prior.r = sqrt(2)) ## | | | 0% | |==== | 6% | |========= | 12% | |============= | 19% | |================== | 25% | |====================== | 31% | |========================== | 38% | |=============================== | 44% | |=================================== | 50% | |======================================= | 56% | |============================================ | 62% | |================================================ | 69% | |==================================================== | 75% | |========================================================= | 81% | |============================================================= | 88% | |================================================================== | 94% | |======================================================================| 100% plot(bf.exp2) Figure 10.2: Représentation graphique des facteurs de Bayes séquentiels Cette manière d’analyse les données vous permet donc de vous assurer que votre facteur de Bayes ne dépend pas que de quelques observations qui feraient pencher la vraisemblance d’un côté ou de l’autre. 10.3 Tester une hypothèse nulle Nous avons évoqué le fait que le facteur de Bayes permettait de tester une hypothèse nulle car la vraisemblance peut être plus élvée pour l’hypothèse nulle que pour l’hypothèse alternative, ce qui n’était pas le cas pour l’approche de Neyman-Pearson (Neyman &amp; Pearson, 1933) car, non seulement, il y avait le risque de faux positifs à 5%, mais surtout parce que, dès lors que la taille d’échantillon augmente, on aura un effet significatif même pour de petits effets. Nous allons examiner ces deux cas de figures sous l’angle bayésiens en utilisant les mêmes paramètres que ceux utilisés précédemment. La seule différence est que nous allons travailler avec 20 000 échantillons plutôt que 200 000 car les temps de calculs sont considérablement allongés pour l’approche bayésienne. set.seed(1234) # le fait de mettre une graine assure une reproductibilité des résultats # on va créer une fonction qui compare deux moyennes qui sont strictement égales lorsque la condition vaut 0 et # dont les moyennes se différencient de 0,2 écart-type (d = 0.2) quand la condition vaut 1 # La fonction renvoie la probabilité du test t F2&lt;-function(cond = 0){ if(cond==0){ # on fait une comparaison de deux populations dont les moyennes sont strictement égales t.out&lt;-ttestBF(rnorm(n = 20, # taille de l&#39;échantillon 1 mean = 0, # moyenne du groupe 1 sd = 1), # écart-type de l&#39;échantillon 1 rnorm(n = 20, # taille de l&#39;échantillon 2 mean = 0,# moyenne du groupe 2 sd = 1) )# écart-type de l&#39;échantillon 2 }else{ t.out&lt;-ttestBF(rnorm(n = 20, # taille de l&#39;échantillon 1 mean = 0, # moyenne du groupe 1 sd = 1), # écart-type de l&#39;échantillon 1 rnorm(n = 20, # taille de l&#39;échantillon 2 mean = 0.2,# moyenne du groupe 2 sd = 1) ) # écart-type de l&#39;échantillon 2 } return(extractBF(t.out)$bf) # renvoie le FB } # on crée des données (200 000) : pour créer de manière aléatoire nos conditions. Elles sont au nombre de 200 000 # ici l&#39;échantillonnage se fait de manière équiprobable avec approximativement autant de situations pour la # condition différence qu&#39;absence de différence df&lt;-data.frame(condition = sample(0:1, 20000, #20000, replace=T )) # on applique la fonction F pour chacune des lignes du jeu de données (variable condition) df$BF&lt;-apply(df, 1, F2) df$sig1&lt;-if_else(df$condition==1 &amp; df$BF&gt;3 | df$condition==0 &amp; df$BF&lt;1/3, &quot;correct&quot;, if_else(df$condition==1 &amp; df$BF&lt;1/3 | df$condition==0 &amp; df$BF&gt;33, &quot;incorrect&quot;, &quot;manque de sensibilité&quot;)) table(df$condition, df$sig1) ## ## correct incorrect manque de sensibilité ## 0 3416 5 6599 ## 1 428 2847 6705 On constate que, avec ces paramètres, l’analyse va indiquer la plupart du temps (dans 66% des situations) que l’expérience manquent de sensibilité pour prendre une décision. Par ailleurs, l’hypothèse nulle n’est quasiment jamais rejetée à tort (5 situations). Enfin, le taux d’erreur est plus élevée pour la situation où la taille d’effet est de 0.2 et que le facteur de Bayes nous indique que nous avons des preuves en faveur de l’hypothèse nulle. Ce phénome est tout à fait cohérent avec l’approche bayésienne. En effet, il faut garder à l’esprit que l’absence totale d’effet n’existe jamais réellement mais que ce sont des approximations d’invariance (Cohen, 1994). Si une absence totale de différence est quasiment impossible, le fait est que certaines tailles d’effet sont tellement négligeables qu’on ne peut pas décemment avancer qu’elles représentent quelque chose qui ait du sens pour le domaine de recherche exploré. Il faut comprendre ici, que presque paradoxalement, Cette même taille d’effet pourrait être d’un intérêt substantiel dans un autre domaine. Il faut donc pouvoir mettre aussi en évidence cet effet minimal. Par exemple, en psychologie, on considérerait sans intérêt un effet qui toucherait par exemple qu’une personne sur 10000 mais il s’agit de la fréquence avec laquelle un jeune vacciné contre la covid pourrait développer une myocardite. Il s’agit donc d’un risque identifié pour le vaccin de la covid chez les jeunes et que ce risque est effectivement considéré comme un effet indésirable potentiel du vaccin contre la covid. La question qui se pose donc est de savoir si le facteur de Bayes fournit la décision appropriée dans ce genre de situations. Pour l’illustrer, nous allons faire une simulation similaire (les changements ont surtout vocation à réduire les temps de calcul) à celle relative sur une différence de 0.1 point sur un test de QI entre deux populations. F1&lt;-function(n){ t.out&lt;-ttestBF(rnorm(n, 100,15), rnorm(n, 100.1,15)) return(extractBF(t.out)$bf) } df&lt;-data.frame(n = rep(2^(1:20), 100)) df$bf&lt;-apply(df, 1, F1) df$Decision&lt;-if_else(df$bf&gt;3, &quot;Preuves en faveur de l&#39;alternative&quot;, if_else(df$bf&lt;1/3, &quot;Preuves en faveur de l&#39;hypothèse nulle&quot;, &quot;Manque de sensibilité&quot;)) df2&lt;-df %&gt;% group_by(n, Decision) %&gt;% summarize(Nombre= n()) ggplot(df2, aes(x=n, y=Nombre, colour =Decision))+geom_line()+ ylab(&quot;Nombre de décision précise (sur 100)&quot;) On se rend compte qu’avec la même simulation que celle que nous avons utilisée précédemment, le facteur de Bayes pour des tailles d’échantillon modérée, voire grande, va favoriser l’hypothèse nulle mais, avec des échantillons énormes, le facteur de Bayes va pencher en faveur d’un effet réel. Remarquez la différence de comportement par rapport à l’approche fréquentiste où le nombre d’effets significatifs augmentait de manière proportionnelle à la taille de l’échantillon. Qu’est-ce que cela signifie : si on s’intéresse à des effets raisonnablement importants, des tailles d’échantillons de quelques dizaines, voire de quelques centaines de participants vont favoriser l’hypothèse nulle si la taille d’effet observée est effectivement ridicule. En revanche, si on s’intéresse à de toutes petites tailles d’effet, on sait qu’il faudra un échantillon conséquent pour le mettre en évidence (sans doute plusieurs milliers de données) et, dans ce cas, le FB sera en mesure de le mettre en évidence. Pour Rouder et al. (2009), ce comportement est idéal : avec les petites tailles d’échantillon, on n’a pas assez d’informations pour distinguer une absence totale d’effet d’un effet extrêmement petit, ce qui permettra au chercheur et à la chercheuse d’accumuler des preuves en faveur de l’hypothèse nulle et avec de très larges échantillons, le facteur de Bayes permet de découvrir de très petits effets. Pour le formuler autrement : le facteur de Bayes favorise un modèle plus parcimonieux, à savoir l’absence de différence, à moins que l’échantillon soit si large que même des petits effets ne sont pas compatibles avec l’hypothèse nulle. Dans la section sur les effets négligeables, nous avions donné l’exemple d’une étude publiée où une corrélation de 0.08 était significative parce que l’échantillon était tout de même conséquent. Si on essaie de reproduire au mieux les données, qu’observe-t-on avec une approche bayésienne ? library(BayesFactor) library(MASS) library(tidyverse) set.seed(46) # create the variance covariance matrix sigma&lt;-rbind(c(1,0.08), c(0.08,1)) # create the mean vector mu&lt;-c(76.51, 51.45 ) # generate the multivariate normal distribution df&lt;-as.data.frame(mvrnorm(n=526, mu=mu, Sigma=sigma)) cor.test(df[,1], df[,2]) ## ## Pearson&#39;s product-moment correlation ## ## data: df[, 1] and df[, 2] ## t = 1.9706, df = 524, p-value = 0.04929 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.0002779501 0.1700172554 ## sample estimates: ## cor ## 0.08576994 corrBF&lt;-correlationBF( y= df[,1], x=df[,2], rscale = &quot;ultrawide&quot; ) corrBF ## Bayes factor analysis ## -------------- ## [1] Alt., r=1 : 0.3752612 ±0% ## ## Against denominator: ## Null, rho = 0 ## --- ## Bayes factor type: BFcorrelation, Jeffreys-beta* On voit ici qu’avec un facteur de Bayes de 0.375 on a quasiment un rapport de 1/3, donc des preuves en faveur de l’hypothèse nulle. Ces données sont beaucoup plus cohérentes pour interpréter une validité divergente. 10.4 Rôle de l’a priori sur le Bayes factor Nosus avons évoqué le fait que certaines personnes pouvaient être mal à l’aise avec l’idée que les résultats puissent dépendre de notre opinion plutôt que des faits objectifs. Une manière simple de répondre à ce problème est de mener un analyse robuste. Concrètement, celle-ci consiste à examener la valeur de facteur de Bayes pour différentes hypothèses a priori et s’assurer que le choix que vous avez fait n’influence pas de manière drastique vos résultats. Le package BayesFactor (Morey &amp; Rouder, 2024) ne fournit pas de fonction permettant d’obtenir directement l’analyse robuste. Cependant, cela ne représente quelque chose de très difficile à faire. Le code annoté explique étape par étape commentaire. # on commencer par établir la liste de prior que nous souhaitons tester # ici c&#39;est une séquence qui va de 0.05 à 2, avec un accent particulier # sur les prior prédéfinis de dans le package BayesFactor (0.5,0.707, 1,1.41) rs &lt;- c(seq(from = .05, to =2, by = 0.05), 0.5, 0.707, 1, 1.41) # on veut pouvoir les calculer tous en même temps. # pour cela, on va utiliser la fonction sapply qui va # calculer le Bayes Factor pour tous les priors qu&#39;on va lui donner (stockés dans rs) bfs &lt;- sapply(rs, function(r) { # on crée un fonction spécifiquement pour notre propos # on utilise exactement la même fonction que celle qu&#39;on utilise pour un seul BF # mais au lieu de donner une valeur au rscale, on lui donne l&#39;argument r # qui seront fourni par tous les rs bf &lt;- ttestBF(x = QI, mu = 100, rscale = r) # on extrait les facteurs de Bayes extractBF(bf)$bf }) # on crée un data.frame pour faire le graphique robust&lt;-data.frame(rs, bfs) # on réalise le graphique # on fait la ligne qui touche tous les points ggplot(robust, aes(x=rs, y=bfs))+geom_line()+ # on donne le titre à l&#39;axe des x xlab(&quot;Choix de la distribution a priori&quot;)+ # on donne le titre à l&#39;axe des y ylab(&quot;Valeur du facteur de Bayes&quot;)+ # on met en valeur les points des priors prédéfinis dans BayesFactor geom_point(data=robust[41:44,], colour=&quot;blue&quot;)+ # On indique sur le graphique à quel prior chaque point correspond * # en faisant un petit décalage afin d&#39;éviter une superposition avec le point annotate(&quot;text&quot;, label = robust$rs[41:44], x = robust$rs[41:44], y = robust$bfs[41:44]+1, colour =&quot;blue&quot;, check_overlap = TRUE) Figure 10.3: Graphique représentant les facteurs de Bayes calculés pour différents prior. Cette analyse est connue sous le nom d’analyse de robustesse. # note les Bayes Factor sont sur une échelle qui permet de les représenter #en valeur #brute. Il peut être utile de faire une transformation logarithmique lorque # leur valeur est très élevée. Dans ce graphique, on observe que, peu importe la distribution a priori choisie parmi les prior par défaut du package BayesFactor (Morey &amp; Rouder, 2024), on dispose de preuves substantielles en faveur de l’existence d’une différence. Si le code ci-dessus est directement adaptable en fonction des situations, dans le package changeofevidence (Dechamps, 2025), Moritz a développé des fonctions qui permettaient de le faire soit pour un test t ou pour une corrélation. Comme nous avions déjà utilisé ce package précédemment, on peut réutiliser l’objet créé et le passer directement à la fonction bfRobustness. bf.robust &lt;- bfRobustness(bf.exp2) ## Highest BF = 102.73 with prior: Cauchy(0.85, 0.05) plot(bf.robust) Figure 10.4: Analyses de robustesse avec le package changeofevidence Les réultats ne sont pas identique à l’analyse précédente car la fonction permet d’utiliser deux paramètres pour préciser la distribution a priori : la variance du prior, comme dans le package BayesFactor mais également la localisation de la taille d’effet, ce qui n’est pas le cas dans le package BayesFactor. La bande représente la zone dans laquelle les BayesFactor peut se situer en fonction de la combinaison des deux paramètres. Pour reproduire le même graphique que celui que précédemment obtenu, on peut préciser que prior.loc est égal à 0, comme dans le package BayesFactor. . bf.robust &lt;- bfRobustness(bf.exp2, prior.loc=0) ## Highest BF = 16.27 with prior: Cauchy(0, 0.7) plot(bf.robust) Figure 10.5: Analyses de robustesse avec le package changeofevidence pour un prior de localisation fixé à 0. References Caldwell, A. R. (2022). Exploring equivalence testing with the updated TOSTER r package. https://doi.org/10.31234/osf.io/ty8de Cohen, J. (1994). The earth is round (p &lt; 05). American Psychologist, 49(12), 997–1003. https://doi.org/10.1037/0003-066x.49.12.997 Dechamps, M. (2025). Changeofevidence: Change of evidence. https://github.com/mrzdcmps/changeofevidence Lakens, D. (2017). Equivalence tests: A practical primer for t tests, correlations, and meta-analyses. Social Psychological and Personality Science, 8(4), 355–362. https://doi.org/10.1177/1948550617697177 Lakens, D., Scheel, A. M., &amp; Isager, P. M. (2018). Equivalence testing for psychological research: A tutorial. Advances in Methods and Practices in Psychological Science, 1(2), 259–269. https://doi.org/10.1177/2515245918770963 Morey, R. D., &amp; Rouder, J. N. (2024). BayesFactor: Computation of bayes factors for common designs. https://CRAN.R-project.org/package=BayesFactor Neyman, J., &amp; Pearson, E. S. (1933). Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231(694–706), 289–337. https://doi.org/10.1098/rsta.1933.0009 Peirce, C. S. (1877). The fixation of belief. Popular Science Monthly, 12, 1–15. Popper, K. (1963). Conjectures and refutations: The growth of scientific knowledge. Routledge; Kegan Paul. Rouder, J. N., Speckman, P. L., Sun, D., Morey, R. D., &amp; Iverson, G. (2009). Bayesian t tests for accepting and rejecting the null hypothesis. Psychonomic Bulletin &amp;Amp; Review, 16(2), 225–237. https://doi.org/10.3758/pbr.16.2.225 Wagenmakers, E.-J., Wetzels, R., Borsboom, D., &amp; Maas, H. L. J. van der. (2011). Why psychologists must change the way they analyze their data: The case of psi: Comment on bem (2011). Journal of Personality and Social Psychology, 100(3), 426–432. https://doi.org/10.1037/a0022790 les formules exactes utilisées dans l’approche bayésienne n’ont pas d’importance pour la compréhension. Le point critique est de comprendre que la vraisemblance est la probabilité d’observer les données pour une hypothèse donnée.↩︎ pour ceux et celles peu à l’aise avec les intégrales, l’idée dans le cas présent est de calculer une surface qui n’est pas simple à calculer puisque c’est une ditribution, il faut donc découper cette distribution en une multitude de batonnets qui vont se rapprocher chacune d’un rectangle. Le calcul de la surface d’un rectangle étant facile à faire, il suffira d’additionner la surface de cette multitude de rectangles↩︎ "],["comparaison-avec-lapproche-fréquentiste.html", "Chapter 11 Comparaison avec l’approche fréquentiste", " Chapter 11 Comparaison avec l’approche fréquentiste Dans la partie consacrée au rappel sur l’approche de Neyman-Pearson(Neyman &amp; Pearson, 1933), nous avons vu que nous connaissions le taux d’erreurs de Type I ou de Type II que nous allions commettre. Ces taux d’erreurs sont connus dès lors que nous connaissons les conditions exactes de l’expérimentation mais toute modification qui n’a pas été annoncée va modifier ce taux d’erreurs. Parmi les facteurs (et sans doute sans être exhaustif) qui vont changer les choses, on a : le rajout d’observations ; des changements dans le plan d’analyse ; le fait de faire des analyses multiples sans corriger la probabilité ; le moment de l’explication, à savoir si l’hypothèse a été faite avant ou après avoir regardé les données. Dans l’approche bayésienne, on ne connait pas le taux d’erreur exact car il dépend de plusieurs paramètres comme la taille de l’échantillon, la distribution a priori, ou encore des seuils utilisé pour interpréter le facteur de Bayes13. En revanche, le fait de modifier le plan d’analyse, de fournir une explication avant ou après avoir recueilli les données ou encore de rajouter des observations quand l’expérimentation n’est pas assez disriminante sont des élements qui n’ont aucune importance sur les décisions qu’on va prendre. Tout est dans les données. Reprenons l’exemple du lancer de dé : on a eu 10 fois 6 sur 20 lancers, est-ce que faire l’hypothèse après avoir vu le résultat ou avant d’avoir lancé le dé change réellement le fait que le dé est probablement pipé ? Pour les Bayésiens, ce n’est pas le cas. Pour l’approche de Neyman-Pearson, cela a de l’importance. Une difficulté qui freine souvent des personnes à adopter une approche bayésienne est qu’on a le sentiment que cette approche dépend des opinions qu’on peut avoir concernant une hypothèse. Si ce n’est pas tout à fait faux, il faut se rappeler que la vraisemblance va au final dominer et que, même dans l’approche de Neyman-Pearson vous devez le faire : quand vous calculez la puissance de votre étude, vous devez vous faire une idée de la taille d’effet que vous devriez ou aimeriez avoir pour que l’étude ait du sens. Finalement, est-ce réellement différent ? Dans l’approche de Neyman-Pearson, le niveau de précision est apporté par l’intervalle de confiance. L’équivalent dans l’approche bayésienne est l’intervalle de crédibilité. Au final, les deux approches ont des avantages et des inconvénients à vous d’identifier leur complémentarité ou de savoir quelle approche vous convient le mieux. References Dienes, Z. (2008). Understanding psychology as a science: An introduction to scientific and statistical inference (1st ed., p. 184). Bloomsbury Academic / Red Globe Press. Neyman, J., &amp; Pearson, E. S. (1933). Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231(694–706), 289–337. https://doi.org/10.1098/rsta.1933.0009 rappelez-vous que les balises fournies précédemment ne sont que des balises, c’est à vous de décider si le rapport est important ou non pour vous. Si 3 vous convient, alors c’est bien mais cela peut être un autre seuil. Dienes (Dienes, 2008) recommande par exemple à un seuil de 4.↩︎ "],["exercices.html", "Chapter 12 Exercices 12.1 Exemples de démonstration 12.2 Exercice 2 12.3 Exercice 3 12.4 Exercice 4 12.5 Exercice 5 12.6 t de Student 12.7 Une corrélation 12.8 Une anova", " Chapter 12 Exercices 12.1 Exemples de démonstration Dans le cadre de cet atelier, nous allons montrer comment faire un t de Student, un corrélation, une analyse de variance et un modèle linéaire. Pour chaque analyse, un exemple (qui peut être fictif) qui servira à illustrer la manière dont les fonctions doivent être utilisées. Les données de ces exemples sont disponibles dans le fichier données Demo.xls 12.1.1 Le t de Student Des chercheurs se sont demandé si le TOLD-P:3 permettait de discriminer des enfants présentant différentes formes de dysphasies. Ils ont comparé les scores obtenus par 50 enfants présentant une dysphasie phonologico-syntaxique (PS, les enfants présentent des difficultés pour s’exprimer) aux scores obtenus par 50 enfants présentant une dysphasie sémantique pragmatique (SP, les enfants présentent des troubles lexicaux) à ce tests. Les données sont disponibles sur la feuille TOLD. 12.1.1.1 Avec R On suppose que les packages sont chargés. On commence par importer les données avec la fonction read_xlsx du package readxl (Wickham &amp; Bryan, 2025). TOLD&lt;-read_xlsx(&quot;./Exercices/Demo.xlsx&quot;, sheet=&quot;TOLD&quot;) On vérifie le jeu de données. En particulier, on s’assure que les données soient considérées comme un data.frame et que les variables str(TOLD) ## tibble [100 × 3] (S3: tbl_df/tbl/data.frame) ## $ groupe: chr [1:100] &quot;PS&quot; &quot;PS&quot; &quot;PS&quot; &quot;PS&quot; ... ## $ TOLD : num [1:100] 93 117 113 102 91 89 83 109 100 86 ... ## $ CASL : num [1:100] 44 65 54 50 42 48 52 64 57 57 ... En l’occurrence, le jeu de données est à la fois un tibble et un data.frame. Cela ne devrait pas poser de souci. En revanche, le fait que la variable groupe soit considérée comme du caractère risque de générer un message d’erreur. On la transforme en facteur grâce à la fonction as.factor. TOLD$groupe&lt;-as.factor(TOLD$groupe) str(TOLD) ## tibble [100 × 3] (S3: tbl_df/tbl/data.frame) ## $ groupe: Factor w/ 2 levels &quot;PS&quot;,&quot;SP&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ TOLD : num [1:100] 93 117 113 102 91 89 83 109 100 86 ... ## $ CASL : num [1:100] 44 65 54 50 42 48 52 64 57 57 ... On regarde les statistiques descriptives pour pouvoir interpréter les données. Il y a de nombreuses manière de le faire. J’utilise généralement la fonction describe du package psych (William Revelle, 2025) mais n’importe quelle autre fonction fournissant les statistiques descriptives fait l’affaire. psych::describeBy(TOLD ~groupe, data= TOLD,mat=T) ## item group1 vars n mean sd median trimmed mad min max range ## TOLD1 1 PS 1 50 97.70 8.944842 98 97.425 10.3782 83 117 34 ## TOLD2 2 SP 1 50 86.62 8.886794 85 86.300 10.3782 73 103 30 ## skew kurtosis se ## TOLD1 0.1361170 -1.024715 1.264992 ## TOLD2 0.2100576 -1.126223 1.256782 On utilise la fonction ttestBF du package BayesFactor (Morey &amp; Rouder, 2024) pour obtenir le facteur de Bayes. Les différents arguments sont expliqués par des comentaires dans le code. t.out&lt;-ttestBF(# formule du type VD ~ VI formula =TOLD ~groupe, # nom du jeu de données data=TOLD, paired =F, # l&#39;argument mu permet d&#39;indiquer une norme, notamment dans # les t avec un seul échantillon # cet argument n&#39;est pas pris en compte si on a une formule # et que la valeur vaut 0 mu = 0, # distribution a priori à .707 rscale = .707, # faut il calculer la distribution a posteriori (F =non) posterior = F) t.out ## Bayes factor analysis ## -------------- ## [1] Alt., r=0.707 : 796968 ±0% ## ## Against denominator: ## Null, mu1-mu2 = 0 ## --- ## Bayes factor type: BFindepSample, JZS Il est à noter qu’on peut également utiliser la fonction bfttest du package changeofprediction (Dechamps, 2025) Son mode de fonctionnement est assez similaire. Il y a deux différences : il est possible de préciser si on veut une hypothèse unilatérale ou bilatérale et on peut fixer un a priori sur la localisation de la taille d’effet. bf.exp &lt;- bfttest(TOLD ~groupe, , data= TOLD, alternative = &quot;two.sided&quot;, prior.loc = 0, prior.r = sqrt(2)) ## | | | 0% | |= | 2% | |=== | 4% | |==== | 6% | |====== | 8% | |======= | 10% | |========= | 12% | |========== | 14% | |=========== | 16% | |============= | 18% | |============== | 20% | |================ | 22% | |================= | 24% | |=================== | 27% | |==================== | 29% | |===================== | 31% | |======================= | 33% | |======================== | 35% | |========================== | 37% | |=========================== | 39% | |============================= | 41% | |============================== | 43% | |=============================== | 45% | |================================= | 47% | |================================== | 49% | |==================================== | 51% | |===================================== | 53% | |======================================= | 55% | |======================================== | 57% | |========================================= | 59% | |=========================================== | 61% | |============================================ | 63% | |============================================== | 65% | |=============================================== | 67% | |================================================= | 69% | |================================================== | 71% | |=================================================== | 73% | |===================================================== | 76% | |====================================================== | 78% | |======================================================== | 80% | |========================================================= | 82% | |=========================================================== | 84% | |============================================================ | 86% | |============================================================= | 88% | |=============================================================== | 90% | |================================================================ | 92% | |================================================================== | 94% | |=================================================================== | 96% | |===================================================================== | 98% | |======================================================================| 100% L’intérêt de cette dernière fonction est qu’elle permet d’obtenir directement les analyses séquentielles grâce à la fonction plot. plot(bf.exp) et de robustesse avec la fonction bfRobustness. bf.robust &lt;- bfRobustness(bf.exp,prior.loc =0 ) ## Highest BF = 886969.2 with prior: Cauchy(0, 1) plot(bf.robust) Il est également possible d’adapter le code que j’ai utilisé dans le chapitre sur le Facteur de Bayes 12.1.1.2 Avec Jamovi Pour faire un t de Student avec Jamovi, on clique sur le menu t et on choisit le type de t de l’approche bayésienne qui nous convient. On choisit les variables de façon similaire à ce qui est fait pour l’approche de Neyman-Pearson. On coche les cases qui nous permettront d’avoir les analyses séquentielles et les analyses de robustesse. Et on fixe la valeur pour la distribution a priori. Pour les résultats, ils sont théoriquement identiques (ou très proches à ceux présentés dans la section R). 12.1.2 La corrélation Kainafets et Relfihcs (5022) se sont intéressés à l’impact de la télévision sur les stéréotypes. Ils émettent l’hypothèse selon laquelle un programme de télévision peut avoir un impact prosocial. Pour tester leur hypothèse, ils proposent à leurs participants de regarder une fiction dans laquelle des personnes issues de différentes minorités voyagent dans l’espace à la recherche d’une planète qui permettrait à l’espèce humaine de survivre. Durant la fiction, plusieurs difficultés s’opposent à cet objectif. Les protagonistes arrivent néanmoins à résoudre ces problèmes, mais uniquement lorsque les différentes minorités agissent de concert avec le groupe majoritaire. Après la fiction, les chercheurs demandent aux participants de choisir parmi 50 descriptions de personnes (dont la moitié sont issues de minorités et l’autre moitié du groupe majoritaire), celles avec lesquelles elles voudraient collaborer pour construire une maison. Sur chacune des descriptions, une photo de la personne décrite était présentée en plus des habiletés et des diplômes obtenus. Après avoir décidé quelles étaient les personnes avec lesquelles elles aimeraient collaborer pour la construction d’une maison, les participants étaient invités à évaluer sur une échelle de 1 à 7 (de pas du tout probable à très probable), la plausibilité de la fiction présentée dans la première phase de l’étude. L’hypothèse des chercheurs est que les personnes qui trouveront la fiction plausible seront plus enclines à choisir des collaborateurs issus de minorités pour la construction de la maison. En plus de l’évaluation de la plausibilité, les chercheurs ont recueilli le nombre de personnes issues de minorités dans le choix des collaborateurs choisis par les 35 participants qui ont pris part à l’étude. Les données sont présentées sur la feuille plausibilite. Pour cet exercice, nous illustrerons comment obtenir une distribution a posteriori. Le raisonnement vaut également pour les autres fonctions décrites dans ce tutoriel. 12.1.2.1 Avec R On commence par importer les données plausib&lt;-read_xlsx(&quot;./Exercices/Demo.xlsx&quot;, sheet=&quot;plausibilite&quot;) On vérifie la structure des données. str(plausib) ## tibble [35 × 2] (S3: tbl_df/tbl/data.frame) ## $ Plaus : num [1:35] 6 5 3 3 5 1 3 6 6 3 ... ## $ collab: num [1:35] 30 28 17 34 25 10 16 32 31 17 ... On peut se faire une représentation graphique pour avoir une idée de l’existe ou non d’une corrélation et éventuellement identifier des valeurs influentes. ggplot(plausib, aes(x = Plaus , y =collab) )+ geom_point()+ stat_smooth(method = &quot;lm&quot;, formula = y ~ x, geom = &quot;smooth&quot;) on fait l’analyse l’analyse avec la fonction correlationBF pour laquelle les arguments sont expliqués dans le code. corr.out&lt;-correlationBF( # la variable sur l&#39;ordonnée y=plausib$Plaus, # la variable en abcisse x=plausib$collab, # la distribution a priori rscale = &quot;medium&quot;, # les limites inférieures et supérieures # d&#39;un intervalle à l&#39;intérieur duquel # on pense que se trouve la corrélation nullInterval = NULL, # Faut il calculer la distribution a posteriori posterior = F) corr.out ## Bayes factor analysis ## -------------- ## [1] Alt., r=0.333 : 1477275 ±0% ## ## Against denominator: ## Null, rho = 0 ## --- ## Bayes factor type: BFcorrelation, Jeffreys-beta* On peut à présent calculer l’intervalle de crédibilité. Deux méthodes peuvent être utilisées pour atteindre cet objectif. # calcul de la distribution a posteriori post&lt;-posterior(corr.out, iterations = 1000) plot(post) summary(post) ## ## Iterations = 1:1000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 1000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## rho 0.7385 0.08045 0.002544 0.007256 ## zeta 0.9706 0.17905 0.005662 0.014835 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## rho 0.5429 0.6888 0.750 0.8005 0.8622 ## zeta 0.6083 0.8456 0.973 1.1000 1.3020 On peut également utiliser le package bayestestR (Makowski et al., 2019) library(bayestestR) ci_hdi &lt;- ci(post, method = &quot;HDI&quot;) ci_hdi ## Highest Density Interval ## ## Parameter | 95% HDI ## ------------------------ ## rho | [0.60, 0.89] ## zeta | [0.60, 1.26] Il est tout à fait normal que les résultats ne soient pas identiques, les méthodes pour les calculer peuvent être sensiblement différentes et parce que les résultats sont obtenus en utilisant un chaîne de Monte-Carlo, c’est-à-dire une simulation. Il est à noter qu’on peut adapter le code présenté dans la section relative aux analyses de robustesse pour l’appliquer à ce contexte. #les 4 dernières valeurs sont les valeurs &quot;réduite&quot;, #&quot;moyenne&quot;, &quot;large&quot; et &quot;ultra large&quot; rs &lt;- c(seq(from = .05, to =2, by = 0.05), 1/sqrt(27), 1/3, 1/sqrt(3), 1) # on veut pouvoir les calculer tous en même temps. # pour cela, on va utiliser la fonction sapply qui va # calculer le Bayes Factor pour tous les priors qu&#39;on va lui donner (stockés dans rs) bfs &lt;- sapply(rs, function(r) { # on crée un fonction spécifiquement pour notre propos # on utilise exactement la même fonction que celle qu&#39;on utilise pour un seul BF # mais au lieu de donner une valeur au rscale, on lui donne l&#39;argument r # qui seront fourni par tous les rs bf &lt;- correlationBF(y=plausib$collab, x=plausib$Plaus, rscale = r, nullInterval = NULL, posterior = F) # on extrait les facteurs de Bayes extractBF(bf)$bf }) # on crée un data.frame pour faire le graphique robust&lt;-data.frame(rs, bfs) # on réalise le graphique robust$bfs&lt;-round(robust$bfs, 3) robust$rs&lt;-round(robust$rs, 3) # on fait la ligne qui touche tous les points ggplot(robust, aes(x=rs, y=bfs))+geom_line()+ # on donne le titre à l&#39;axe des x xlab(&quot;Choix de la distribution a priori&quot;)+ # on donne le titre à l&#39;axe des y ylab(&quot;Valeur du facteur de Bayes&quot;)+ # on met en valeur les points des priors prédéfinis dans BayesFactor geom_point(data=robust[41:44,], colour=&quot;blue&quot;)+ # On indique sur le graphique à quel prior chaque point correspond * # en faisant un petit décalage afin d&#39;éviter une superposition avec le point annotate(&quot;text&quot;, label = robust$rs[41:44], x = robust$rs[41:44]+0.2, y = robust$bfs[41:44]+0.2, colour =&quot;blue&quot;, check_overlap = TRUE) Notez qu’ici, utiliser une échelle logarithmique sur le graphique aurait pu faire sens. 12.1.2.2 Avec Jamovi On commence par choisir le menu corrélation bayésienne par paire. On indique les variables d’intérêt. On coche tous les options en n’oubliant pas de préciser la distribution a priori. Dans le package BayesFactor, une distrubtion étroite vaut \\(1/\\sqrt{27}\\), une moyenne vaut 1/3, une large vaut \\(1/\\sqrt{3}\\) et une ultra large vaut 1. Pour répliquer les résultats, il faut une distribution de 1/3. 12.1.3 La régression Faire une régression sous l’angle bayésien ne présente pas de réelle particularité par rapport au fait de faire une corrélation ou un test t. Des chercheurs s’intéressent au niveau de détresse émotionnelle et formulent l’hypothèse selon laquelle la détresse serait inversement reliée à l’adoption de stratégies de coping. Ces chercheurs demandent à leurs participants d’évaluer sur une échelle de 1 (pas du tout) à 7 (en totale détresse) leur niveau de détresse émotionnelle. Ils leur demandent ensuite d’expliquer les comportements qu’ils adoptent lorsqu’ils ne se sentent pas bien. Les chercheurs attendent 30 réponses. Une fois, les réponses récoltées, ils comptent le nombre de comportements de coping. Par ailleurs, les chercheurs ont également utilisé une échelle d’anxiété sur 50 et ont demandé l’âge des participants. 12.1.3.1 Avec R On commence par importer les données detresse&lt;-read_xlsx(&quot;./Exercices/Demo.xlsx&quot;, sheet=&quot;detresse&quot;) On vérifie la structure des données. str(detresse) ## tibble [69 × 3] (S3: tbl_df/tbl/data.frame) ## $ detresse: num [1:69] 4 5 3 4 5 3 4 4 7 1 ... ## $ coping : num [1:69] 7 6 10 7 8 9 4 5 27 11 ... ## $ age : num [1:69] 70 56 76 75 84 54 55 54 66 59 ... On peut se faire une représentation graphique pour avoir une idée de l’existe ou non d’une corrélation et éventuellement identifier des valeurs influentes. Le package olsrr permet d’obtenir des graphiques des effets conditionnels dans les modèles linéaires fréquentistes. La représentation graphique n’étant pas dépendante de l’approche, on peut l’utiliser sans souci. library(olsrr) model&lt;-lm(detresse~coping+age, detresse) ols_plot_added_variable(model) on fait l’analyse l’analyse avec la fonction lmBF pour laquelle les arguments sont expliqués dans le code. lm.out&lt;-lmBF( # on précise le modèle du type VD ~VI1+VI2 # on peut mettre des interactions VD ~VI1+VI2+VI1:VI2 formula = detresse~coping+age, # on précise le jeu de données data = detresse, # on peut préciser la variable aléatoire # sous forme de caractère comme &quot;ID&quot; whichRandom = NULL, # on peut préciser les ditributions pour les effets d&#39;intérêts rscaleFixed = &quot;medium&quot;, # et contrôler la distribution de la variable aléatoire # on peut toujours laisser la valeur par défaut rscaleRandom = &quot;nuisance&quot;, # il s&#39;agit du prior sur la pente # mais la différence par rapport à rscaleFixed n&#39;est pas claire. # il est possible que rscaleFixed s&#39;applique à tout # et que rscalecont et rscaleRandom permet de dissocier les deux rscaleCont = &quot;medium&quot;, # il est possible de préciser des prior pour chaque effet # par exemple c(coping = 0.5, age =0.3) # on ne précise pas ici rscaleEffects = NULL, # la distribution a posteriori doit elle être calculée. posterior = FALSE) lm.out ## Bayes factor analysis ## -------------- ## [1] coping + age : 5902276 ±0% ## ## Against denominator: ## Intercept only ## --- ## Bayes factor type: BFlinearModel, JZS On observe que nous avons le facteur de Bayes pour l’ensemble des effets du modèle. Pour avoir les effets séparément et voir dans quelle mesure une variable apporte quelque chose au modèle, il faut modéliser chacun des modèles. Par exemple, quand on veut savoir si l’âge apporte quelque chose de plus que le coping, on peut faire : lm.out1&lt;-lmBF( formula = detresse~coping, data = detresse, whichRandom = NULL, rscaleFixed = &quot;medium&quot;, rscaleRandom = &quot;nuisance&quot;, rscaleCont = &quot;medium&quot;, rscaleEffects = NULL, posterior = FALSE) lm.out2&lt;-lmBF( formula = detresse~coping+age, data = detresse, whichRandom = NULL, rscaleFixed = &quot;medium&quot;, rscaleRandom = &quot;nuisance&quot;, rscaleCont = &quot;medium&quot;, rscaleEffects = NULL, posterior = FALSE) lm.out2/lm.out1 ## Bayes factor analysis ## -------------- ## [1] coping + age : 448076.1 ±0% ## ## Against denominator: ## detresse ~ coping ## --- ## Bayes factor type: BFlinearModel, JZS En l’occurrence, le facteur de Bayes est très largement supérieur à 100, on sait que l’âge a un apport important au modèle. 12.1.3.2 Avec Jamovi Dans Jamovi, on peut faire des modèles linéaires avec l’approche bayésienne en cliquant sur Bayesian Linear Regression. Il permet de faire des modèles simples (sans interaction) en entrant les variables du côté de la variable dépendante et des covariables. Les résultats permettent de comparer le facteur de Bayes d’un modèle donné par rapport au modèle où il n’y a que la variable aléatoire (non spécifiée) ou par rapport au meilleur modèle. En réalité, dans l’approche bayésienne, on veut pouvoir savoir si une variable particulière apporte quelque chose par rapport à des variables qu’on impose dans le modèle. Il faut donc pouvoir faire le rapport des facteurs de Bayes (ce qui donne également un facteur de Bayes) mais ce n’est pas possible dans Jamovi. Jamovi propose de montrer les 10 meilleurs modèles pour ne pa montrer tous les modèles car le nombre de modèles augmente de manière exponentielle avec le nombre de variables (en suivant la règle \\(n^2-1\\) où n est le nombre de variables) Il y a d’autres options disponibles mais elles semblent être encore en développement dans ma version (2.6.44) et ne fournissent pas de résultats. 12.1.4 L’analyse de variance Stefaniak et al. (Stefaniak et al., 2008) se sont intéressés aux mécanismes d’apprentissage implicite. Ils ont administré à leurs participants une tâche de temps de réaction sériel. Dans cette tâche, on demande aux participants de répondre le plus rapidement et le plus précisément possible aux stimuli qui apparaissent à différentes localisation sur l’écran. Les stimuli n’apparaissent pas de manière aléatoire mais suivent, à l’insu des participants, une séquence. Cette séquence suit une structure probabilité (85% de régularités et 15% d’irrégularités) La tâche est composée de 15 blocs dans lesquels la séquence est présentée à 8 reprises. Les blocs 1 à 12 sont des blocs d’apprentissage. Le bloc 13 est un bloc dans lequel une autre séquence que la séquence d’apprentissage est utilisée et le bloc 14 est à nouveau un bloc où la séquence d’apprentissage initiale est utilisée. L’apprentissage se manifeste par des temps de réaction de plus en plus courts entre les blocs 1 à 12 et un ralentissement de la vitesse de réponse pour le bloc 13. Leur objectif était de voir si une connaissance explicite de la séquence améliorait l’apprentissage. Ils ont donc comparé l’apprentissage pour un groupe en condition incidente, un groupe dont les connaissances se limitait à la séquence régulière et un groupe qui avait non seulement la connaissance de la séquence régulière mais également de la manière dont les irrégularités étaient construites. 12.1.4.1 Avec R Nous n’allons pas reprendre les étapes de bases et les réexpliquer. Ce sont toujours les mêmes. Nous focaliserons sur la préparation du jeu de données et sur la réalisation de l’analyse. Tout d’abord, il faut préparer les données car, pour des mesures répétées, R a besoin d’un format long et non d’un format large14. Pour ce faire, on va sélectionner les variables d’intérêt avec le package dplyr (Wickham et al., 2023) et sa fonctioin select et utiliser la fonction melt du package reshape2 (Wickham, 2007). important : comme plusieurs fonction dans R s’appelle ‘select’, il peut être bon de préciser dans quelle package il faut aller chercher cette fonction entre tapant le nom du package suivi de deux fois deux points dplyr::select. library(reshape2) AI2&lt;-AI %&gt;% dplyr::select(TYPE, BLOC1, BLOC12, BLOC13) AI.long&lt;-melt(AI2,id.vars=&quot;TYPE&quot;) names(AI.long)&lt;-c(&quot;TYPE&quot;, &quot;BLOC&quot;, &quot;Temps&quot;) AI.long$TYPE&lt;-as.factor(AI.long$TYPE) Il est souvent bon d’être explicite sur la variable aléatoire quand on fait des anovas, en particulier des anovas à mesure répétées. Nous allons donc rajouter une variable identifiant les participants. AI.long$ID&lt;-rep(paste0(&quot;p&quot;,1:60), 3) AI.long$ID&lt;-as.factor(AI.long$ID) On peut à présent réaliser l’analyse aov.out&lt;- generalTestBF(# on précise le modèle # remarquez la présence de l&#39;identifiant dans le modèle # R en a besoin pour identifier que c&#39;est une mesure répétée Temps ~ TYPE*BLOC + ID, data = AI.long, # on explicite ici que ID est le facteur aléatoire whichRandom = &quot;ID&quot;, # pour éviter de multiplier les modèle calculés # on va conserver la variable aléatoire dans tous # les modèles # cela évite d&#39;avoir VD~ID, VD~VI1, VD~ID+VI1 neverExclude=&quot;ID&quot;) aov.out ## Bayes factor analysis ## -------------- ## [1] TYPE + ID : 62469120306 ±0.71% ## [2] BLOC + ID : 867788093218138308002666860 ±0.95% ## [3] TYPE + BLOC + ID : 647737570786917884260024882 ±3.79% ## [4] TYPE + BLOC + TYPE:BLOC + ID : 247996970907350544346868868 ±1.5% ## [5] ID : 102575400468 ±0% ## ## Against denominator: ## Intercept only ## --- ## Bayes factor type: BFlinearModel, JZS Pour savoir si l’effet d’interaction apporte quelque chose au modèle, on compare le modèle avec l’interaction (modèle 4) avec le modèle le plus proche sans l’interaction (modèle 3) aov.out[4]/aov.out[3] ## Bayes factor analysis ## -------------- ## [1] TYPE + BLOC + TYPE:BLOC + ID : 0.3828664 ±4.08% ## ## Against denominator: ## Temps ~ TYPE + BLOC + ID ## --- ## Bayes factor type: BFlinearModel, JZS Ici, l’interaction tend plutôt à favoriser l’hypothèse nulle. Il est à noter qu’il est possible de contrôler les distributions a priori exactement de la même manière que celle qui a été décrite pour lmBF Pour réaliser les contrastes sous un angle bayésien, vous pouvez réaliser une anova dans une perspective fréquentiste, faire les contrastes et utiliser la valeur du t du contraste avec l fonction ttest.tstat. Si je voulais comparer mon groupe incident aux deux autres groupes et que la valeur du contraste valeur 1.2, on utiliserait la fonction ainsi : ttest.tstat(1.2, n1 =20, n2 = 40, rscale = &quot;medium&quot;) ## $bf ## [1] -0.696399 ## ## $properror ## [1] 0.00007990923 ## ## $method ## [1] &quot;quadrature&quot; 12.1.4.2 Avec Jamovi Pour faire une anova bayésienne mixte, il faut choisir le module anova à meure répétée bayésienne. Il faut préciser les nom des modalités à mesure répétées dans la section ‘Repeated Measures Factors’ et placer dans la section ‘Repeated Measures Cells’ les variables de votre jeu de données correspondant à ce l’ordre ‘Repeated Measures Factors’ et vous obtenez vos résultats. Pour terminer, vous pouvez obtenir les comparaison 2 à 2 en cliquant sur ‘post-hoc test’. Pour les plus avertis, il est possible de contrôler la distribution a priori en cliquant sur “options avancées”. 12.2 Exercice 2 Priolo et ses collaborateur (Priolo et al., 2023) ont cherché à repliqué les effets des nudges sur l’efficacité comportementale et l’acceptabilité dans le cadre d’une expérience de terrain en contexte naturel. Le nudge étudié consiste à définir par défaut l’option « zéro sucre » dans les distributeurs de boissons chaudes d’une université française. Deux campus ont été comparés : le campus A (option par défaut : 0 sucre) et le campus B (option par défaut : 3 sucres). L’efficacité du nudge a été mesurée en observant la quantité de sucre effectivement choisie par les participants, et son acceptabilité a été évaluée au moyen d’un questionnaire. Les données (généreusement mises à disposition par Daniel Priolo) sont disponibles dans le fichier Nudge. Voici la description des variables (d’intérêt) Participants : Identifiant du participant Campus : Campus A (qui a 0 sucres par défaut) et campus B (3 sucrus pas défaut) Gender : genre du / de la participant·e Age : age du du / de la participant·e CSP : catégorie socioprofessionnelle Discipline_Cat : UFR de l’étudiant·e Discipline : formation de l’étudiant·e Saw_Sugar : est-ce que la personne a vu ou non la valeur en sucre par défaut (0 =non, 1 = oui) UC = combien de sucres met la personne d’habitude OC = combien de sucres la personne a mis OC_B = a-t-elle mis du sucre ? (0 = non, 1 = oui) UC_B = met-elle du sucre d’habitude (0 = non, 1 = oui) MOY_ACC = acceptabilité d’être nudgé - d’avoir une option par défaut pour réduire la consommation de sucre MOY_FORCE = A quel point est-ce que la personne était favorable à l’idée de réduire sa consommation en sucre Les autres variables ne seront pas utilisées. Les données sont disponibles ici. Importer les données. Vérifiez si l’effet du nudge a fonction en montrant que les étudiant·e du campus A a consommé moins de sucre que ceux du campus B. Pour mener votre analyse : - identifier l’analyse que vous allez faire - établissez la distribution a priori en vous appuyant sur les données de (Mertens et al., 2021) disponibles ici - Interpétez les résultats - Vérifiez que vos résultats sont robustes à différents prior et qu’ils ne sont pas dépendants de quelques observations seulement. Cliquez pour la solution Puisque dans la méta-analyse, la taille d’effet est 0.43, nous allons fixé le prior à “medium”. L’analyse qu’il faut réaliser est un test t de Student. library(readxl) library(BayesFactor) library(changeofevidence) library(bayestestR) priolo&lt;-read_xlsx(&quot;./Exercices/Nudge.xlsx&quot;) priolo &lt;-as.data.frame(priolo) t.out&lt;-ttestBF(formula =OC ~Campus, data=priolo, paired =F, rscale = .707) # prior à .707 t.out ## Bayes factor analysis ## -------------- ## [1] Alt., r=0.707 : 23796524 ±0% ## ## Against denominator: ## Null, mu1-mu2 = 0 ## --- ## Bayes factor type: BFindepSample, JZS bf.exp &lt;- bfttest(OC ~Campus, data= priolo, alternative = &quot;two.sided&quot;, prior.loc = 0, prior.r = sqrt(2)) ## | | | 0% | | | 1% | |= | 1% | |== | 2% | |== | 3% | |== | 4% | |=== | 4% | |==== | 5% | |==== | 6% | |===== | 7% | |====== | 8% | |====== | 9% | |======= | 10% | |======== | 11% | |======== | 12% | |========= | 13% | |========== | 14% | |========== | 15% | |=========== | 16% | |============ | 16% | |============ | 17% | |============ | 18% | |============= | 19% | |============== | 19% | |============== | 20% | |============== | 21% | |=============== | 21% | |================ | 22% | |================ | 23% | |================ | 24% | |================= | 24% | |================== | 25% | |================== | 26% | |=================== | 27% | |==================== | 28% | |==================== | 29% | |===================== | 30% | |====================== | 31% | |====================== | 32% | |======================= | 33% | |======================== | 34% | |======================== | 35% | |========================= | 36% | |========================== | 36% | |========================== | 37% | |========================== | 38% | |=========================== | 39% | |============================ | 39% | |============================ | 40% | |============================ | 41% | |============================= | 41% | |============================== | 42% | |============================== | 43% | |============================== | 44% | |=============================== | 44% | |================================ | 45% | |================================ | 46% | |================================= | 47% | |================================== | 48% | |================================== | 49% | |=================================== | 50% | |==================================== | 51% | |==================================== | 52% | |===================================== | 53% | |====================================== | 54% | |====================================== | 55% | |======================================= | 56% | |======================================== | 56% | |======================================== | 57% | |======================================== | 58% | |========================================= | 59% | |========================================== | 59% | |========================================== | 60% | |========================================== | 61% | |=========================================== | 61% | |============================================ | 62% | |============================================ | 63% | |============================================ | 64% | |============================================= | 64% | |============================================== | 65% | |============================================== | 66% | |=============================================== | 67% | |================================================ | 68% | |================================================ | 69% | |================================================= | 70% | |================================================== | 71% | |================================================== | 72% | |=================================================== | 73% | |==================================================== | 74% | |==================================================== | 75% | |===================================================== | 76% | |====================================================== | 76% | |====================================================== | 77% | |====================================================== | 78% | |======================================================= | 79% | |======================================================== | 79% | |======================================================== | 80% | |======================================================== | 81% | |========================================================= | 81% | |========================================================== | 82% | |========================================================== | 83% | |========================================================== | 84% | |=========================================================== | 84% | |============================================================ | 85% | |============================================================ | 86% | |============================================================= | 87% | |============================================================== | 88% | |============================================================== | 89% | |=============================================================== | 90% | |================================================================ | 91% | |================================================================ | 92% | |================================================================= | 93% | |================================================================== | 94% | |================================================================== | 95% | |=================================================================== | 96% | |==================================================================== | 96% | |==================================================================== | 97% | |==================================================================== | 98% | |===================================================================== | 99% | |======================================================================| 99% | |======================================================================| 100% plot(bf.exp) bf.robust &lt;- bfRobustness(bf.exp,prior.loc =0 ) ## Highest BF = 25788787 with prior: Cauchy(0, 1) plot(bf.robust) psych::describe(OC ~Campus, data= priolo) ## ## Descriptive statistics by group ## Campus: A ## vars n mean sd median trimmed mad min max range skew kurtosis se ## OC 1 78 0.82 1.33 0 0.58 0 0 5 5 1.45 1.13 0.15 ## ------------------------------------------------------------ ## Campus: B ## vars n mean sd median trimmed mad min max range skew kurtosis se ## OC 1 67 2.3 1.3 3 2.33 0 0 5 5 -0.47 -0.65 0.16 Le facteur de Bayes indique que nous avons des preuves extrêmes en faveur d’une différence de consommation de surces entre les deux campsus, où les étudiant·es sur le campus B, avec une moyenne à 2.3 sucres, consomment plus de sucres que ceux sur le campus A, avec une moyenne de 0.82 sucres. L’analyse séquentielle indique que la tendance est globalement toujours ascendante au fur et à mesure que l’échantillon grandit et nos résultats ne semblent pas être influencés par le choix du prior puisque les analyses de robustesses montrent que les facteurs bayésiens sont supérieur à \\(10^6\\) pour l’ensemble des distributions a priori examinées. 12.3 Exercice 3 Testez si l’acceptabilité du nudge dépend de la force de l’attitude. Vous n’avez pas d’étude qui vous offre des balises. Adoptez une attitude qui vous permettra de justifier vos résultats. Vérifiez entre quelles valeurs se situent l’intervalle de crédibilité. Cliquez pour la solution L’analyse que nous devons réaliser est une corrélation. Il est raisonnable de penser que la force de l’attitude favorisent l’acceptabilité du nudge mais on peut difficilement imaginer qu’une personne s’oppose farouchement à la mise en place d’une politique visant à adopter des comportements (alimentaires) plus sains. On peut imaginer une corrélation moyenne au maximum. library(bayestestR) corr.out&lt;-correlationBF( y=priolo$MOY_ACC, x=priolo$MOY_FORCE, rscale = &quot;medium&quot;, nullInterval = NULL, posterior = F) # calcul de l&#39;intervalle de crédibilité post&lt;-posterior(corr.out, iterations = 1000) post2 = recompute(post, iterations = 10000) plot(post2) summary(post2) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## rho 0.1857 0.07901 0.0007901 0.0008677 ## zeta 0.1891 0.08232 0.0008232 0.0009015 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## rho 0.02499 0.1328 0.1874 0.2391 0.3374 ## zeta 0.02500 0.1336 0.1896 0.2439 0.3511 plot(post2[,1:2]) ## OU corr.out.post&lt;-correlationBF( y=priolo$MOY_ACC, x=priolo$MOY_FORCE, rscale = &quot;medium&quot;, nullInterval = NULL, posterior = T, iterations =1000) ci_hdi &lt;- ci(corr.out.post, method = &quot;HDI&quot;) ci_hdi ## Highest Density Interval ## ## Parameter | 95% HDI ## ------------------------ ## rho | [0.03, 0.33] ## zeta | [0.03, 0.34] ggplot(priolo, aes(x = MOY_FORCE, y =MOY_ACC) )+ geom_point()+ stat_smooth(method = &quot;lm&quot;, formula = y ~ x, geom = &quot;smooth&quot;) rs &lt;- c(seq(from = .05, to =2, by = 0.05), 1/sqrt(27), 1/3, 1/sqrt(3), 1) # on veut pouvoir les calculer tous en même temps. # pour cela, on va utiliser la fonction sapply qui va # calculer le Bayes Factor pour tous les priors qu&#39;on va lui donner (stockés dans rs) bfs &lt;- sapply(rs, function(r) { # on crée un fonction spécifiquement pour notre propos # on utilise exactement la même fonction que celle qu&#39;on utilise pour un seul BF # mais au lieu de donner une valeur au rscale, on lui donne l&#39;argument r # qui seront fourni par tous les rs bf &lt;- correlationBF(y=priolo$MOY_ACC, x=priolo$MOY_FORCE, rscale = r, nullInterval = NULL, posterior = F) # on extrait les facteurs de Bayes extractBF(bf)$bf }) # on crée un data.frame pour faire le graphique robust&lt;-data.frame(rs, bfs) # on réalise le graphique robust$bfs&lt;-round(robust$bfs, 3) robust$rs&lt;-round(robust$rs, 3) # on fait la ligne qui touche tous les points ggplot(robust, aes(x=rs, y=bfs))+geom_line()+ # on donne le titre à l&#39;axe des x xlab(&quot;Choix de la distribution a priori&quot;)+ # on donne le titre à l&#39;axe des y ylab(&quot;Valeur du facteur de Bayes&quot;)+ # on met en valeur les points des priors prédéfinis dans BayesFactor geom_point(data=robust[41:44,], colour=&quot;blue&quot;)+ # On indique sur le graphique à quel prior chaque point correspond * # en faisant un petit décalage afin d&#39;éviter une superposition avec le point annotate(&quot;text&quot;, label = robust$rs[41:44], x = robust$rs[41:44]+0.2, y = robust$bfs[41:44]+0.2, colour =&quot;blue&quot;, check_overlap = TRUE) En l’occurence le facteur de Bayes indique des preuves en faveur d’une corrélation. Néanmoins cette corrélation est faible car pour des prior supérieur à medium, le facteur de Bayes tend vers une zone d’incertitude. 12.4 Exercice 4 Vérifiez si l’écart sur la consommation observée de sucres entre les deux campus ne peut pas s’expliquer par des différences de consommations entre les étudiant·es qui préexistaient. Soyez cohérent·e dans le choix du prior Attention, le jeu de données doit être préparé pour pouvoir réaliser l’analyse correctement. Cliquez pour la solution require(reshape2) require(dplyr) priolo2&lt;-priolo %&gt;% dplyr::select( Participants, Campus, UC, OC) priolo.long&lt;-melt(priolo2, id.vars = c(&quot;Participants&quot;, &quot;Campus&quot;), variable.name=&quot;Localisation&quot;, value.name=&quot;Quantite&quot;) priolo.long$Participants&lt;-as.factor(priolo.long$Participants) priolo.long$Campus&lt;-as.factor(priolo.long$Campus) aov.out&lt;- generalTestBF(Quantite ~ Campus*Localisation + Participants, data = priolo.long, whichRandom = &quot;Participants&quot;, neverExclude=&quot;Participants&quot;, progress=FALSE) aov.out ## Bayes factor analysis ## -------------- ## [1] Campus + Participants : 28426215199734063104 ±1.11% ## [2] Localisation + Participants : 947828574210654 ±1.15% ## [3] Campus + Localisation + Participants : 20219846208840953856 ±1.45% ## [4] Campus + Localisation + Campus:Localisation + Participants : 6785407505150435655680 ±4.63% ## [5] Participants : 1322151571553891 ±0% ## ## Against denominator: ## Intercept only ## --- ## Bayes factor type: BFlinearModel, JZS aov.out[4]/aov.out[3] ## Bayes factor analysis ## -------------- ## [1] Campus + Localisation + Campus:Localisation + Participants : 335.5816 ±4.85% ## ## Against denominator: ## Quantite ~ Campus + Localisation + Participants ## --- ## Bayes factor type: BFlinearModel, JZS psych::describeBy(Quantite ~ Campus*Localisation, data=priolo.long,mat=T) ## item group1 group2 vars n mean sd median trimmed mad ## Quantite1 1 A UC 1 78 1.0000000 1.338734 0 0.828125 0.0000 ## Quantite2 2 B UC 1 67 1.6567164 1.492935 1 1.527273 1.4826 ## Quantite3 3 A OC 1 78 0.8205128 1.326489 0 0.578125 0.0000 ## Quantite4 4 B OC 1 67 2.2985075 1.302851 3 2.327273 0.0000 ## min max range skew kurtosis se ## Quantite1 0 5 5 0.9938842 -0.006426413 0.1515817 ## Quantite2 0 5 5 0.4270383 -0.942605220 0.1823911 ## Quantite3 0 5 5 1.4468359 1.127781997 0.1501953 ## Quantite4 0 5 5 -0.4731558 -0.651910476 0.1591686 Les moyennes indiquent que les personnes sur le campus A consomment moins de sucre que celles sur le campus B et que cette différence est d’autant plus marquée sur la différence observée par rapport à la différence rapportée de leur consommation habituelle. Le rapport entre le facteur de Bayes avec l’interaction et sans l’interaction est de 287, ce qui représente des preuves extrêmes en faveur de la présence de l’interaction. 12.5 Exercice 5 Drouillet et al. (2018) ont voulu savoir dans quelle mesure les capacités d’apprentissage procédural étaient impliqués dans la compréhension des métaphores. Dans cette étude, les participants devaient décider si une phrase avait du sens ou non. Les participant·es étaient amené·es à traiter des expressions littérales (balayer la poussière), métaphorique (balayer ses soucis) ou pour lesquels il était très difficile de trouver un sens (balayer les nuages). D’après Ullman (2001), la mémoire déclarative est impliquée dans le lexique (et donc dans la compréhension) tandis que la mémoire procédurale devrait être impliquée dans la grammaire. Ainsi, la mémoire procédurale ne devrait pas être impliqué dans la compréhension des métaphores. Vérifiez si la mémoire déclarative (évaluée par le Mill Hill), les capacités d’apprentissage implicite (indice_app_impl) ou leur interaction permet de prédire la difficulté que représente de traiter une métaphore par rapport à une phrase littérale (indice1.meta.baseline) et la faciliter que représente de traiter une métaphore par rapport à une phrase qui n’a pas sens (indice2.meta.baseline). Les données sont disponibles dans le fichier “Drouillet2018.xlsx” Réalisez l’analyse adaptée et interpréter les résultats. Cliquez pour la solution drouillet&lt;-read_xlsx(&quot;./Exercices/Drouillet2018.xlsx&quot;) drouillet$participant&lt;-as.factor(drouillet$participant) lm.out1.1&lt;-lmBF(indice1.meta.baseline ~ Mill_Hill + participant, data = drouillet, whichRandom = &quot;participant&quot;) lm.out1.2&lt;-lmBF(indice1.meta.baseline ~ indice_app_impl+ Mill_Hill + participant, data = drouillet, whichRandom = &quot;participant&quot;) lm.out1.3&lt;-lmBF(indice1.meta.baseline ~ indice_app_impl+ Mill_Hill + indice_app_impl:Mill_Hill+ participant, data = drouillet, whichRandom = &quot;participant&quot;) lm.out2.1&lt;-lmBF(indice2.meta.baseline ~ Mill_Hill + participant, data = drouillet, whichRandom = &quot;participant&quot;) lm.out2.2&lt;-lmBF(indice2.meta.baseline ~ indice_app_impl+ Mill_Hill + participant, data = drouillet, whichRandom = &quot;participant&quot;) lm.out2.3&lt;-lmBF(indice2.meta.baseline ~ indice_app_impl+ Mill_Hill + indice_app_impl:Mill_Hill+ participant, data = drouillet, whichRandom = &quot;participant&quot;) Ces analyses montrent que la difficulté que rencontrent les personnes pour comprendre une métaphore par rapport à du langage littéral s’explique par l’interaction entre la mémoire procédurale et la mémoire déclarative. Tous les autres modèles ne sont pas discriminants. 12.6 t de Student 12.6.1 Illustration 12.6.1.1 Avec R 12.6.1.2 Avec Jamovi 12.6.2 Exercice énoncé 12.6.2.1 Solution avec R 12.6.2.2 Solution avec Jamovi 12.7 Une corrélation 12.7.1 Illustration 12.7.1.1 Avec R 12.7.1.2 Avec Jamovi 12.7.2 Exercice énoncé 12.7.2.1 Solution avec R 12.7.2.2 Solution avec Jamovi 12.8 Une anova 12.8.1 Illustration 12.8.1.1 Avec R 12.8.1.2 Avec Jamovi 12.8.2 Exercice énoncé 12.8.2.1 Solution avec R 12.8.2.2 Solution avec Jamovi Would you like some coffee with your sugar? A natural field experiment on the efficiency and acceptability of setting zero sugars as a default in coffee-vending machines Daniel Priolo, Isabelle Milhabet, Marilena Bertolino, Tom Juille, Dorian Jullien, Guilhem Lecouteux, Ismaël Rafaï &amp; Pierre Thérouanne To cite this article: Daniel Priolo, Isabelle Milhabet, Marilena Bertolino, Tom Juille, Dorian Jullien, Guilhem Lecouteux, Ismaël Rafaï &amp; Pierre Thérouanne (2023): Would you like some coffee with your sugar? A natural field experiment on the efficiency and acceptability of setting zero sugars as a default in coffee-vending machines, Comprehensive Results in Social Psychology, DOI: 10.1080/23743603.2023.2214964 To link to this article: https://doi.org/10.1080/23743603.2023.2214964 ABSTRACT This paper aims to replicate the effect of a nudge on behavior (efficiency) and acceptability in a natural field experiment. The nudge in our study consists in setting zero sugars as the default level of sugar in hot drinks–vending machines in a French university. We compared Campus A (default option set to 0 sugars) to Campus B (default option set to 3 sugars). We measured the efficiency of this default option by observing the level of sugar actually chosen by the participants, and we measured acceptability through a questionnaire. We hypothesized a high level of efficiency for the nudge and a higher acceptability in Campus A (default option set to 0 sugars) compared to Campus B (default option set to 3 sugars). Our results show that participants with the default option set to zero sugars (Campus A) consumed less sugar than those with the default option set to 3 sugars (Campus B). We also found a high level of acceptability on both campuses, though with no difference between Campus A (where the nudge was implemented) and Campus B (where a future nudge would be implemented). The discussion addresses the applied perspectives and ethical implications of these results est-ce que la force de l’attitude consistant à vouloir diminuer le sucre est associé à accepter le nudge Campus A : défaut à 0 Campus B : défaut à 3 sucres etudes anova avec 3 groupes References Dechamps, M. (2025). Changeofevidence: Change of evidence. https://github.com/mrzdcmps/changeofevidence Drouillet, L., Stefaniak, N., Declercq, C., &amp; Obert, A. (2018). Role of implicit learning abilities in metaphor understanding. Consciousness and Cognition, 61, 13–23. https://doi.org/10.1016/j.concog.2018.03.015 Makowski, D., Ben-Shachar, M. S., &amp; Lüdecke, D. (2019). bayestestR: Describing effects and their uncertainty, existence and significance within the bayesian framework. Journal of Open Source Software, 4(40), 1541. https://doi.org/10.21105/joss.01541 Mertens, S., Herberz, M., Hahnel, U. J. J., &amp; Brosch, T. (2021). The effectiveness of nudging: A meta-analysis of choice architecture interventions across behavioral domains. Proceedings of the National Academy of Sciences, 119(1). https://doi.org/10.1073/pnas.2107346118 Morey, R. D., &amp; Rouder, J. N. (2024). BayesFactor: Computation of bayes factors for common designs. https://CRAN.R-project.org/package=BayesFactor Priolo, D., Milhabet, I., Bertolino, M., Juille, T., Jullien, D., Lecouteux, G., Rafaï, I., &amp; Thérouanne, P. (2023). Would you like some coffee with your sugar? A natural field experiment on the efficiency and acceptability of setting zero sugars as a default in coffee-vending machines. Comprehensive Results in Social Psychology, 7(1–2), 25–41. https://doi.org/10.1080/23743603.2023.2214964 Stefaniak, N., Willems, S., Adam, S., &amp; Meulemans, T. (2008). What is the impact of the explicit knowledge of sequence regularities on both deterministic and probabilistic serial reaction time task performance? Memory &amp;Amp; Cognition, 36(7), 1283–1298. https://doi.org/10.3758/mc.36.7.1283 Ullman, M. T. (2001). Journal of Psycholinguistic Research, 30(1), 37–69. https://doi.org/10.1023/a:1005204207369 Wickham, H. (2007). Reshaping data with the reshape package. Journal of Statistical Software, 21(12), 1–20. http://www.jstatsoft.org/v21/i12/ Wickham, H., &amp; Bryan, J. (2025). Readxl: Read excel files. https://CRAN.R-project.org/package=readxl Wickham, H., François, R., Henry, L., Müller, K., &amp; Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://CRAN.R-project.org/package=dplyr William Revelle. (2025). Psych: Procedures for psychological, psychometric, and personality research. Northwestern University. https://CRAN.R-project.org/package=psych je présuppose que vous savez ce que c’est si vous utilisez régulièrement R.↩︎ "],["conclusions.html", "Chapter 13 Conclusions", " Chapter 13 Conclusions Vous connaissez à présent les principes sous-jacents l’approche bayésienne et vous connaissez ses avantages. Sans doute, vous connaissez un peu moins ses limites car nous ne les avons pas réellement abordées vu qu’elles sont un peu techniques et que ce n’est pas nécessairement des limites (mais pour une discussion sur ce point, voir Dienes, 2008). Á vous de décider si la manière dont vous voulez réaliser vos statistiques tendent plutôt vers une approche bayésienne ou une approche fréquentiste. Les deux approches ont leurs avantages et leurs inconvénients. Une solution peut aussi être de ne pas choisir (notamment si vous avez peur que des experts vous titillent sur vos analyses ou que votre article soit refusé en raison de l’utilisation de l’approche bayésienne). Á titre personnel, c’est la voie que j’ai choisie et qui est cohérente avec une approche multivers de l’analyse des données (Steegen et al., 2016), qui consiste à analyser les données de différentes manières afin de s’assurer de la robustesse des résultats. Si vos résultats n’ont pas la même interprétation en fonction de la manière dont vous avez analyé les données, alors sans doute qu’il faut s’interroger sur ce que veulent vraiment dire vos données. References Dienes, Z. (2008). Understanding psychology as a science: An introduction to scientific and statistical inference (1st ed., p. 184). Bloomsbury Academic / Red Globe Press. Steegen, S., Tuerlinckx, F., Gelman, A., &amp; Vanpaemel, W. (2016). Increasing transparency through a multiverse analysis. Perspectives on Psychological Science, 11(5), 702–712. https://doi.org/10.1177/1745691616658637 "],["references.html", "References", " References Al-Hujaj, O.-A., &amp; Harney, H. L. (1997). Objective bayesian statistics. Annalen Der Physik, 509(1), 93–110. https://doi.org/10.1002/andp.19975090109 Amir, Y., &amp; Sharon, I. (1990). Replication research: A \"must\" for the scientific advancement of psychology. Journal of Social Behavior &amp; Personality, 5(4), 51–69. Batselé, E., Stefaniak, N., &amp; Fantini-Hauwel, C. (2019). Resting heart rate variability moderates the relationship between trait emotional competencies and depression. Personality and Individual Differences, 138, 69–74. https://doi.org/10.1016/j.paid.2018.09.020 Bayes, T., &amp; Price, R. (1763). An essay towards solving a problem in the doctrine of chances. Philosophical Transactions of the Royal Society of London, 53, 370–418. https://doi.org/10.1098/rstl.1763.0053 Berger, J. O., &amp; Pericchi, L. R. (2001). Objective bayesian methods for model selection: Introduction and comparison. In P. Lahiri (Ed.), Model selection (Vol. 38, pp. 135–207). Institute of Mathematical Statistics. Bohannon, J. (2015). Many psychology papers fail replication test. Science, 349(6251), 910–911. https://doi.org/10.1126/science.349.6251.910 Caldwell, A. R. (2022). Exploring equivalence testing with the updated TOSTER r package. https://doi.org/10.31234/osf.io/ty8de Champely, S. (2020). Pwr: Basic functions for power analysis. https://CRAN.R-project.org/package=pwr Clarke, B., Schiavone, S., Vazire, S., Bavel, J. J. V., &amp; Chambers, C. D. (2024). The prevalence of direct replication articles in top-ranking psychology journals (2010–2021). Royal Society Open Science, 11(1), 231506. https://doi.org/10.1098/rsos.231506 Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Lawrence Erlbaum Associates. Cohen, J. (1994). The earth is round (p &lt; 05). American Psychologist, 49(12), 997–1003. https://doi.org/10.1037/0003-066x.49.12.997 Dallagi-Belkilani, M., Olivier, M., &amp; Besche-Richard, C. (2024). Validation of the basic empathy scale in an arabic-speaking population: The BES-ar. L’Encéphale, 50(2), 149–153. https://doi.org/10.1016/j.encep.2023.04.002 Dechamps, M. (2025). Changeofevidence: Change of evidence. https://github.com/mrzdcmps/changeofevidence Dienes, Z. (2008). Understanding psychology as a science: An introduction to scientific and statistical inference (1st ed., p. 184). Bloomsbury Academic / Red Globe Press. Drouillet, L., Stefaniak, N., Declercq, C., &amp; Obert, A. (2018). Role of implicit learning abilities in metaphor understanding. Consciousness and Cognition, 61, 13–23. https://doi.org/10.1016/j.concog.2018.03.015 Edwards, W., Lindman, H., &amp; Savage, L. J. (1963). Bayesian statistical inference for psychological research. Psychological Review, 70(3), 193–242. https://doi.org/10.1037/h0044139 Finetti, B. de. (1974). Theory of probability, vol. 1. Wiley. Fisher, R. A. (1955). Statistical methods and scientific induction. Journal of the Royal Statistical Society. Series B (Methodological), 17(1), 69–78. https://doi.org/10.2307/2983785 Hájek, A. (2012). Interpretations of probability. https://plato.stanford.edu/entries/probability-interpret/. Hamaoui, J., Stefaniak, N., &amp; Segond, H. (2022). The influence of vestibular system and fetal presentation on handedness, cognitive and motor development: A comparison between cephalic and breech presentation. Developmental Science, 26(3). https://doi.org/10.1111/desc.13317 Hengartner, M. P. (2021). Targeting the replication crisis and improving the credibility of research findings in clinical psychology. A commentary on pittelkow et al. Clinical Psychology: Science and Practice, 28(2), 226–228. https://doi.org/10.1037/cps0000028 Henry, A., Stefaniak, N., Schmid, F., Kwiatkowski, A., Hautecoeur, P., &amp; Lenne, B. (2023). Assessing cognitive changes in multiple sclerosis: Criteria for a reliable decision. Journal of Clinical and Experimental Neuropsychology, 45(4), 321–344. https://doi.org/10.1080/13803395.2023.2232122 Ioannidis, J. P. A. (2005). Why most published research findings are false. PLoS Medicine, 2(8), e124. https://doi.org/10.1371/journal.pmed.0020124 Jeffreys, H. (1961). Theory of probability (3rd ed.). Oxford University Press. Klein, R. A., Hardwicke, T. E., Aust, F., Breuer, J., Danielsson, H., Mohr, A. H., IJzerman, H., Nilsonne, G., Veer, A. E. van’t, Frank, M. C., &amp; Schönbrodt, F. D. (2021). Accelerating psychological science with transparency. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467. https://doi.org/10.1177/25152459211007467 Lakens, D. (2017). Equivalence tests: A practical primer for t tests, correlations, and meta-analyses. Social Psychological and Personality Science, 8(4), 355–362. https://doi.org/10.1177/1948550617697177 Lakens, D. (2019). The value of preregistration for psychological science: A conceptual analysis. Japanese Psychological Review, 62(3), 221–230. https://doi.org/10.4992/jjpsy.62.221 Lakens, D., Scheel, A. M., &amp; Isager, P. M. (2018). Equivalence testing for psychological research: A tutorial. Advances in Methods and Practices in Psychological Science, 1(2), 259–269. https://doi.org/10.1177/2515245918770963 LaPlace, P. S. (1814). Essai philosophique sur les probabilités. Courcier. http://eudml.org/doc/203193 Lindley, D. V. (1957). A statistical paradox. Biometrika, 44(1/2), 187. https://doi.org/10.2307/2333251 Makowski, D., Ben-Shachar, M. S., &amp; Lüdecke, D. (2019). bayestestR: Describing effects and their uncertainty, existence and significance within the bayesian framework. Journal of Open Source Software, 4(40), 1541. https://doi.org/10.21105/joss.01541 Maxwell, S. E., Lau, M. Y., &amp; Howard, G. S. (2015). Is psychology suffering from a replication crisis? What does “failure to replicate” really mean? American Psychologist, 70(6), 487–498. https://doi.org/10.1037/a0039400 Mertens, S., Herberz, M., Hahnel, U. J. J., &amp; Brosch, T. (2021). The effectiveness of nudging: A meta-analysis of choice architecture interventions across behavioral domains. Proceedings of the National Academy of Sciences, 119(1). https://doi.org/10.1073/pnas.2107346118 Mises, R. von. (1957). Probability, statistics and truth (Revised English edition). Macmillan. Morey, R. D., &amp; Rouder, J. N. (2011). Bayes factor approaches for testing interval null hypotheses. Psychological Methods, 16(4), 406–419. https://doi.org/10.1037/a0024377 Morey, R. D., &amp; Rouder, J. N. (2024). BayesFactor: Computation of bayes factors for common designs. https://CRAN.R-project.org/package=BayesFactor Neoh, J. X., Taylor, C. A., Driessen, G. W. J., &amp; Leung, J. (2023). Fifty years of research on questionable research practices in science: Quantitative analysis of co-citation patterns. Scientometrics, 128(10), 6275–6302. https://doi.org/10.1007/s11192-023-04766-1 Neyman, J., &amp; Pearson, E. S. (1933). Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231(694–706), 289–337. https://doi.org/10.1098/rsta.1933.0009 Nissen, M. J., &amp; Bullemer, P. (1987). Attentional requirements of learning: Evidence from performance measures. Cognitive Psychology, 19(1), 1–32. https://doi.org/10.1016/0010-0285(87)90002-8 Nosek, B. A., Ebersole, C. R., DeHaven, A. C., &amp; Mellor, D. T. (2018). The preregistration revolution. Proceedings of the National Academy of Sciences, 115(11), 2600–2606. https://doi.org/10.1073/pnas.1708274114 Open Science Collaboration. (2015). Estimating the reproducibility of psychological science. Science, 349(6251). https://doi.org/10.1126/science.aac4716 Peirce, C. S. (1877). The fixation of belief. Popular Science Monthly, 12, 1–15. Poor, C. L. (1922). Gravitation versus relativity. Putnam. https://archive.org/details/gravitationversu00pooruoft Popper, K. (1963). Conjectures and refutations: The growth of scientific knowledge. Routledge; Kegan Paul. Popper, K. R. (1959). The logic of scientific discovery. Hutchinson. Priolo, D., Milhabet, I., Bertolino, M., Juille, T., Jullien, D., Lecouteux, G., Rafaï, I., &amp; Thérouanne, P. (2023). Would you like some coffee with your sugar? A natural field experiment on the efficiency and acceptability of setting zero sugars as a default in coffee-vending machines. Comprehensive Results in Social Psychology, 7(1–2), 25–41. https://doi.org/10.1080/23743603.2023.2214964 Rocchi, P., &amp; Gianfagna, L. (2013). An essay on the double nature of probability. https://arxiv.org/abs/1301.5443. Rossi, P. E., Allenby, G. M., &amp; McCulloch, R. (2005). Bayesian statistics and marketing. In Wiley Series in Probability and Statistics. Wiley. https://doi.org/10.1002/0470863692 Rouder, J. N., Morey, R. D., Speckman, P. L., &amp; Province, J. M. (2012). Default bayes factors for ANOVA designs. Journal of Mathematical Psychology, 56(5), 356–374. https://doi.org/10.1016/j.jmp.2012.08.001 Rouder, J. N., Speckman, P. L., Sun, D., Morey, R. D., &amp; Iverson, G. (2009). Bayesian t tests for accepting and rejecting the null hypothesis. Psychonomic Bulletin &amp;Amp; Review, 16(2), 225–237. https://doi.org/10.3758/pbr.16.2.225 Royall, R. M. (1997). Statistical evidence: A likelihood paradigm. Chapman &amp; Hall. Steegen, S., Tuerlinckx, F., Gelman, A., &amp; Vanpaemel, W. (2016). Increasing transparency through a multiverse analysis. Perspectives on Psychological Science, 11(5), 702–712. https://doi.org/10.1177/1745691616658637 Stefaniak, N., Baltazart, V., &amp; Declercq, C. (2021). Processing verb meanings and the declarative/procedural model: A developmental study. Frontiers in Psychology, 12. https://doi.org/10.3389/fpsyg.2021.714523 Stefaniak, N., Willems, S., Adam, S., &amp; Meulemans, T. (2008). What is the impact of the explicit knowledge of sequence regularities on both deterministic and probabilistic serial reaction time task performance? Memory &amp;Amp; Cognition, 36(7), 1283–1298. https://doi.org/10.3758/mc.36.7.1283 Student. (1908). The probable error of a mean. Biometrika, 6(1), 1–25. https://doi.org/10.1093/biomet/6.1.1 Szucs, D., &amp; Ioannidis, J. P. A. (2017). Empirical assessment of published effect sizes and power in the recent cognitive neuroscience and psychology literature. PLOS Biology, 15(3), e2000797. https://doi.org/10.1371/journal.pbio.2000797 Ullman, M. T. (2001). Journal of Psycholinguistic Research, 30(1), 37–69. https://doi.org/10.1023/a:1005204207369 Venn, J. (1876). The logic of chance (2nd ed.). Macmillan. Wagenmakers, E.-J., Wetzels, R., Borsboom, D., &amp; Maas, H. L. J. van der. (2011). Why psychologists must change the way they analyze their data: The case of psi: Comment on bem (2011). Journal of Personality and Social Psychology, 100(3), 426–432. https://doi.org/10.1037/a0022790 Wagenmakers, E.-J., Wetzels, R., Borsboom, D., Maas, H. L. J. van der, &amp; Kievit, R. A. (2012). An agenda for purely confirmatory research. Perspectives on Psychological Science, 7(6), 632–638. https://doi.org/10.1177/1745691612463078 Wickham, H. (2007). Reshaping data with the reshape package. Journal of Statistical Software, 21(12), 1–20. http://www.jstatsoft.org/v21/i12/ Wickham, H., &amp; Bryan, J. (2025). Readxl: Read excel files. https://CRAN.R-project.org/package=readxl Wickham, H., François, R., Henry, L., Müller, K., &amp; Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://CRAN.R-project.org/package=dplyr William Revelle. (2025). Psych: Procedures for psychological, psychometric, and personality research. Northwestern University. https://CRAN.R-project.org/package=psych "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
