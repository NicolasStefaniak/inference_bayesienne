[{"path":"index.html","id":"section","chapter":"","heading":"","text":"","code":""},{"path":"remerciements.html","id":"remerciements","chapter":"Remerciements","heading":"Remerciements","text":"La création de ce document été un véritable challenge à relever à la fois pour sa conception technique que pour la réflexion qu’impliquait le fait de rendre l’approche bayésienne accessible et compréhensible.Ce document n’aurait jamais pu voir le jour sans des personnes qui ont contribué, consciemment ou non,à sa conception.Je tiens tout d’abord à avoir une pensée particulière pour ma femme et mon fils qui sont une source infinie de joie et de bonheur au quotidien. Partager ma vie avec vous pousse à être chaque jour meilleur que la veille.Ce document n’aurait sans doute jamais vu le jour sans le groupe R que nous avons formé avec Philippe Regnault et Frédéric Blanchard qui m’ont fait découvrir RMarkdown.Je ne peux décemment pas négliger Zoltan Dienes qui, par son livre, profondément impacté ma manière de penser la recherche et permis de m’initier à l’approche bayésienne. Ce fut donc une joie quand Olivier Klein m’proposé de participer à la traduction de cet ouvrage et je le remercie de l’avoir proposé.Ce document ne serait encore qu’une idée de ce que je dois faire un jour si le comité organisateur des journées thématiques de l’ADRIPS ne m’avaient pas proposé que je fasse un atelier. Je tiens à leur présenter mes plus sincères remerciements d’avoir été l’étincelle qui mis le feu aux poudres de ce document.Merci à Daniel Priolo d’avoir généreusement mis ses données à disposition pour les exercices et d’avoir pris le temps de briefer sur leur organisation.Enfin, je remercie toutes les personnes qui lisent ce document, qui le trouvent inspirant pour changer leur approche du traitement des données et qui ont le sentiment d’avoir compris la philosophie inhérente à l’approche bayésienne.","code":""},{"path":"á-propos-de-cet-ouvrage..html","id":"á-propos-de-cet-ouvrage.","chapter":"1 Á propos de cet ouvrage.","heading":"1 Á propos de cet ouvrage.","text":"Les jeux de données et les codes sont disponibles sur le projet github.Si vous identifiez des fautes de frappes, des erreurs conceptuelles ou que des informations supplémentaires seraient utiles à ce document, vous pouvez également utiliser l’onglet issue ou pull request de la page github.","code":""},{"path":"introduction.html","id":"introduction","chapter":"2 Introduction","heading":"2 Introduction","text":"","code":""},{"path":"introduction.html","id":"êtes-vous-une-bayésienne-dans-lâme","chapter":"2 Introduction","heading":"2.1 Êtes-vous un·e bayésien·ne dans l’âme ?","text":"Beaucoup de personnes pourraient assister à cet atelier sans trop d’attente, juste pour voir, juste pour nourrir leur curiosité car ils ou elles sont intrigué·es par ce que cela peut bien signifier de faire des inférences bayésiennes. Mais peut-être que vous avez l’âme d’un·e bayésien·ne qui s’ignore.Pour le savoir, nous allons commencer cette séance en questionnant quelques-unes de vos connaissances et/ou de vos intuitions concernant les statistiques mais avant de commencer, j’aimerais faire un pari avec vous. Je suis convaincu de pouvoir radicalement modifier la manière dont vous pensez les statistiques et vos recherches.La question qui se pose donc est de savoir si vous pensez que, dans les 3 heures qui sont allouées, je serai en mesure de changer la manière dont vous penserez les statistiques et vos recherches à l’avenir. De mon côté, j’en suis convaincu et je suis disposé à vous donner 50 euros si ce n’est pas le cas. De votre côté, combien êtes-vous prêt à donner si c’est le cas ?","code":""},{"path":"introduction.html","id":"me-concernant","chapter":"2 Introduction","heading":"2.2 Me concernant","text":"Après une thèse à l’université de Liège (en Belgique), je suis arrivé à Reims en 2009 avec un poste d’ATER avant d’obtenir un poste de maître de conférences en 2011. Spécialisé en neuropsychologie, j’ai été recruté pour assurer des cours de méthodologie et de statistiques.Dans le cadre de ces cours et de mon initiation à R, j’ai développé une interface graphique d’avoir des boîtes de dialogue directement dans l’environnement R, tout en permettant de produire facilement. des scripts reproductiblesDepuis plusieurs années, je m’intéresse à l’approche bayésienne dans le traitement des données que j’ai commencé à utiliser dans le cadre de mes recherches (Batselé et al., 2019; Drouillet et al., 2018; Hamaoui et al., 2022; Stefaniak et al., 2021) avant d’être impliqué dans la traduction du livre de Zoltan Dienes (2008) (understanding psychology science) (à paraître) et de développer des outils basés sur l’approche bayésienne à destination des neuropsychologues cliniciens (Henry et al., 2023).","code":""},{"path":"introduction.html","id":"prérequis-souhaitables","chapter":"2 Introduction","heading":"2.3 Prérequis souhaitables","text":"avoir installé Rstudioêtre en mesure d’exécuter des lignes de commande Ravoir installé les packages suivants :\nbayestestR\npwr\ndplyr\nggplot2\nplotly\ndevtools\nchangeofevidence\nMASS\ntidyverse\nbayestestRpwrdplyrggplot2plotlydevtoolschangeofevidenceMASStidyverse","code":""},{"path":"introduction.html","id":"prérequis-indispensables","chapter":"2 Introduction","heading":"2.4 Prérequis indispensables","text":"savoir ce qu’est une distribution normaleêtre à l’aise avec un logiciel de traitement des données parmi R, Jamovi ou JASPconnaître les notions suivantes :\nmoyenne\nécart-type\nerreur-type\ncoefficient de régression\nseuil de significativité\néchantillonnage\nmoyenneécart-typeerreur-typecoefficient de régressionseuil de significativitééchantillonnageSi vous utilisez R, il est attendu que vous sachiez :\n- importer les données\n- faire des manipulations basiques (filtrer, sélectionner des variables, passer d’un format large à un format long)\n- soyez en mesure de faire les analyses de base en utilisant l’approche fréquentiste.","code":""},{"path":"introduction.html","id":"ce-que-nous-allons-faire","chapter":"2 Introduction","heading":"2.5 Ce que nous allons faire","text":"Expliquer ce que signifie la formule de BayesFaire un rappel sur les probabilités et l’approche fréquentisteApprendre à définir une distribution prioriComprendre la vraisemblance et son calculExpliquer ce qu’est la distribution posteriori et l’intervalle de crédibilitéPrésenter le facteur de BayesComparer l’approche fréquentiste avec l’approche bayésienneFaire des mises en applicationConclure.","code":""},{"path":"le-théorème-de-bayes.html","id":"le-théorème-de-bayes","chapter":"3 Le théorème de Bayes","heading":"3 Le théorème de Bayes","text":"“Le statisticien ne peut pas se soustraire à l’obligation d’être au clair quant aux principes de l’inférence scientifique, mais de même, aucune autre personne censée ne peut se soustraire à une telle obligation.”Le théorème de Bayes été imaginé par Thomas Bayes [1702 - 1761], un prêtre non conformiste qui était également membre de la Royal Society. Cependant, il n’été publié que deux ans après sa mort, grâce à Richard Price à qui Bayes avait laissé ses manuscrits inachevés. Il sembla à Price que ces manuscrits étaient d’une telle importance qu’il prit l’initiative d’envoyer le manuscrit à la Royal Society en 1763 (Bayes & Price, 1763). Ce théorème, qui été redécouvert de manière indépendante par Laplace (LaPlace, 1814), permettait de savoir comment les données modifiait la probabilité d’une hypothèse.En langage mathématique, le théorème de Bayes se définit par l’équation (3.1) :\\[\\begin{equation}\n  P\\left(H|D\\right) =\\frac{P\\left(D|H\\right) \\times P\\left(H\\right)}{P\\left(D\\right)}\n  \\tag{3.1}\n\\end{equation}\\]Cette équation signifie que la probabilité d’une hypothèse étant donné les données, P(H|D), est proportionnelle à la probabilité des données étant donné une hypothèse, P(D|H), multiplié par la probabilité de l’hypothèse, le tout divisé par la probabilité des données, P(H). La probabilité d’une hypothèse étant donné les données est ce qu’appelle la probabilité posteriori. La probabilité de l’hypothèse est ce qu’appelle la probabilité priori et la probabilité des données étant donné l’hypothèse est la vraisemblance. Il n’est pas nécessaire de s’attarder sur la probabilité des données car ce facteur va se simplifier lorsqu’voudra appliquer le théorème de Bayes à l’inférence statistique.Sans en identifier encore tous les tenants et aboutissants, peut intuitivement comprendre plusieurs points importants. Les différents points seront présentés du plus facile au plus difficile à comprendre :La probabilité d’un événement change quand accumule des informations ;Quelques notions élémentaires des probabilités sont indispensables à la compréhension de ce théorème pour pouvoir l’appliquer.doit connaître la probabilité de l’hypothèse avant d’avoir recueilli les données pour arriver à appliquer le théorème.Il faut comprendre ce que signifie la vraisemblance.Le théorème de Bayes informe sur la probabilité d’une hypothèse.Dans cette section, nous allons commencer par aborder ces 4 points avant d’entrer un peu plus dans les détails de l’inférence bayésienne.","code":""},{"path":"accumuler-les-informations..html","id":"accumuler-les-informations.","chapter":"4 Accumuler les informations.","heading":"4 Accumuler les informations.","text":"peut comprendre assez intuitivement que les probabilités changent quand accumule des informations au travers d’un exemple simple : vous partez en vacance et pour vos vacances, vous avez loué une superbe villa avec piscine dans un endroit paradisiaque (qui se trouve évidemment en France puisque vous êtes éco-responsable). Vous arrivez vers 19.30 dans le logement et après avoir fait le tour du propriétaire, vous ouvrez le frigo. Á l’intérieur, une boite hermétique avec de la nourriture dedans. Vous avez lu dans les commentaires de la location que, pour le confort des invités, les propriétaires amenaient le premier repas faits de produits frais et locaux aux vacanciers vu qu’ils n’avaient pas encore eu le temps de faire les courses. Vous vous demandez s’il s’agit du repas que les propriétaires offrent aux locataires ou s’il s’agit d’un repas oublié par les locataires précédents qui n’aurait pas été enlevé du frigidaire par mégarde. Le reste du frigo est parfaitement propre.Au travers de cet exemple, se rend compte que votre opinion évolué en fonction des informations qui se sont accumulées. Ainsi, la probabilité d’un évènement dépend des informations que nous avons de cet événement.","code":""},{"path":"les-axiomes-des-probabilités.html","id":"les-axiomes-des-probabilités","chapter":"5 Les axiomes des probabilités","heading":"5 Les axiomes des probabilités","text":"Les statistiques, et les méthodes d’inférences sont intimement liées aux probabilités et aux théories sous-jacentes à celles-ci. Dans cette section, va commencer par présenter quelques axiomes des probabilités, en particulier ceux dont nous aurons besoin pour comprendre l’inférence bayésienne, évoquera dans le chapitre suivant ce que signifie (ou non) les probabilités dans l’inférence de Neyman-Person (1933), et terminera les chapitres sur les probabilités en se questionnant la nature objective ou subjective des probabilités.Dans ce chapitre, il ne s’agit pas de faire une présentation avancée de ce que sont les probabilités mais de rappeler les contraintes des axiomes probabilistes qui vont contraindre l’application de Bayes. Pour le formuler autrement, l’application du théorème de Bayes doit respecter les axiomes des probabilités pour que son application ait du sens. Cela ne semble pas déraisonnable comme contrainte.Ainsi, il est bon de se rappeler que :La valeur d’une probabilité est toujours située entre 0 et 1La probabilité que l’événement ou B survienne, en admettant que et B ne peuvent pas survenir en même temps, est égal à la somme de leur probabilité respective, P()+P(B). Par exemple, ne peut pas avoir pile et face en même temps et la probabilité d’avoir pile ou face est bien égale à 1 si attribue une probabilité de 0,5 à chacun des deux événements.P(\\(\\cap\\) B) = P() × P(B|). P(\\(\\cap\\) B) est la probabilité que et B surviennent en même temps tandis que P(B|) est la probabilité de B lorsqu’connait , c’est-à-dire la probabilité de B si est vrai.Prenons le cas d’un jeu de cartes de 52 cartes et nous voulons déterminer la probabilité d’obtenir l’de coeur. Une solution simple est de considérer qu’il y un seul de coeur sur les 52 cartes, ce qui signifie que cette probabilité vaut 1/52. Une version alternative est de considérer que, dans un jeu de cartes, il y 4 sur 52, ce qui signifie que la probabilité d’obtenir un est de 1/13, que la probabilité d’avoir une carte rouge est de 1/2 et que, parmi les cartes rouges, il y 1 chance sur 2 que ce soit du coeur.\n(#fig:Fig2.1)Représentation visuelle des probabilités conjointes.\nAinsi, en décomposant le calcul, obtient :\\[ \\frac{1}{13} \\times \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{52} \\approx 0.019\\] Cette illustration, très simple, montre que le raisonnement qu’peut appliquer pour P(\\(\\cap\\) B) est également valable pour des plus complexes ou aurait par exemple P(\\(\\cap\\) B \\(\\cap\\) C \\(\\cap\\) D).Ces quelques notions suffiront pour pouvoir comprendre comment applique le théorème de Bayes dans le cadre des inférences statistiques. Tout","code":""},{"path":"quelques-rappels-sur-lapproche-de-neyman-pearson.html","id":"quelques-rappels-sur-lapproche-de-neyman-pearson","chapter":"6 Quelques rappels sur l’approche de Neyman-Pearson","heading":"6 Quelques rappels sur l’approche de Neyman-Pearson","text":"Si vous avez ce support entre les mains (ou sur votre écran), c’est que vous souhaitez sans doute pouvoir appliquer l’approche bayésienne au traitement de vos données et vous êtes certainement impatient·e de comprendre comment peut concrètement appliquer la formule (3.1) pour traiter des données. Il est également possible que vous ayez pratiqué l’approche de Neyman-Person (1933) (aussi connus sous les noms d’approche fréquentiste ou tests d’hypothèse nulle) et que vous ne soyez pas totalement satisfait·e de cette manière de traiter les données.Dans tous les cas, puisque l’approche de Neyman-Person (1933) est l’approche dominante, il est indispensable de connaitre les tenants et les aboutissants de cette approche. Ainsi, pour pouvoir mettre plus aisément en évidence les différences épistémologiques entre les deux approches, nous vous invitons à répondre au questionnaire ci-dessous qui permettra à la fois de savoir si vous avez une bonne compréhension de l’approche de Neyman-Person (1933) mais aussi si vous êtes bayésien dans l’âme.Quand nous réalisons une analyse fréquentiste, appelée aussi approche ou tests d’hypothèse nulle, nous savons si nous pouvons ou non exclure le 0 parmi l’ensemble des différences qui existent ainsi que le taux d’erreur de Type qu’va observer à long terme.","code":""},{"path":"quelques-rappels-sur-lapproche-de-neyman-pearson.html","id":"que-signifie-la-valeur-p","chapter":"6 Quelques rappels sur l’approche de Neyman-Pearson","heading":"6.1 Que signifie la valeur p ?","text":"La logique sous-jacente à l’approche de Neyman-Person (1933) est de pouvoir contrôler un niveau d’erreur à long terme. Cela signifie qu’un événement particulier n’pas de probabilité qui lui est associée. Prenons un exemple simple : vous avez un dé et vous voulez savoir s’il est pipé ou non. Vous lancez le dé une seule fois, vous obtenez 5. Pouvez-vous dire s’il est pipé ? Bien sûr que non. Vous le lancez 3 fois, vous obtenez 5, 4,5, êtes-vous plus informé·e ? Pas vraiment. Pour savoir s’il est pipé, il faudrait lancer le dé un grand nombre de fois, disons 6000 fois, et vérifier si obtient un peu près 1000 fois la face 1, 1000 fois la face 2 …Lorsque vous mené une expérimentation, vous avez lancé le dé une fois, ce qui signifie que la probabilité renvoyée par les logiciels de statistiques n’apporte pas d’autre information qu’indiquer si un effet est significatif ou non. Si Fisher (1955) avait une conception des probabilités qui suggérait que la probabilité obtenue était informative1, il y consensus à l’heure actuelle pour considérer que la conception de Fisher était erronée.\nPour beaucoup de chercheurs et de chercheuses, cette affirmation va tellement à l’encontre de ce qui est profondément ancré dans la manière dont ils et elles font des statistiques, que cela peut entre être déboussolant. Si des doutes persistent, il peut être utile de pouvoir bénéficier d’une petite démonstration.Reprenons l’exemple du questionnaire, vous menez une expérimentation dans laquelle vous comparez deux conditions. L’analyse statistique qu’va mener pour comparer ces deux conditions est un t de Student (Student, 1908) pour échantillon indépendants.Pour simuler les données, peut utiliser la fonction rnorm qui simule des données ayant une distribution normale. Par exemple, si veut simuler un échantillon de 20 personnes ayant une moyenne de 100 et un écart-type de 15, peut faire :Evidemment la moyenne n’aura pas exactement la valeur de 100, ni l’écart-type une valeur de 15. Ces valeurs pourront être plus ou moins éloignées en fonction des aléas de l’échantillonnage. Pour notre échantillon, nous obtenons :Grâce à cette fonction, nous allons pouvoir simuler un grand nombre de t de Student grâce à la fonction t.test et obtenir les probabilités associées à ces analyses. Le code ci-dessous va illustrer cette opération lorsqu’ne fait qu’un seul t de Student où les deux échantillons ont la même moyenne.Nous allons faire cela à présent un grand nombre de fois (à savoir 200 000) avec deux types de situations : une situation où compare deux échantillons issus de la même population (condition absence de différence) et une situation où compare deux échantillons issus de deux populations dont la différence est de 0.2 écarts-types (condition différence). Le code pour reproduire cette simulation est présenté ci-dessous. Cette simulation représente 200 000 études qui sont réalisées, dont l’hypothèse est fondée pour la moitié d’entre elles et non fondée pour l’autre moitié.Nous sommes à présent en mesure de nous mettre dans la peau du chercheur ou de la chercheuse qui est face à ses données. La première chose que nous allons décider est notre seuil \\(\\alpha\\), le seuil de décision statistique. Nous allons adopter une position simple et prendre comme seuil de décision 5%. Ce seuil est le pourcentage de faux positif que vous êtes prêt·e à tolérer à long terme, c’est-à-dire si vous deviez refaire un grand nombre de fois la même expérience où vous devriez tolérer l’hypothèse nulle.Deux questions se posent ici : 1) est-ce que le nombre de situations où la probabilité est inférieure seuil \\(\\alpha\\) correspond effectivement à 5% ; 2) quel est le pourcentage de situations où j’ai rejeté l’hypothèse nulle dans la condition **différence*. Par commodité, nous allons répondre aux deux questions en même temps.Le premier constat est que, quand répète la même expérimentation un grand nombre de fois, nous obtenons effectivement 5% de rejet de l’hypothèse nulle alors qu’elle devrait être tolérée. Concernant les situations où nous devrions rejeter l’hypothèse nulle car la différence est réelle, nous observons que l’effet est significatif dans 9% des situations. Cette valeur correspond à la puissance statistique, qu’peut vérifier aisément avec le package pwr (Champely, 2020) qui contient la fonction power.t.test. Cette fonction nous indique que la puissance est effectivement de 9%Les résultats de la simulation correspondent assez bien à ce que nous étions censés obtenir de manière théorique. Encart 1. Á propos des paramètres de la simulation.Il faut comprendre que nous aurions pu mener notre simulation avec d’autres paramètres. Nous aurions pu augmenter la puissance statistique de la situation de différence en augmentant la taille d’échantillon dans chacun de nos échantillons, mais nous aurions pu également changer le rapport entre les situations où nous devrions observer une différence par rapport à celles où ce n’est pas le cas. Si la puissance est particulièrement faible dans cette simulation, jusqu’à ces dernières années, ce n’était pas si rare d’observer des études avec une vingtaine de participants par groupe (voire moins, (Szucs & Ioannidis, 2017)) et une taille d’effet de 0,2 représente environ 36% des tailles d’effet en psychologie et neurosciences (Szucs & Ioannidis, 2017).Un autre paramètre qu’il est possible de modifier est la proportion d’hypothèses testées qui ont du sens par rapport à celles qui en ont moins. Dans notre exemple, nous avons autant d’expérimentation dans la condition présence d’une différence que dans la condition absence de différence. Cependant, cette vision est favorable au raisonnement selon lequel, si la valeur p est égale à 0.0001, plus de chances que la différence soit réelle. Néanmoins, Ioannidis (2005) avancent que la plupart des hypothèses testées ne devraient pas l’être car elles manquent de fondements justifiant de tester l’hypothèse. Il donne comme exemple une étude qui ferait une analyse sur les 100 000 polymorphismes génomiques afin d’identifier ceux susceptibles d’être associés à un risque de schizophrénie, si seuls une dizaine d’entre eux sont associés à la schizophrénie, alors comprend que, sur les 100 000 analyses réalisées, le risque d’avoir des effets significatifs est beaucoup plus élevé pour les polymorphismes qui ne sont pas associés à la schizophrénie que pour ceux qui le sont (n’oubliez pas qu’il y aussi un risque de faux négatifs). Vous pouvez faire des simulations différentes en changeant la répartition entre les conditions différences par rapport à absence de différence. Par exemple, si imagine que pour une bonne idée, deux idées ne sont pas satisfaisantes, alors vous pourriez utiliser la ligne de commande suivante :\nLe problème est que le chercheur ou la chercheuse n’pas accès à l’ensemble des échantillons possibles des populations. Il ou elle mène une expérimentation et doit prendre une décision sur la base d’une seule et unique expérimentation. Imaginons que l’expérimentation qui été menée, c’est l’expérimentation 15454, voici les résultats de cette étude particulière (en arrondissant à la \\(4^{ème}\\) décimale) :La probabilité est de 0.0001, l’effet est significatif. Si vous aviez eu une probabilité de 0.03, est-ce que vous auriez dit autre chose ? Non, dans les deux cas, c’est significatif. Vous avez fixé le seuil à 5% avant de mener votre expérimentation, vous ne pouvez pas le changer une fois que vous obtenez vos résultats. Dans notre simulation, nous avons 21 situations où la probabilité vaut exactement 0.03 (quand elle est arrondie à la \\(4^{ème}\\) décimale) pour la condition différence et il y en 5 pour la condition non-différence. Il y en donc 4,2 fois plus.Table 6.1: Expérimentations pour lesquelles la probabilité vaut exactement 0.03 dans la condition différence.conditionp.valuesignp.rond10.03003133oui0.0310.03003270oui0.0310.03003281oui0.0310.02995552oui0.0310.03001438oui0.0310.02997408oui0.0310.02999383oui0.0310.03002244oui0.0310.02997382oui0.0310.02998753oui0.0310.02996546oui0.0310.03001263oui0.0310.02997350oui0.0310.03002785oui0.0310.03000106oui0.0310.02996308oui0.0310.02995004oui0.0310.02996229oui0.0310.03002986oui0.0310.03004315oui0.0310.02997314oui0.03Table 6.2: Expérimentations pour lesquelles la probabilité vaut exactement 0.03 dans la condition absence de différence.conditionp.valuesignp.rond00.03003216oui0.0300.03002575oui0.0300.02998427oui0.0300.02997384oui0.0300.02998068oui0.03Intuitivement, vous vous dites que vous avez donc 4,2 fois plus de chances que cette expérimentation soit issue de la condition différence.Qu’en est-il à présent pour les situations où la probabilité arrondie vaut exactement 0.0001. Cela représente 40 situations.Table 6.3: Expérimentations pour lesquelles la probabilité vaut exactement 0.0001 dans la condition différence.conditionp.valuesignp.rond10.00014968727oui0.000110.00005884055oui0.000100.00006646775oui0.000110.00011611656oui0.000100.00006901200oui0.000110.00006868364oui0.000110.00012318743oui0.000110.00010176068oui0.000110.00010612005oui0.000110.00006607349oui0.000110.00005853225oui0.000110.00006131283oui0.000110.00006595854oui0.000110.00005909742oui0.000110.00005850616oui0.000110.00013808667oui0.000100.00006449358oui0.000110.00010922188oui0.000100.00006024203oui0.000110.00009713865oui0.000100.00014927947oui0.000100.00008221906oui0.000110.00014962026oui0.000110.00007810776oui0.000110.00011908708oui0.000110.00008400170oui0.000110.00009411372oui0.000100.00012101431oui0.000100.00009521599oui0.000110.00006910508oui0.000110.00012642834oui0.000110.00007243453oui0.000110.00013643819oui0.000110.00006174456oui0.000110.00012684684oui0.000110.00008282673oui0.000110.00012626133oui0.000110.00007654101oui0.000100.00005962663oui0.000100.00009698696oui0.0001Parmi ces 40 situations, il y en 10 qui proviennent de la condition absence de différence et 30 de la condition différence.Par rapport à la situation où s’intéressait à une probabilité de 0,03, le rapport entre les deux conditions diminué : vous n’avez à présent plus que 3 fois plus de chances que votre effet soit issu de la condition différence par rapport à la condition pas de différence. se rend compte ici que le raisonnement qui suppose que l’effet est plus significatif parce que la probabilité est plus faible ne tient pas.Néanmoins, nous allons continuer le raisonnement. Précédemment, nous avons établi que les résultats de votre expérimentation étaient ceux de l’expérimentation 15454. La question qui se pose est de savoir à quelle condition est-ce que cela appartient ? Maintenant, que vous savez qu’il y 10 expérimentations sur les 40 qui ont une probabilité égale à 0.0001 qui sont issues de la condition **absence de différence*, vous ne pouvez pas dire avec certitude la condition à laquelle elle appartient.Vous pourriez utiliser la stratégie de dire systématiquement “cela provient de la condition différence” parce que vous savez que sur le long terme, toutes choses étant égales par ailleurs, la condition différence sera plus souvent représentée. Vous auriez en partie raison sur ce point : sur le long terme, votre raisonnement tient mais ce n’est pas le cas pour une analyse isolée. Pour les résultats de votre expérimentation, il s’agit de la condition absence de différence. Néanmoins, dans ce cas, votre seuil de décision ne serait plus de 5% mais de 0,01% et il faudrait avoir décider de cette règle avant d’avoir recueilli (ou du moins analysé) les données.Il faut comprendre que, quand prend un seuil à 5%, cela signifie qu’il va y avoir 5% des expérimentations pour lesquelles la probabilité se situe entre 0.00000000000000001 et 0.049999999999999999. peut observer ce constat sur la Figure 6.1 qui est un échantillon de 1000 probabilités parmi les 200 000 probabilités qu’calculées précédemment. observe que, sur environ 500 échantillons de la condition absence de différence, il y environ 25 valeurs en dessous de 0.05, réparties entre 0.000001 et 0.04999999999. Remarquez aussi que, peu importe la condition, les probabilités se répartissent sur toute la hauteur, tant quand doit tolérer l’hypothèse nulle que lorsqu’doit la rejeter. Si une des probabilités changeait de condition pour savoir si vous être capable d’identifier la probabilité intrue, vous ne pourriez pas le faire.\nFigure 6.1: Représentation de la distribution des probabilités en fonction de la condition\n Encart 2. Sur la reproductibilité des résultats.Vous pourriez évoquer dans ce cas le fait qu’peut s’assurer des résultats en les répliquant puisque la reproductibilité des résultats est une propriété désirable de la science (Amir & Sharon, 1990). est ici confronté à trois problèmes :Il existe un problème de reproductibilité en psychologie (Bohannon, 2015; Open Science Collaboration, 2015), comme dans de nombreuses science, et cette crise ne semble pas beaucoup progresser (Hengartner, 2021; Klein et al., 2021).Si les résultats ne sont pas reproduits, est-ce que le problème vient de l’étude initiale ou de la réplication (Maxwell et al., 2015)?il est très difficile de publier une reproduction d’études (Clarke et al., 2024).Alors comment pouvez-vous savoir si, avec une valeur p pour une étude spécifique, vous avez eu une idée formidable ou une idée qui ne sera pas reproductible ? Vous ne pouvez pas réellement. Vous pouvez juste savoir quel sera votre taux d’erreur à long terme en connaissant les seuils de décisions et la puissance des études.\nUne fois qu’compris que, peu importe la probabilité renvoyée par le logiciel, la probabilité de rejeter à tort l’hypothèse nulle dépend du seuil de décision que nous avions initialement choisi, nous amène à comprendre qu’ne peut pas dire qu’une chance sur 10 000 de se tromper en disant que l’effet est significatif alors qu’il ne l’est pas. Il est de 5%. Néanmoins, même cette vision reste erronée car dit que l’effet est significatif dès lors que la probabilité renvoyée par le logiciel est inférieure à 0,05.Dans notre simulation, il y 5004 fois où l’effet est significatif alors qu’il ne devrait pas l’être et 9335 fois où il est significatif et il doit l’être. Ce qui signifie que le taux d’erreur de première espèce est de :\\[100 \\times\\frac{5004}{5004+9335} = 34,90 \\%\\]Bref, même si souhaiterait qu’elle nous apporte des informations sur la pertinence de notre hypothèse, la probabilité dans l’approche fréquentiste ne fournit pas d’autre information que le fait de savoir si l’effet est significatif ou non au seuil de décision que nous avons fixé et que nous considérons être un seuil satisfaisant pour rejeter, à long terme, de manière erronée l’hypothèse nulle alors qu’devrait la tolérer.","code":"\nechantillon<-rnorm(n = 20, # nombre de personnes\n                   mean = 100, # la moyenne\n                   sd = 15 ) # l'écart-type\nechantillon##  [1] 120.81463  90.98593  50.97039 105.07190  97.74540  90.79006 110.69123\n##  [8] 111.59649 111.22932 103.81360 110.45246 121.76581 131.97369  91.75430\n## [15]  69.40027  75.56120 116.65785  89.42626 110.20521  92.42593\nmean(echantillon)## [1] 100.1666\nsd(echantillon)## [1] 19.44035\n# on fait une comparaison de deux populations dont les moyennes sont strictement égales \nt.out<-t.test(rnorm(n = 20, # taille de l'échantillon 1\n                    mean = 0, # moyenne du groupe 1\n                    sd = 1), # écart-type de l'échantillon 1\n              rnorm(n = 20, # taille de l'échantillon 2\n                    mean = 0,# moyenne du groupe 2\n                    sd = 1) ) # écart-type de l'échantillon 2\nt.out## \n##  Welch Two Sample t-test\n## \n## data:  rnorm(n = 20, mean = 0, sd = 1) and rnorm(n = 20, mean = 0, sd = 1)\n## t = -0.18122, df = 36.322, p-value = 0.8572\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -0.7228546  0.6042382\n## sample estimates:\n##  mean of x  mean of y \n## -0.2204420 -0.1611339\nset.seed(1234) # le fait de mettre une graine assure une reproductibilité des résultats \n\n# on va créer une fonction qui compare deux moyennes qui sont strictement égales lorsque la condition vaut 0 et\n# dont les moyennes se différencient de 0,2 écart-type (d = 0.2) quand la condition vaut 1\n# La fonction renvoie la probabilité du test t \n\nF1<-function(cond = 0){ \n  if(cond==0){\n  # on fait une comparaison de deux populations dont les moyennes sont strictement égales \n  t.out<-t.test(rnorm(n = 20, # taille de l'échantillon 1\n                      mean = 0, # moyenne du groupe 1\n                      sd = 1), # écart-type de l'échantillon 1\n                rnorm(n = 20, # taille de l'échantillon 2\n                      mean = 0,# moyenne du groupe 2\n                      sd = 1) )# écart-type de l'échantillon 2\n  }else{ \n                        t.out<-t.test(rnorm(n = 20, # taille de l'échantillon 1\n                                            mean = 0, # moyenne du groupe 1\n                                            sd = 1), # écart-type de l'échantillon 1\n                                      rnorm(n = 20, # taille de l'échantillon 2\n                                            mean = 0.2,# moyenne du groupe 2\n                                            sd = 1) ) # écart-type de l'échantillon 2\n                      }\n  \n  return(c(t.out$p.value)) # renvoie la probabilité du test t \n  \n}\n\n# on crée des données (200 000) oour créer de manière aléatoire nos conditions. Elles sont au nombre de 200 000\n# ici l'échantillonnage se fait de manière équiprobable avec approximativement autant de situations pour la\n# condition différence qu'absence de différence \ndf<-data.frame(condition = sample(0:1, 200000, replace=T )) \n\n# on applique la fonction F pour chacune des lignes du jeu de données (variable condition)\ndf$p.value<-apply(df, 1, F1)\nlibrary(dplyr)\n\ndf$sign<-if_else(df$p.value<.05, \"oui\", \"non\") # créer une colonne qui indique si c'est significatif ou non\n\nT1<-table(df$condition, df$sign) # on fait une table \nT1##    \n##       non   oui\n##   0 94686  5004\n##   1 90975  9335\nround(prop.table(T1, 1),4)*100 # on obtient les proportions par ligne ##    \n##       non   oui\n##   0 94.98  5.02\n##   1 90.69  9.31\nlibrary(pwr)\n\npwr.t.test(n = 20,# la taille de l'échantillon dans chacun des groupes\n           d =0.2, # la taille d'effet \n           type=\"two.sample\") # le type de test de Student ## \n##      Two-sample t test power calculation \n## \n##               n = 20\n##               d = 0.2\n##       sig.level = 0.05\n##           power = 0.09456733\n##     alternative = two.sided\n## \n## NOTE: n is number in *each* group\ndf<-data.frame(condition = \n                 sample(0:1, 200000, \n              replace=T,\n              prob=c(2/3, 1/3) )) \ndf$p.rond<-round(df$p.value, 4)\ndf$p.rond[15454]## [1] 0.0001\ndim(df[which(df$condition==1 & df$p.rond==.030),])## [1] 21  4\ntable(df2$condition)## \n##  0  1 \n## 10 30\ndf[15454,]##       condition       p.value sign p.rond\n## 15454         0 0.00006646775  oui 0.0001"},{"path":"quelques-rappels-sur-lapproche-de-neyman-pearson.html","id":"quand-un-effet-négligeable-est-significatif","chapter":"6 Quelques rappels sur l’approche de Neyman-Pearson","heading":"6.2 Quand un effet négligeable est significatif","text":"Un aspect qui est souvent oublié dans l’approche fréquentiste est que, si vous rejeter l’hypothèse nulle, vous n’avez rejeté qu’une seule valeur : le zéro. Cependant, il semble peu vraisemblable qu’il y ait une quelconque situation ou la différence entre deux populations soit exactement égale à zéro et si elle n’est pas exactement égale à 0, peu importe à quel point la différence est petite, il sera possible d’avoir un effet significatif dès lors que votre échantillon est suffisamment grand. Pour l’illustrer, nous allons commencer par analyser la formule du t de Student comparaison à une norme et nous ferons ensuite une petite simulation qui vous donnera le taux d’effet significatif pour en fonction de la taille de l’échantillon.\\[\\begin{equation}\n  t =\\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}\n  \\tag{6.1}\n\\end{equation}\\]Où \\(\\bar{x}\\) est la moyenne de l’échantillon, \\(\\mu\\) est la moyenne de la population, s est l’écart-type, et n est la taille de l’échantillon. Imaginons que nous tirions à chaque fois des échantillons qui soit parfaitement représentatif de la différence entre la moyenne d’un échantillon et celle de la population, et que l’écart-type soit également estimé avec exactitude. se rend compte que plus l’échantillon augmenter, plus le dénominateur (à savoir \\(\\frac{s}{\\sqrt{n}}\\) diminue, ce qui amène finalement à ce que la valeur du t augmente. Si \\(\\sqrt{n}>s\\), alors la valeur est inférieure à 1 est diviser par un nombre par une valeur inférieure à 1 résulte en une valeur plus grande. Par exemple, \\(\\frac{1}{0.5}=2\\). , plus la valeur de la statistique est grande, plus la probabilité qui est associée à sa valeur est faible, ce qui amène donc au rejet de l’hypothèse nulle.Si vous n’êtes pas encore totalement convaincu·e, imaginons que nous testions le QI dans deux populations pour savoir laquelle est la plus intelligente et que la moyenne de la première population soit de 100 avec un écart-type de 15 et que la moyenne de la seconde population soit de 100.1, avec un écart-type de 15. D’un point de vue psychologique, s’il est raisonnable de considérer que cette différence est tellement ridicule qu’peut la négliger. Nous allons tester ce cas de figure en faisant varier la taille de l’échantillon et nous allons comptabiliser, pour chaque taille d’échantillon, le nombre de fois que l’effet sera significatif.\nFigure 6.2: Proportion d’effets significatifs sur 1000 essais pour différentes tailles d’échantillons\nLa Figure 6.2 illustre que, bien que la différence soit minimale, la proportion d’effet significatif est proche de 100% dès lors que la taille de l’échantillon est suffisamment grande.Vous pourriez vous dire que la taille d’échantillon doit vraiment être considérable pour avoir quasiment à coup sûr un effet significatif mais que, dans des situations réelles, n’observe pas des échantillons aussi grands. Pourtant, il n’est pas rare de tester quelques centaines de personnes pour valider une échelle. Ainsi, peut observer que, dans une étude où 526 personnes ont pris part à l’étude, peut être embêté pour interpréter les résultats d’une analyse censée montrer une validité divergente2 et qu’obtient une corrélation 0.08 qui est significative, comme c’est le cas dans l’étude de Dalagi (2024). L’interprétation qu’en donne les auteures : il y une corrélation mais elle est très modérée. Nous verrons comment, dans une telle situation, une approche bayésienne peut apporter un éclairage différent.Cet exemple illustre ce que nous évoquions précédemment : dans un contexte de recherche, penser qu’une variable indépendante n’absolument aucun effet sur une variable dépendante ou qu’une corrélation entre deux variables vaut exactement 0 ne fait en effet généralement pas sens. Même lorsque la théorie est fausse, il y forcément d’autres raisons pour lesquelles il existe une relation, ne fût-ce que minime, entre les variables (Dienes, 2008).","code":""},{"path":"quelques-rappels-sur-lapproche-de-neyman-pearson.html","id":"quand-la-règle-darrêt-vient-tout-changer","chapter":"6 Quelques rappels sur l’approche de Neyman-Pearson","heading":"6.3 Quand la règle d’arrêt vient tout changer","text":"Vous avez sans doute déjà entendu parler de p hacking ou de triturage des données, cette pratique consistant à réanalyser les données de différentes manière jusqu’à l’obtention d’un effet significatif. Cette pratique fait partie de ce qu’appelle les pratiques de recherche questionnables (par ex., Neoh et al., 2023).Cependant, dans le questionnaire que vous avez réalisé précédemment, la situation ne semblait pas révéler une intention de triturer les données pour obtenir des résultats mais simplement de faire la partie statistique d’une mémoire une année 1. Ce que l’énoncé ne dit pas, c’est qu’aurait fait notre scientifique si l’effet avait été significatif avec 35 participants. La tentation est grande de s’arrêter là : finalement pourquoi dépenser encore beaucoup d’énergie et de temps pour continuer le recueil alors que l’effet est présent et qu’sait que, plus la taille de l’échantillon est grande, plus l’effet risque d’apparaître. Ce comportement, bien qu’il ne soit pas associé à une intention de frauder, correspond tout à fait du p-hacking. Voyons comment le taux d’effet significatif va évoluer si compare deux conditions avec une taille d’échantillon de 35, s’arrête si c’est significatif, ou ajoute 15 personnes si cela ne l’est pas.observe ici que le taux de rejet à tort de l’hypothèse nulle n’est plus de 5% mais 9.7%.Cette valeur correspond à l’augmentation du taux d’erreur qu’devrait obtenir de manière théorique pour 2 analyses. peut en effet estimer le taux d’erreurs en fonction du nombre d’analyses grâce à l’équation (6.2) :\\[\\begin{equation}\n  \\alpha_{famille} =1- (1-\\alpha)^n\n  \\tag{6.2}\n\\end{equation}\\]Où _{famille} est le taux \\(\\alpha\\) pour une famille de tests , \\(\\alpha\\) est le seuil de décision et n est le nombre d’analyses qui ont été réalisées. Dans notre exemple, deux analyses ont été réalisées, ce qui nous amène à :\\[1 - (1  - 0.05)^2= 0.0975\\] Lorsqu’se retrouve dans cette situation, doit corriger la probabilité pour maintenir les erreurs à rejeter à tort H0 à 5%.Cet exemple illustre un phénomène central de l’approche de Neyman-Pearson (Neyman & Pearson, 1933) à savoir qu’elle est sensible aux règles d’arrêt. C’est pour cette raison que le calcul de la puissance est aussi important (voir par ex., Cohen, 1988) et qu’vous apprend à le faire. C’est aussi pour cette raison qu’vous incite à pré-enregistrer vos recherches afin qu’puisse s’assurer que la taille d’échantillon correspond à ce qui avait été annoncé (Lakens, 2019; Nosek et al., 2018; Wagenmakers et al., 2012).","code":""},{"path":"les-probabilités-objectif-ou-subjectif.html","id":"les-probabilités-objectif-ou-subjectif","chapter":"7 Les probabilités : objectif ou subjectif","heading":"7 Les probabilités : objectif ou subjectif","text":"La conception des probabilités dans l’approche de Neyman-Pearson (Neyman & Pearson, 1933) est une conception objective des probabilités, il s’agit du taux d’erreur à long terme. Cependant, il existe d’autres conceptions des probabilités, notamment une conception subjective (Hájek, 2012; Rocchi & Gianfagna, 2013).Il faut comprendre que ces deux approches sont radicalement différentes avec de farouches défenseurs de part et d’autre. Ainsi, certains auteurs n’adhèrent qu’à une conception purement objective des probabilités (Mises, 1957; Venn, 1876) alors que d’autres sont à l’extrême opposé et ne considère les probabilités que comme un phénomène purement subjectif (voir par ex., Finetti, 1974).Mais comment une probabilité pourrait-elle bien être subjective ? Revenons en arrière, nous sommes le 30 mai 2025, la veille de la finale de la ligue des champions. Les supporters du PSG croient durs comme fer que leur équipe va gagner ; les supporters de l’inter n’en sont pas moins convaincus que ceux du PSG. Les supporters de l’OM espèrent que l’inter l’emportera alors que les supporters de l’AC Milan soutiennent ouvertement le PSG. Les supporters du Standard de Liège (en Belgique), eux, se disent que cela va être un beau match. Bref, chacun son opinion, sa croyance sur le fait de savoir qui va gagner. Finalement, le PSG gagne. Les croyances de beaucoup de personnes se sont avérées fausses. Même parmi les supporters du PSG qui aurait parié sur un résultat 5-0. Bien peu de personnes : la cote pour un résultat 5-0 était de 36 pour 1.Ces croyances sont omniprésentes : je pense qu’il va neiger demain, je ne crois pas qu’il va venir, je suis sûr que je peux négocier le prix de ma nouvelle voiture blanche… Tous ces exemples renvoient à une conception subjective des probabilités, c’est-à-dire la croyance qu’une personne qu’un événement va survenir.Cette conviction qu’un événement va survenir est propre à chacun·e. Il n’y pas de bonne réponse. La croyance que vous avez en quelque chose renvoie à la notion de probabilité priori dans la conception bayésienne.","code":""},{"path":"la-probabilité-a-priori.html","id":"la-probabilité-a-priori","chapter":"8 La probabilité a priori","heading":"8 La probabilité a priori","text":"Nous avons précédemment vu que le théorème de Bayes nécessitait de connaître la probabilité de l’hypothèse avant d’avoir recueilli les données. Cela peut sembler étrange à première vue à des chercheurs et chercheuses biberonné·es à l’approche fréquentiste. ne vous jamais demandé de réfléchir à la probabilité de votre hypothèse.Pourtant, si y réfléchit un instant, quand fait une analyse fréquentiste, par exemple, un t de Student, déjà toute une série de présupposés, comme la distribution des données suit une distribution normale, les variances sont homogènes, ou encore l’échantillon est suffisamment grand pour mettre en évidence l’effet qu’cherche à observer. Pourquoi ne pourrait-pas avoir un présupposé supplémentaire sur la probabilité que l’hypothèse est vraie ?La première fois qu’est confronté à cette situation, peut se questionner sur la manière dont il est possible d’attribuer une valeur précise à une hypothèse. peut également être perturbé par le fait que l’inférence bayésienne requiert qu’ait à donner une opinion sur la pertinence d’une théorie. Après tout, la science doit être objective dans le sens où quiconque essaierait de reproduire des résultats devraient obtenir les mêmes résultats (K. R. Popper, 1959). , si pour appliquer Bayes, donne notre opinion, une sorte de niveau de crédit qu’accorde à une théorie, comment une personne qui ne partagerait pas notre opinion pourrait obtenir les mêmes résultats ? Nous répondrons à cette question plus loin et commençons par nous rendre compte que, en réalité, ce n’est ni si compliqué, ni si aberrant et que, en réalité, vous le faites déjà.","code":""},{"path":"la-probabilité-a-priori.html","id":"une-approche-intuitive","chapter":"8 La probabilité a priori","heading":"8.1 Une approche intuitive","text":"Un des points critiques de l’approche bayésienne est que les personnes qui souhaitent changer de pratique pour adhérer à l’approche bayésienne se retrouvent souvent perdu·e quand il s’agit de réfléchir à la probabilité priori d’une théorie. Pourtant, si y réfléchit un instant, demandez-vous si les scientifiques accordent vraiment la même probabilité à toutes les théories et se rendre compte que, en réalité, ce n’est pas le cas. N’y -t-il pas des points de vue divergents sur l’explication des données ? N’y -t-il pas des guerres de chapelle pour un peu près toutes les théories de la psychologie, et de la science en général. Qu’en est-il des personnes qui affirment que les vaccins sont non seulement inefficaces mais sont à l’origine des plus graves maladies, comme les troubles du spectre autistique ? En physique, l’existence même de la théorie des cordes est controversée. Est-ce que toutes les personnes qui essaient de proposer un cadre théorique cohérent en s’appuyant sur cette théorie doivent être considérés comme des hurluberlus ?Vous-même, n’êtes-vous pas disposé·e à adhérer plus à certaines théories qu’à d’autres ? Faisons un petit exercice qui vous amènera à prendre conscience que c’est le cas. Dans cet exercice, vous devez classer des théories selon que le niveau de croyance que vous leur accordez. Il n’y pas de bonnes ou de mauvaises réponses, c’est quelque chose de personnel.Á présent, revenons au tout début de la session. Je vous ai annoncé que je donnerais 50€3 aux personnes qui ne changeraient pas radicalement leur manière de mener leurs analyses et de mener leurs recherches. La contrepartie était de savoir combien vous seriez disposé à parier. Ainsi, si vous avez misé plus de 50€, disons 200€, cela signifie que vous êtes à peu près sûr·e que, peu importe ce que je vais dire dans la formation, vous ne changerez pas d’un iota. En revanche, si vous n’êtes prêt·e à miser qu’un euro, c’est que vous désirez profondément changer votre manière de faire des recherches et que vous m’accorder une confiance presque totale pour vous ouvrir la voie vers de nouvelles perspectives.peut facilement estimer la probabilité que vous accordez à la théorie selon laquelle vous allez changer profondément votre manière de penser vos recherches grâce à ce pari.Si vous étiez prêt·e à miser 50€, cela signifie que vous accordez autant de chance au fait de pouvoir changer grâce à cette session qu’au fait de continuer à utiliser vos pratiques actuelles. Votre probabilité priori est de 50%. Si vous étiez prêts à mettre 200 euros, c’est que vous croyez quatre fois plus dans le fait que l’hypothèse est fausse que dans le fait qu’elle soit vraie, ce qui nous donne \\(\\frac{200}{200+50}= 0.80\\). Vous accordez 80% de chances à l’hypothèse que vous ne changerez pas votre manière de penser la science, donc 20% à l’hypothèse que vous allez être chamboulé·e après cette formation. Á l’inverse, si vous n’étiez disposé·e à muser qu’un euro, cela signifie que vous accordez une probabilité de \\(\\frac{1}{1+50}= 0.019\\) au fait que vous ne changerez pas vos pratiques. Vous êtes sûr·e à 98% que cette session va profondément modifier votre manière de penser vos recherches.Vous pouvez adopter ce raisonnement avec n’importe quelle théorie. Prenez le temps de réfléchir à votre dernière recherche, ou à la prochaine. Imaginez à présent que vous deviez décider de miser soit sur la pertinence de votre théorie (dans le sens où en récoltant des données, vous allez avoir des preuves qui vont venir la soutenir) soit sur un tirage au sort. Pour le tirage au sort, vous avez un sac avec deux billes : une noire et une rouge. Le pari est de tirer rouge4. Est-ce que vous placez votre pari sur votre théorie ou sur le tirage au sort ? Si vous le placez sur le tirage au sort, alors vous accordez un crédit inférieur à 0.5 à votre théorie. Si vous misez sur votre théorie, vous lui accordez un crédit supérieur à 0.5. peut affiner : la répartition des billes dans le sac change : vous avez deux rouges pour une noire. Préférez-vous parier sur le fait de tirer rouge ou sur votre théorie ? Si vous préférez miser sur votre théorie, c’est que vous lui accordez une probabilité supérieure à 0.66 (\\(\\frac{2}{2+1}\\)). Vous pouvez continuer à ajuster votre probabilité avec n’importe quelle répartition de billes qu’il est nécessaire pour atteindre le niveau de précision souhaité.Appliquer ce genre de raisonnement permet d’éviter d’accorder une probabilité priori déraisonnable à votre théorie, en affirmant par exemple que vous êtes sûr·e à 99.999% que les vaccins sont la cause du trouble du spectre autistique.\nVous pourriez encore vous dire que, si vous tester une théorie, c’est que vous lui accordez suffisamment de crédit pour qu’elle mérite que vous vous y intéressiez. En fait, les choses ne peuvent pas être aussi simples : certaines théories sont tellement évidentes que les tester ne sera qu’une perte de temps. Par exemple, quand je lève un bras, au bout d’un moment, j’ai mal. Il est probable que personne ne s’intéresse à cette théorie5. Á l’inverse, certaines théories peuvent avoir de grandes applications mais peuvent sembler peu crédible priori. La théorie de la relativité d’Einstein n’pas tout de suite eu le succès retentissant qu’elle aujourd’hui (pur une critique de cette théorie, voir par exemple Poor, 1922). Par exemple, si je vous demandais si la théorie sous-tendant l’homéopathie6 mérite d’être d’être testée, où la placeriez-vous ?","code":""},{"path":"la-probabilité-a-priori.html","id":"construire-une-distribution-a-priori","chapter":"8 La probabilité a priori","heading":"8.2 Construire une distribution a priori","text":"Arrivé à ce stade, vous avez une idée de ce que signifie la probabilité priori d’une hypothèse et la manière dont peut la formaliser. Cependant, ce n’est pas simple de comprendre comment peut appliquer ce raisonnement pour arriver à mener des inférences.Un cas de figure particulièrement fréquent en psychologie est de comparer des moyennes. Comment est-il possible de passer d’une situation où accorde une confiance à 80% à une théorie à une situation où c’est utile pour faire mon t de Student ?Une réponse précise à cette question est quelque peu technique et pourrait être rebutant. Nous allons donc aborder les choses de manière un peu plus accessible. Dans tous les cas, construire une distribution priori est sans doute la partie la plus difficile dans l’utilisation de l’approche bayésienne. Dans cette section, l’objectif est d’expliquer la logique sous-tendant la construction d’une distribution priori. Dans la section suivante, nous évoquerons une manière beaucoup plus simple de le faire, mais l’exercice est utile pour comprendre ce que la logique sous-tendant la section suivante s’appuie directement de celle-ci.Concrètement, ce qu’veut savoir, c’est dans quelle zone est que nous avons la plus forte probabilité que notre effet soit observé. Donc, tout comme dans l’approche fréquentiste où va calculer la puissance statistique pour une taille d’effet que nous estimons raisonnablement pouvoir observer, la construction d’une distribution priori raisonnable requiert d’être expert du domaine dans lequel veut mener l’étude. Si ne se sent pas suffisamment expert, peut regarder les effets qui sont habituellement observés dans le domaine qu’veut investiguer en examinant par exemple des méta-analyses. peut également se questionner sur la taille d’effet minimale qui vous amènerait à considérer que votre étude du sens.Dans mon cas, je travaille sur l’apprentissage implicite en utilisant une tâche de temps de réaction sériel (Nissen & Bullemer, 1987). Dans cette tâche, les participants doivent réagir le plus rapidement et le plus précisément possible à l’apparition d’un stimulus en fonction de sa localisation (voir Figure 8.1). Á l’insu des participants, les stimuli n’apparaissent pas de manière aléatoire mais suivent une séquence. L’apprentissage se manifeste par des temps de réaction de plus en plus courts au fur et à mesure que la séquence est répétée et augmente drastiquement lorsqu’expose les participants à une nouvelle séquence.\nFigure 8.1: Illustration d’une tâche de temps de réaction sériel.\nLa question qu’se pose ici est de savoir si les participants ont appris la séquence7.Pour construire la distribution priori, il est nécessaire d’avoir des connaissances sur cette tâche :pour répondre à un stimulus en fonction de sa localisation, des personnes jeunes prennent en moyenne environ 400-450 ms par stimulus.si demande à des personnes de répondre le plus rapidement possible à un stimulus visuel (sans notion de localisation), obtiendrait une moyenne située entre 200 et 250 ms.les temps de réaction manquent de fiabilité et ils sont donc associés à une variance assez importante.La tâche est longue et ennuyeuse et certaines personnes peuvent se lasser et/ou se déconcentrer.Une fois qu’connait suffisamment le protocole et les variables que nous mesurons, va devoir se questionner sur deux points :quelle amélioration est-ce que je peux m’attendre à avoir sur les temps de réaction ;comment cette amélioration pourrait se répartir.Réfléchissons au premier point. Vu que des personnes ne peuvent pas répondre à des stimuli simples en moins de 200-250 ms, il ne semble pas raisonnable de penser que, en moyenne, les participants puissent avoir une amélioration de plus de 200 ms. Á l’inverse, si l’amélioration des temps de réaction était de l’ordre de 10 ms, pourrait considérer que l’apprentissage ne semble pas contribuer de manière substantielle à la bonne réalisation de la tâche. Si est moyennement optimiste sur notre procédure, un objectif raisonnable est de se dire qu’obtiendra une amélioration d’environ 50 ms (ce qui représenterait une amélioration de 12,5% des temp de réaction \\(\\frac{400-350}{400}\\)). Si est très optimiste, peut imaginer une amélioration de 100 ms, donc un amélioration de 25% des temps de réaction. peut choisir l’un ou l’autre, ou éventuellement couper la poire en deux et se mettre d’accord sur 75 ms. Dans la Figure 8.2, la ligne verticale rouge représente les temps à 400 ms pour le premier bloc et la verticale bleue représente l’amélioration de 75 ms.Á présent qu’une idée de l’amélioration des temps de réaction, il ne semble pas plausible que notre procédure va permettre d’obtenir une différence d’exactement 75 ms. peut se questionner sur les limites entre lesquelles la différence pourrait varier. sait que les temps de réaction varient entre 200 et 250 ms pour stimuli simples et entre 400-450 pour les premiers blocs de la tâche de temps de réaction sériel. peut donc se dire que la variabilité sera au maximum de 50 ms.Nous allons à présent vérifier si cette hypothèse tient la route. Vu que la moyenne des temps de réaction de l’ensemble des participants ne peut raisonnablement pas être inférieure à 250 ms, il s’agit de l’amélioration maximale qu’peut envisager. Nous l’identifierons par la ligne jaune sur la Figure 8.2.\nsait que 95% des observations se situent entre -1.96 et +1.96 écart-types. Donc, si estime que l’amélioration moyenne est 75 ms, et que cette amélioration peut se situer quelque part entre -2 et +2 écart-types autour de cette amélioration moyenne (hypothétique), cela signifie que les temps de réaction qu’pourra observer après apprentissage seront situés entre 227 ms et 423 ms. Cet intervalle est représentée par la zone verte dans la Figure 8.2.\nFigure 8.2: Vérification de la plausibilité des hypothèses dans la construction d’une distribution priori.\nDans la Figure 8.2, observe que, au lieu d’améliorer les temps de réaction, les participants pourraient ralentir (la zone au-delà de la barre verticale rouge). Cette supposition n’est pas complètement déraisonnable car la tâche est rébarbative. peut estimer la probabilité d’observer ce phénomène avec la fonction pnorm.6.6% de chances de ne pas avoir d’apprentissage du tout.estimait également qu’il n’était pas raisonnable que les participants puissent répondre en moyenne en-dessous de 200-250 ms. En l’occurrence, la zone verte ne descend pas en-dessous de 200 ms, mais descend en-dessous de 250 ms. Avec les hypothèses que nous avons faites concernant les paramètres, cela signifie que cela surviendrait dans presque 7% des situations.Ainsi, ne l’exclut pas totalement mais imagine que cela ne devrait pas arriver fréquemment. doit à présent se demander si les hypothèses sont satisfaisantes ou s’il faut les ajuster. Peut-être qu’il est raisonnable de considérer qu’une absence d’apprentissage pourrait être plus fréquente que dans 7% des situations. pourrait alors réduire l’effet d’apprentissage et revenir à l’hypothèse d’une amélioration des 50 ms, ou pourrait augmenter l’écart-type. Dans le premier cas, cela rendrait moins probable d’avoir une amélioration qui amènerait les participants à répondre en moins de 250 ms en moyenne ; dans le second cas, cela rendrait également plus probable le fait d’avoir des temps moyens inférieurs à 250 ms. Donc, si n’est pas totalement satisfait avec une amélioration moyenne de 75 ms, le changement qui semble le plus raisonnable est d’ajuster la moyenne. peut évidemment ajuster la moyenne et l’écart-type.Il est indispensable de se rappeler de deux points :cette distribution priori représente la manière dont les résultats moyens pourraient survenir et non les résultats individuels. Ce sont des hypothèses que vous faites sur les résultats qu’il est vraisemblable ou non d’obtenir.Dans tous les cas, l’avis ultime correspondra à l’opinion personnelle du psychologue et dépendra entièrement de lui.","code":"\nz<-(400-325)/50\n\npnorm(z, lower.tail=F)## [1] 0.0668072\nz<-(250-325)/50\n\npnorm(z, lower.tail=T)## [1] 0.0668072"},{"path":"la-probabilité-a-priori.html","id":"envisager-les-priors-comme-des-tailles-deffets.","chapter":"8 La probabilité a priori","heading":"8.3 Envisager les priors comme des tailles d’effets.","text":"Lorsque nous passerons à la partie exercices, nous verrons qu’ne devra pas réaliser cet exercice de réflexion sur les données car nous utiliserons le package BayesFactor (Morey & Rouder, 2024). La logique qui sous-tend l’utilisation de ce package été largement décrite dans des revues de psychologie (Morey & Rouder, 2011; Rouder et al., 2009, 2012) et s’appuie sur la conception de Jeffreys (1961) pour établir la distribution priori. Encart 3. Différence entre une distribution normale et une distribution Cauchy.Pour des raisons techniques, la distribution qui est utilisée dans le package BayesFactor (Morey & Rouder, 2024) est une distribution Cauchy.va de suite relativiser l’importance de cette décision en comparant les deux courbes : excepté le fait que la distribution Cauchy est plus pointue que la distribution normale, les deux courbes se ressemblent. Ce n’est que sur les valeurs extrêmes où va observer des petites différences entre les deux distributions (voir Figure 8.3)\nFigure 8.3: Comparaison d’une distribution Cauchy avec une distribution normale.\n\nDans cette manière d’envisager l’approche bayésienne, l’objectif n’est plus de se demander quelle valeur exacte va observer, mais plutôt quelles tailles d’effet sont plausibles avant d’avoir vu les données. Concrètement, si l’répète un grand nombre de fois la même expérience en s’attendant à une petite taille d’effet (par exemple \\(d_{\\text{Cohen}} = 0.2\\)), pourrait observer des tailles d’effet légèrement plus grandes (par exemple 0.5), ou plus petites (comme -0.1).La distribution des tailles d’effet sous l’hypothèse alternative est alors modélisée par une loi de Cauchy centrée en 0, qui reflète notre incertitude. Cette loi est large, mais il est irréaliste que la vraie taille d’effet soit aussi extrême que 6. À l’inverse, si l’s’attend à une grande taille d’effet (disons \\(d_{\\text{Cohen}} = 1\\)), pourrait observer des valeurs comme 1.5 ou 0.5, mais il devient alors moins probable d’observer une valeur proche de 0.Examinez maintenant la Figure 8.4. Prenons le cas où l’s’attend à une taille d’effet relativement grande, disons \\(d = 1\\). Si le rscale vaut 0.2 ou 0.5, la hauteur sous la courbe est faible autour de 1 ; en revanche, cette densité augmente pour des valeurs de rscale plus élevées comme 1 ou 1.41. Il est donc préférable, dans ce cas, d’utiliser un rscale de 1 ou 1.41, car cela reflète mieux nos attentes.Inversement, si l’pense que la taille d’effet est petite (par exemple \\(d = 0.2\\)), la hauteur de la distribution priori est plus élevée autour de cette valeur lorsque le rscale est fixé à 0.5. Toutefois, si choisit un rscale très faible, comme 0.2, la courbe devient très concentrée autour du zéro : donne alors beaucoup plus de poids à l’absence d’effet qu’à la présence d’un petit effet — ce qui peut rendre difficile la détection de ce dernier.Ainsi, le choix du rscale revient à un compromis entre la hauteur du prior au point que l’souhaite mettre en évidence (ex. d = 0.2 )) et la hauteur au niveau de l’absence d’effet (\\(d = 0\\)). Il s’agit de maximiser ce rapport, qui influence directement le Bayes factor.Rouder (2009) propose des valeurs de référence pour le rscale en fonction de la taille d’effet attendue :petite taille d’effet : rscale = 0.707taille d’effet moyenne : rscale = 1grande taille d’effet : rscale = 1.41Ces valeurs sont intégrées directement dans le package BayesFactor (Morey & Rouder, 2024), comme nous le verrons plus loin.\nFigure 8.4: Priors sur une distribution Cauchy sur la taille d’effet standardisée (δ)\n","code":""},{"path":"la-probabilité-a-priori.html","id":"quelques-remarques-supplémentaires","chapter":"8 La probabilité a priori","heading":"8.4 Quelques remarques supplémentaires","text":"Bien que la possibilité de fixer votre distribution priori ne doit plus avoir de secrets pour vous à présent, l’idée que les résultats de vos analyses puissent dépendre de vos opinions pourrait vous gêner.Il est vrai que, si utilise pour la distribution priori une très grande variance, c’est-à-dire que l’incertitude concernant la taille d’effet est très grande, alors vous pouvez artificiellement modifier les résultats. D’après Rouder (2009), cela survient quand l’incertitude concernant la taille d’effet sont supérieures à \\(\\delta > 6\\). En choisissant une distribution aussi indéterminée, privilégierait l’hypothèse nulle. Ceci s’explique par le fait que, avec une distribution très large, la théorie qu’souhaite tester est compatible avec une large gamme de résultats. Une théorie vague peut être compatible avec des données qui ont été obtenues, mais celles-ci la soutiennent peu si cette théorie peut s’accommoder de pratiquement n’importe quelles données. Ce phénomène s’appelle le paradoxe de Jeffreys–Lindley (Lindley, 1957). Comparez ici l’approche bayésienne avec l’approche fréquentiste. Dans l’approche fréquentiste, l’objectif est d’exclure une valeur : le 0. Dès lors que la probabilité de dépassement est inférieure à 0.05, le zéro est exclu et beaucoup en sont satisfaits, Á l’inverse, c’est le coeur de l’analyse bayésienne de punir celles et ceux dont les théories sont vagues (Dienes, 2008).Cependant, est-il vraiment raisonnable de penser qu’puisse avoir des tailles d’effets supérieures à 6, voire même à 2 ? En vous entraînant à réaliser une distribution priori avec vos hypothèses, non seulement vous prendrez conscience que ce n’est pas si difficile mais surtout cela vous amènera à réfléchir plus en profondeur à votre théorie et à faire des prédictions plus audacieuses. En ce sens, l’approche bayésienne rejoint l’esprit poppérien qui faisait l’apologie du risque (K. R. Popper, 1959)Le second point à avoir à l’esprit est que, si les données sont suffisantes, les données vont faire converger vers la même probabilité posteriori, qu’importe la distribution priori choisie tant que les tailles d’effets envisagées sont raisonnables. L’objectif est seulement de savoir si vous avez une représentation précise de ce que votre théorie permet de prédire (Dienes, 2008). Vous pouvez facilement savoir si vous avez recueilli assez de données en utilisant une approche robuste dans l’utilisation de l’inférence bayésienne, qui consiste à comparer les valeurs des facteurs de Bayes (nous verrons bientôt de quoi il s’agit) Évidemment, les fonctions adaptées sont déjà implémentées dans R.Si cela ne vous suffit pas et que vous n’êtes toujours pas très à l’aise avec le fait de placer une probabilité sur votre hypothèse, il existe une autre alternative : placer une distribution priori qui n’est pas informative. L’idée est de considérer que vous n’avez aucune raison de préférer une hypothèse plutôt qu’une autre (Al-Hujaj & Harney, 1997; Berger & Pericchi, 2001). Dans ce cas, seule la vraisemblance des données déterminera votre probabilité posteriori. Cette approche est ce qu’appelle est les bayésiens objectifs Al-Hujaj & Harney (1997). Cette approche est finalement assez similaire à l’école de vraisemblance (Royall, 1997) qui, avec l’approche fréquentiste et l’inférence bayésienne, représente la troisième grande école d’inférences statistiques.Si fondamentalement, les tenants de l’approche objective ne s’opposent pas à l’approche subjective, et considèrent même qu’être capable de fixer une distribution priori représente la situation idéale, il y néanmoins deux raisons qui justifient de favoriser l’approche objective. La première est celle que nous évoquons insidieusement depuis le début de cette partie : quand mène des analyses statistiques, il peut être nécessaire de donner une apparence d’objectivité. Cette raison n’est sans doute pas la plus importante dès lors qu’est capable de justifier le choix de la distribution priori. La seconde raison est pragmatique : lorsque les modèles deviennent complexes, la spécifications attentives des distribution priori subjectives pour tous les paramètres du modèle peut devenir ardu8. Il semble plus raisonnable de sélectionner des modèles avec des valeurs par défaut et, dans un second temps, préciser les distributions priori pour le modèle sélectionner (Berger & Pericchi, 2001).Pour terminer sur les distributions priori, de manière théorique, il est envisageable de modéliser un autre distribution qu’une distribution normale. Cependant, comme l’objectif est de présenter la manière d’utiliser le package BayesFactor (Morey & Rouder, 2024), et que les fonctions de packages ne requiert pas d’avoir plus qu’une idée de la taille d’effet que vous supposez pouvoir observer pour utiliser les fonctions de ce package, il ne semble ni opportun ni utile de présenter plus en détail ces cas de figures. Le lecteur intéressé pourra consulter Rossi (2005) et Dienes (Dienes, 2008).","code":""},{"path":"la-vraisemblance.html","id":"la-vraisemblance","chapter":"9 La vraisemblance","heading":"9 La vraisemblance","text":"","code":""},{"path":"la-vraisemblance.html","id":"une-explication-intuitive","chapter":"9 La vraisemblance","heading":"9.1 Une explication intuitive","text":"Vous venez de vous disputer avec une personne que vous savez être\nrancunière. Pourtant, le lendemain de votre dispute, cette personne\nvient sonner à votre porte, vous prie de l’excuser de son comportement\nde la veille et souhaite se faire pardonner en vous offrant un cadeau.Après avoir accepté le présent, vous vous rendez compte que quelque\nchose bouge à l’intérieur. Dans un premier temps, vous vous dites que\nc’est sans doute un mignon petit chaton. Cependant, après quelques\ninstants de réflexion, vous vous rappelez que la personne avec laquelle\nvous vous êtes disputée est rancunière et vous vous demandez s’il ne\ns’agirait pas plutôt d’un diable de Tasmanie et si la personne vous \nfait ce présent pour se débarasser définitivement de vous. Vous vous\ndites que vous allez introduire un morceau de viande à l’intérieur de la\nboîte parce que vous savez que vous avez 90% de chances que le morceau\nsoit dévoré s’il s’agit d’un diable de Tasmanie. Vous n’oubliez tout de\nmême pas que les chats sont carnivores et qu’il y 10% de chances qu’un\npetit chaton arrive à manger le morceau de viande que vous avez\nintroduit.Après avoir introduit le morceau de viande, vous attendez un instant,\nvous tirez sur la corde à laquelle le morceau était solidement attaché,\nplus rien. Est-ce que c’est un diable ou un chaton ?Si vous pensez que vous êtes probablement face à un diable de Tasmanie, vous avez saisi l’idée de vraisemblance. Dans le cas contraire…","code":""},{"path":"la-vraisemblance.html","id":"définition","chapter":"9 La vraisemblance","heading":"9.2 Définition","text":"La vraisemblance est la probabilité d’observer des données pour une\nhypothèse donnée. La seconde partie de la phrase est particulièrement\nimportante. La probabilité d’observer des données dépend de l’hypothèse\nqu’est en train d’examiner. Prenons les données présentées ci-dessous.Sans faire de calcul, demandez-vous quelle pourrait être la moyenne et quel pourrait être l’écart-type. En faisant cet exercice, vous faites une hypothèse concernant cette moyenne et cet\nécart-type, hypothèse qui pourra être plus moins proche de la réalité.\nSi vous êtes très proche de la réalité, la probabilité d’observer les\ndonnées sera élevée, si vous l’êtes moins, cette probabilité va\ndiminuer.\nAstuce \nPour vous aider dans vos estimations, la valeur la plus petite est\n13 et la plus grande est 56, sachant que 95%\ndes données se situent entre -2 et +2 écart-types, cela devrait vous\naider à estimer l’écart-type.Nous reviendrons au calcul précis de la vraisemblance pour ces données un\npeu plus loin mais commençons à expliquer le calcul de la vraisemblance\npar un exemple simple.","code":"##  [1] 45 20 15 30 29 29 32 46 35 27 28 16 34 24 56 30 40 19 13 46"},{"path":"la-vraisemblance.html","id":"un-exemple-simple","chapter":"9 La vraisemblance","heading":"9.3 Un exemple simple","text":"Vous jouez aux dés et vous faites l’hypothèse que le dé est équilibré.\nVous lancez le dé 20 fois, vous obtenez 10 fois le 6, et 2 fois chacune\ndes autres valeurs. peut obtenir la vraisemblance d’avoir 10 fois la\nvaleur 6 en 20 essais en utilisant la binomiale. Dans R, l’obtient\nfacilement avec la fonction binom.test.La probabilité d’observer exactement 10 fois 6 sur les 20 lancers vaut r round(bi$p.value, 6). Cette probabilité, assez faible, est la vraisemblance d'observer 10 fois 6 sur 20 lancers si le dé est équilibré.Vous pouvez faire une nouvelle hypothèse à présent : le dé est peut-être pipé de sorte à ce qu’il tombe 2 fois plus souvent sur le 6\nque sur les autres nombres. Notre nouvelle probabilité du succès est de\n2/7 pour le 6, et 1/7 pour toutes les autres faces (1/7 pour le 1, 1/7\npour 2, 1/7 pour le 3, 1/7 pour le 4, et 1/7 pour le 5). Ainsi, le\nchiffres 6 deux fois plus de chances d’être observé que n’importe\nquelle autre face.Dans ce cas, la vraisemblance que d’avoir 6 si la probabilité d’avoir 6 est deux fois plu élevée vaut\n0.045626. Cette vraisemblance est\n76.1702838 plus élevée que la\nvraisemblance d’un dé non pipé. Le dé est sans doute pipé. Remarquez\nqu’ici, j’aurais pu utiliser “le dé est vraisemblablement pipé” mais\nj’ai évité cette formulation pour éviter l’ambiguïté entre le mot\n“vraisemblablance” au sens statistique par rapport au sens commun.\nEncart 4. Á propos de\nl’estimation par maximum de vraisemblance.Pour quiconque ayant déjà réalisé une analye factorielle, une\nmodélisation d’équation structurale ou encore un modèle linéaire (mixte)\ngénéralisé, le mot vraisemblance ne doit pas être étranger car un des\nalgorithmes les plus utilisés dans ces contextes est l’estimation du\nmaximum de vraisemblance.L’estimation du maximum de vraisemblance consiste à estimer la\nvraisemblance pour différentes hypothèses et d’identifier l’hypothèse\npour laquelle la probabilité est la plus élevée. L’intérêt est d’estimer les paramètres d’intérêt qui sont les plus vraisemblables.Sans vouloir rentrer dans la rigueur mathématique pour estimer un\nmaximum de vraisemblance, voici schématiquement ce qu’un algorithme\nd’estimation du maximum de vraisemblance réaliserait pour estimer la\nprobabilité du succès pour le dé de notre exemple.Table 9.1: Vraisemblance estimée pour différentes hypothèses de probabilité d'obtenir 6.p.succèsvraisemblance0.050.000000011340720.100.000007150904020.150.000248381989620.200.002594827400670.250.017035628882700.300.083445029629810.350.166156189823850.400.370261769406640.450.660644678101940.501.000000000000000.550.660644678101940.600.370261769406640.650.166156189823850.700.083445029629810.750.017035628882700.800.002594827400670.850.000248381989620.900.000007150904020.950.000000011340721.000.00000000000000Sans grande surprise, la vraisemblance est maximale dans notre exemple\nlorsque la probabilité d’obtenir 6 est de 0.5. Néanmoins, quand il faut\npouvoir estimer plusieurs paramètres simultanément, les choses sont\nmoins triviales que cela.\n","code":"\nbinom.test(x = 10, # nombre de succès, càd. avoir 6\n           n = 20, # nombre d'essais \n           p = 1/6) # la probabilité d'avoir 6 si le dé n'est pas pipé## \n##  Exact binomial test\n## \n## data:  10 and 20\n## number of successes = 10, number of trials = 20, p-value = 0.0005985\n## alternative hypothesis: true probability of success is not equal to 0.1666667\n## 95 percent confidence interval:\n##  0.2719578 0.7280422\n## sample estimates:\n## probability of success \n##                    0.5\nbinom.test(x = 10, # nombre de succès, càd. avoir 6\n           n = 20, # nombre d'essais \n           p = 2/7) # la probabilité d'avoir 6 pour un dé est pipé## \n##  Exact binomial test\n## \n## data:  10 and 20\n## number of successes = 10, number of trials = 20, p-value = 0.04563\n## alternative hypothesis: true probability of success is not equal to 0.2857143\n## 95 percent confidence interval:\n##  0.2719578 0.7280422\n## sample estimates:\n## probability of success \n##                    0.5"},{"path":"la-vraisemblance.html","id":"vraisemblance-et-variable-quantitative","chapter":"9 La vraisemblance","heading":"9.4 Vraisemblance et variable quantitative","text":"Si dans le cas précédent, le calcul de la vraisemblance est assez\nsimple, les choses se compliquent lorsqu’est confronté à une variable\nquantitative.Pour comprendre la manière dont la vraisemblance est calculée pour des variables quantitatives, il est nécessaire de\ncomprendre une notion supplémentaire : la densité de probabilité.La densité de probabilité est la hauteur sous la courbe dans une\ndistribution. Pour une distribution normale, peut l’obtenir avec la\nfonction dnorm9. Concrètement, j’ai des\ndonnées dont la moyenne est de 100, l’écart-type vaut 15, la hauteur\nsous la courbe pour la valeur 112 est obtenue ainsi :Il est important de comprendre que, pour une variable continue, aucun\nscore, aucune valeur n’une densité de probabilité différente de 0. La\ndensité est calculée pour un intervalle. Il n’est pas nécessaire de\npréciser cet intervalle, R va l’inférer en fonction de la valeur qu’\nrentre.\nFigure 9.1: Représentation graphique de la densité de probabilité pour 1 observervation située à 112 dans une distibution dont la moyenne est supposée être à 100 et l’écart-type à 15.\nNous avions déjà évoqué la hauteur sous la\ncourbedans la section consacrée à l’estimation de la\ndistribution priori. Il s’agissait déjà de la densité de probabilité. Nous n’avions\npas évoqué le concept à ce moment-là pour focaliser sur la compréhension\ndu prior plutôt que sur les aspects mathématiques.La vraisemblance pour des données quantitatives va être la probabilité\nconditionnelle d’avoir conjointement les densités de probabilité pour\nune hypothèse donnée. Nous avons vu dans les rappels sur les\nprobabilités qu’une probabilité\nconjointe était le produit entre différentes probabilités lorsque\ncertains éléments sont imposés. Dans le cas de la vraisemblance, c’est la probabilité des données étant\ndonné une hypothèse.Revenons à notre exemple sur le QI. Imaginons que nous mesurions le QI\ndes personnes qui suivent cette formation. Voici les données obtenuesOn peut obtenir la densité de probabilité pour ces valeurs pour\nl’hypothèse d’une moyenne à 100 et d’un écart-type à 15, c’est-à-dire\nl’hypothèse selon laquelle votre QI ne dépasse pas celui de la moyenne de la\npopulation (bref une hypothèse invraisemblable).Le produit de toutes ces densités nous fournit la vraisemblance :De manière générale, plus il y des valeurs, plus le produit des\ndensités va se rapprocher de 010.Néanmoins, dans ce cas,\nla vraisemblance semble particulièrement faible. pouvait s’y\nattendre. Si représente graphiquement les densité de ces\nobservations, il y un décalage à droite de la moyenne, avec peu d’observations autour de la moyenne, et plusieurs observations qui sont sur les extrémités.\nFigure 9.2: Représentation graphique de la densité pour l’ensemble des valeurs de QI pour une moyenne à 100.\npeut refaire la même figure mais en utilisant cette fois la moyenne\net l’écart-type observé pour les valeurs de QI (voir Figure\n9.3). constate sur la Figure que la hauteur pour\nchaque observation est bien plus élevée que ce qu’observait dans la\nFigure 9.2. Les données nous disent qu’une moyenne à\n122 est bien plus vraisemblable qu’une moyenne à 100.\nFigure 9.3: Représentation graphique des densités pour l’ensemble des valeurs de QI lorsque la moyenne et l’écart-type correspondent à la moyenne et l’écart-type des valeurs de QI.\npeut comparer la vraisemblance qu’obtient quand utilise la\nbonne moyenne et le bon écart-type. La valeur qu’obtient est bien\nplus élevée que celle qu’obtenait avec une moyenne à 100 et un\nécart-type à 15. Vous pouvez comparer la vraisemblance qu’obtenue\navec celle qu’obtient en utilisant la fonction logLik qui fournit le logarithme de la vraisemblance.Avant de passer à la section suivante, il est important de préciser, dans notre exemple, que la vraisemblance atteint son maximum au niveau de la moyenne et pour l’écart-type obtenu arithmétiquement parce que les\ndonnées étaient issue d’une distribution normale et qu’il n’y avait pas\nde valeur influente. Quand la distribution n’est pas une distribution normale, ou quand est dans des modèles complexes où plusieurs paramètres doivent être estimés simultanément, une approche arithmétique va s’avérer insuffisante.","code":"## [1] 0.01931277##  [1] 143 127 125 126 127 116 108 119 126 117 125 109 110 129 126 116 127##  [1] 0.0004368688 0.0052633439 0.0066318093 0.0059212307 0.0052633439\n##  [6] 0.0150575218 0.0230702595 0.0119238944 0.0059212307 0.0139928197\n## [11] 0.0066318093 0.0222149735 0.0212965337 0.0041036534 0.0059212307\n## [16] 0.0150575218 0.0052633439## [1] 0.0000000000000000000000000000000000009854725##  [1] 143 127 125 126 127 116 108 119 126 117 125 109 110 129 126 116 127##  [1] 143 127 125 126 127 116 108 119 126 117 125 109 110 129 126 116 127\n# Vraisemblance avec l'hypothèse d'un QI égal à la moyenne du QI \n# et un écart-type égal à la moyenne de l'écart-type\ndensite<-dnorm(QI,mean(QI),sd(QI) )\n\ndensite##  [1] 0.002748363 0.038794592 0.042862914 0.041040758 0.038794592 0.035552856\n##  [7] 0.012571736 0.042476075 0.041040758 0.038212811 0.042862914 0.014974513\n## [13] 0.017608902 0.033354098 0.041040758 0.035552856 0.038794592\nvraisemblance122<-prod(densite)\nvraisemblance122## [1] 0.000000000000000000000000004623054\n# Comparaison avec la vraisemblance obtenue par la fonction logLik\nlmx <- lm(QI ~ 1) # on modélise uniquement l'intercept\nlogML<-logLik(lmx) # on obtient le logarithme (log Likelihood) de la vraisemblance \nas.numeric(exp(logML)) # en faisant l'exponentiel, on obtient la même valeur que celle que nous avons calculée. ## [1] 0.000000000000000000000000004694374"},{"path":"la-vraisemblance.html","id":"exercice","chapter":"9 La vraisemblance","heading":"9.5 Exercice","text":"","code":""},{"path":"la-vraisemblance.html","id":"énoncé","chapter":"9 La vraisemblance","heading":"9.5.1 Énoncé","text":"Calculez la vraisemblance avec les données qui vous ont été présentées dans la partie définition avec la moyenne et l’écart-type que vous aviez imaginés. Comparez la différence de vraisemblance avec la moyenne et l’écart-type calculés. Pour vous aider, vous pouvez recréer le vecteur en utilisant cette ligne de commande","code":"\nExo1<-c(45, 20, 15, 30, 29, 29, 32, 46, 35, 27, 28, 16, 34, 24, 56, \n30, 40, 19, 13, 46)\nm<-35 # ma moyenne\ns<-10 # mon écart-type\ndensite<-dnorm(Exo1,m,s) \n\nvrais<-prod(densite)\nvrais## [1] 0.00000000000000000000000000000000005259341\n# La même chose avec la vraie moyenne\nm<-mean(Exo1) # moyenne exo1\ns<-sd(Exo1) # écart-type exo1\ndensite<-dnorm(Exo1,m,s) \n\nvrais2<-prod(densite)\nvrais2## [1] 0.000000000000000000000000000000000445032"},{"path":"la-probabilité-a-posteriori.html","id":"la-probabilité-a-posteriori","chapter":"10 La probabilité a posteriori","heading":"10 La probabilité a posteriori","text":"Dans l’approche bayésienne, déterminer la probabilité posteriori\nsuffit pour se faire une opinion concernant une théorie.Selon Bayes, P(H|D) est proportionnel à \\(P(D|H) \\times P(H)\\),\nc’est-à-dire que l’posteriori est donné par la vraisemblance\nmultipliée par l’priori. Ainsi, dans notre exemple, la probabilité\nposteriori pour l’hypothèse nulle \\(P(D|H_0)\\) vaut\n\\(P(H_{QI_{100}}|D) \\text{ est proportionnel à } P(D|H_{QI_{100}}) \\times P(H_{QI_{100}})\\).\nDe même, la probabilité posteriori pour l’hypothèse alternative\n\\(P(D|H_1)\\) est égale à\n\\(P(H_{QI_{122}}|D) \\text{ est proportionnel à } P(D|H_{QI_{122}}) \\times P(H_{QI_{122}})\\)En créant une ditribution priori, formalise le fait que certaines\ntailles d’effet sont plus probables que d’autres. Chacune de ces tailles\nd’effet représente une hypothèse particulière. Nous devons multiplier\nchaque hypothèse de la distribution priori par la vraisemblance pour\nobtenir la distribution posteriori. Quand fait cela, \nremarque que la distribution posteriori est essentiellement dominée\npar la vraisemblance (voir Figure 10.1) qui illustre la\nmanière dont la distribution posteriori évolue pour différentes\ndistributions priori en fonction de la vraisemblance des données qui\natteint son maximum pour la zone où la taille d’effet est le plus\nprobable.\nFigure 10.1: Représentation de la distribution posteriori en fonction de différentes distributions priori, de la vraisemblance et de différentes tailles d’effet\nDonc, même si des personnes partent avec des distribution priori\ntrès différentes, en recueillant suffisamment de données, tant que les\ndistributions priori sont suffisamment étalées et autorisent une\nprobabilité non négligeable dans la région correspondant à la valeur\nréelle de la population, les distributions posteriori, étant\nfortement déterminées par la vraisemblance, finiront par être très\nsimilaires (Edwards et al., 1963). En ce sens, les statistiques bayésiennes\nsoulignent la nature objective de la science : différentes opinions de\ndépart convergeront lorsque les données seront suffisantes. La\nvraisemblance, qui représente les données, finit par dominer les\nconclusions.Résumer les résultats par une distribution posteriori peut être\ndéroutant pour les scientifiques habitué·es à l’approche fréquentiste.\nAvoir une probabilité, c’est bien mais qu’en fait-? Cela pourrait\nêtre rassurant de pouvoir se positionner par rapport à une hypothèse\nnulle. Nous verrons comment le faire dans la section consacrée aux\nFacteur de Bayes.","code":""},{"path":"la-probabilité-a-posteriori.html","id":"lintervalle-de-crédibilité","chapter":"10 La probabilité a posteriori","heading":"10.1 l’intervalle de crédibilité","text":"La Figure 10.1 va permettre d’aider à comprendre à quoi correspond l’intervalle de crédibilité, également appelé intervalle de\nprobabilité ou région de plus haute densité (RHD).Un intervalle de crédibilité est utilisé pour caractérisé une distribution probabiliste. Il s’agit de la probabilité qu’un paramètre qu’ne peut pas directement observer ait une probabilité particulière (par exemple 95%) d’être à l’intérieur de cet intervalle.Cette notion est assez proche de l’intervalle de confiance dans l’approche fréquentiste mais s’en distingue conceptuellement sur un aspect important : dans l’approche fréquentiste, l’intervalle de confiance renvoie au fait que, si répète un grand nombre de fois la même expérience, dans 95% des situations, la valeur de la population pour le paramètre d’intérêt sera inclus à l’intérieur des limites de l’intervalle estimé à partir de l’échantillon. Ainsi, les limites sont aléatoires dans l’intervalle de confiance alors que le paramètre est fixe. Dans l’approche bayésienne, l’idée est un peu différente car, non seulement il dépend de la distribution priori mais aussi parce qu’ne considère pas que ce sont les limites qui sont aléatoires mais ce qui peut changer c’est le paramètre et non l’intervalle. Imaginons qu’un intervalle de crédibilité fixe les limites entre 30 et 40, cet intervalle est centré sur la moyenne de la\ndistribution posteriori, c’est-à-dire 35, cela signifie qu’une valeur du paramètre égale à 35 est la valeur la plus probable, 34 et 36 sont un peu moins probables mais raisonnablement probables et il est très peu probable que le paramètre ait une valeur de 29 ou de 41.","code":""},{"path":"le-facteur-de-bayes.html","id":"le-facteur-de-bayes","chapter":"11 Le facteur de Bayes","heading":"11 Le facteur de Bayes","text":"Dans la partie consacrée à la\nvraisemblance, nous avons\ncalculé la vraisemblance pour l’hypothèse selon laquelle le QI de cette\nassemblée ne se distinguait pas de celui de la moyenne de la population\ngénérale (l’hypothèse nulle) et pour l’hypothèse selon laquelle cette\nassemblée avait un QI de 12211. Nous avons vu que la\nvraisemblance était très différente pour l’hypothèse où le QI moyen de\ncette assemblée était de 100 et pour l’hypothèse où le QI moyen de\nl’assemblée était de 122. pourrait se demander à quel point\nl’hypothèse selon laquelle “le QI moyen est à 122” est plus probable que\nl’hypothèse selon laquelle “le QI moyen est de 100”. Si pouvait\nrépondre à cette question, pourrait alors savoir si nous disposons de\npreuves tangibles en faveur d’une hypothèse par rapport à une autre.Pour répondre à cette question, peut simplement faire le rapport\nentre les deux (voir l’équation (11.1)). Ce rapport de vraisemblance\nest ce qu’apppelle le facteur de Bayes.\\[\\begin{equation}\n  \\frac{P\\left(H_1|D \\right)}{P\\left(H_0|D \\right)} =\n  \\frac{P\\left(H_1\\right)}{P\\left(H_0\\right)}\n  \\times\n  \\frac{P\\left(D|H_1 \\right)}{P\\left(D|H_0 \\right)}\n  \\tag{11.1}\n\\end{equation}\\]où, pour rappel, P(H|D) est la probabilité d’une hypothèse étant donné\nles données et P(D|H) est la probabilité des données étant donné une\nhypothèse, c’est-à-dire la vraisemblance.peut formuler aussi les choses d’une autre manière :\\[\\begin{equation}\n  \\text{Cotes posteriori} =\\text{Cotes priori} \\times \\text{rapport de vraisemblance}\n  \\tag{11.2}\n\\end{equation}\\]Rappelez-vous qu’déjà évoqué les cotes en faveur d’une hypothèse\npar rapport à une autre, notamment quand vous avez dû parier sur le fait\nque cette formation changerait votre manière de penser vos recherches. Pour avoir le rapport posteriori, il faut donc multiplier votre rapport priori par le rapport de vraisemblance.\nPar ailleurs, nous avons déjà calculé la vraisemblance pour les deux\nhypothèses. Nous pouvons donc examiner le rapport de vraisemblance :Dans le contexte bayésien, le rapport de vraisemblance est appelé le facteur de Bayes (B). Une\nnotation \\(B_{01}\\) indique qu’place la vraisemblance de l’hypothèse\nnulle au numérateur et celle de l’hypothèse alternative au dénominateur.\nAinsi, une facteur de Bayes supérieur à 1 dans ce cas apporterait du\nsoutien en faveur de l’hypothèse nulle tandis qu’un facteur de Bayes\ninférieur à 1 apporterait un soutien en faveur de l’hypothèse\nalternative. La notation \\(B_{01}\\) signifie que c’est la vraisemblance de\nl’hypothèse alternative qui est au numérateur. L’interprétation est donc\nl’inverse que celle de \\(B_{01}\\). Si B est proche de 1, alors\nl’expérimentation manque de sensibilité, sans doute parce que vous\nn’avez pas assez de participant·es. Remarquez ici que vous pouvez\ndistinguer les situations où votre expérimentation n’est pas assez\ndiscriminante entre l’hypothèse nulle et l’hypothèse alternative des\nsituations où les preuves soutiennent l’hypothèse nulle. Ceci\nreprésente une différence majeure par rapport à l’approche fréquentiste\noù ne peut que tolérer l’hypothèse nulle. En effet, dans le cadre de l’approche fréquentiste, il faut se rappeler que l’absence de preuve\nn’est pas la preuve de l’absence (Caldwell, 2022; Lakens, 2017; voir néanmoins le packages TOSTER qui\npermet de tester des hypothèses nulles en utilisant une approche\nfréquentiste, Lakens et al., 2018). Dans notre cas,\nnous avons placé la vraisemblance au numérateur, cela signifie que\nl’hypothèse d’un QI moyen à 122 est\n4691204878.88566 fois plus probable que l’hypothèse\nnulle. En d’autres termes, même avec une très faible probabilité\npriori en faveur de l’hypothèse alternative, ce rapport est tellement\nénorme que la probabilité posteriori serait proche de 1. La question\nqui se pose est comment interpréter ces facteurs de Bayes dans des\nsituations moins claires ? Est-ce qu’un FB de 1.5 est suffisamment\nélevé pour apporter du soutien à une hypothèse ?Les bayésiens vous diraient que c’est à vous de décider, qu’ils se\nrefusent à proposer des heuristiques arbitraires telle que le fameux\n\\(p<.05\\) pour déclarer qu’un effet est significatif. Néanmoins, certains\nauteur (par ex., Wagenmakers et al., 2011) ont apporté des balises qui\npermettent aux personnes qui s’initient aux statistiques bayésiennes de\nse positionner. Ces balises ont été établies pour que, ce qui représente\ndes preuves en faveur de l’hypothèse alternative, corresponde plus ou\nmoins à un effet significatif si avait utilisé une approche\nfréquentiste pour traiter les données.Table 11.1: Balise permettant d'interpréter les facteurs de Bayes quand la vraisemblance pour l'hypothèse nulle est au numérateur (B10)FB10interprétation>100Preuves extrêmes en faveur de l'hypothèse alternative>30 et <100Très fortes preuves en faveur de l'hypothèse alternative>10 et <30Fortes preuves en faveur de l'hypothèse alternative>3 et <10Preuves substantielles en faveur de l'hypothèse alternative>1 et <3Preuves anecdotiques en faveur de l'hypothèse alternative1Absence de preuve<1 et >1/3Preuves anecdotiques en faveur de l'hypothèse nulle<1/3 et >1/10Preuves substantielles en faveur de l'hypothèse nulle<1/10 et >1/30Fortes preuves en faveur de l'hypothèse nulle<1/30 et >1/100Très fortes preuves en faveur de l'hypothèse nulle<1/100Preuves extrêmes en faveur de l'hypothèse nulleDe ce qui vient d’être expliqué découlent deux propriétés\nparticulièrement intéressante. D’abord, l’utilisation des facteurs de\nBayes n’implique pas que deux scientifiques aient les mêmes cotes \npriori en faveur d’une hypothèse. Puisqu’un facteur de Bayes est un\nrapport de vraisemblance et que ce rapport ne dépend pas (vraiment) des\ncotes priori, quiconque peut mettre à jour sa cote en faveur d’une\nhypothèse en la multipliant par le facteur de Bayes. Le facteur de Bayes\npermet d’ajuster les cotes de façon continue sans devoir rejeter ou\naccepter une hypothèse. D’ailleurs, nous avons vu dans la tâche où il\nvous était demandé de classer les théories qu’il peut y avoir une\ncertaine part d’incertitude pour certaines théories alors qu’accorde plus de crédit à d’autres, même si se laisse une petite place pour le\ndoute. Après tout, est-ce que le faillibilisme n’est pas une propriété\ninhérente de la science (Peirce, 1877; K. Popper, 1963) ?\nDans l’approche bayésienne, les données viennent moduler nos croyances,\nnos convictions, bref, le crédit que nous accordons aux théories.Le second point est que cette modulation peut se faire en faveur de\nl’hypothèse nulle. peut avoir des preuves en faveur de l’hypothèse\nnulle, et donc la tester. Dans la suite de cette section, nous allons\ndans un premier temps présenter de manière plus rigoureuse la manière de\ncalculer les facteurs de Bayes avant d’illustrer ces propriétés en\nreprenant une procédure assez similaire à celle que nous avons utilisée\npour illutrer certaines limites de l’approche de Neyman-Pearson\n(Neyman & Pearson, 1933).Nous terminerons en évoquant comment peut s’assurer que notre facteur\nde Bayes n’pas été influencé par le choix de la distribution priori.","code":"\nFB<-vraisemblance122/vraisemblance100\nFB## [1] 4691204879"},{"path":"le-facteur-de-bayes.html","id":"un-peu-de-rigueur-mathématique","chapter":"11 Le facteur de Bayes","heading":"11.1 Un peu de rigueur mathématique","text":"Si vous n’êtes pas sensibles à la précision mathématique mais que vous vous placez uniquement dans la perspective de l’utilisateur, cette section peut être omise. En revanche, si les imprécisions mathématiques (volontaires) que j’ai pu faire jusqu’à présent vous chagrine, cette section corrigera les manquements que je suis permis jusqu’à présent (pour des raisons pédagogiques).En effet, les calculs qui ont été réalisés jusqu’à présent pour obtenir les\nfacteurs de Bayes ont négligé la rigueur mathématique pour favoriser\nl’aspect pédagogique. Ainsi, si utilisait la fonction\nttestBF (Morey & Rouder, 2024) qui permet de réaliser un t de\nStudent en utilisant l’approche bayésienne, nous aurions également des\npreuves substantielles en faveur de l’hypothèse alternative mais la\nvaleur serait beaucoup moins élevée que celle que nous avons calculée.Pour obtenir cette valeur, il faut s’appuyer sur la formule exacte qui est fournie par Rouder et al.\n(2009) et décrite dans l’équation (11.3)\\[\\begin{equation}\nB_{10} = \\frac{ \\int_{0}^{\\infty} \\left(1+Ng\\right)^{-1/2} \\times  \n\\Bigg( 1+\\frac{t^2}{(1+Ng)\\times v}\\Bigg)^{\\left(v+1\\right)/2} \\times 2\\pi^{-1/2} \\times g^{-3/2} \\times e^{-1/(2g) \\times dg}}{\\Bigg( 1+\\frac{t^2}{v}\\Bigg)^{(v+1)/2}}\n  \\tag{11.3}\n\\end{equation}\\]Dans cette équation, t représente la valeur du t de Student (selon\nl’approche fréquentiste), N représente la taille de l’échantillon, v\nreprésente les degrés de liberté (N-1) et g représente la densité de\nprobabilité sur la distribution Cauchy dont nous avons parlé\nprécédemment.Nous pouvons à présent montrer comment la valeur est réellement calculée\ndans le package BayesFactor (Morey & Rouder, 2024).Nous allons commencer par préparer les informations les plus accessibles\nla valeur du t de Student selon l’approche fréquentiste. peut\nobtenir cette information grâce à la fonction t.test.\nrécupère la taille de l’échantillon et nous établissons le\nrscaleDans l’équation, le dénominateur est la partie la plus simple à\ncomprendre. Il s’agit de la densité de probabilité sous hypothèse nulle.\nIl s’agit pratiquement de ce que nous avons fait précédemment, avec la\nnuance que nous allons utiliser une distribution t plutôt qu’une\ndistribution normale. Pour la distribution normale, la fonction était\ndnorm. Pour la distribution t, la fonction est\ndt.Il y deux différences importantes entre le numérateur et le\ndénominateur : la première est qu’doit réaliser une intégrale. La\nseconde est qu’il faut pondérer la vraisemblance conditionnelle,\nc’est-à-dire la vraisemblance pour une multitude de cas de tailles\nd’effets possibles, par la densité de probabilité de la distribution\nCauchy. Vous ne serez pas surpris·e d’apprendre qu’il existe une\nfonction pour calculer la densité de probabilité sur une distribution\nCauchy qui s’appelle dcauchy. Dans l’équation (11.3), remarque\naussi qu’une partie du numérateur correspond au dénominateur, qu’doit\nappliquer dans le cadre d’une intégrale. suppose que la taille\nd’effet \\(\\delta\\) suit une distribution Cauchy centrée en 0, dont la\nlargeur dépend du paramètre rscale. va modéliser la distribution des\ntailles d’effet possible en utilisant l’argument ncp avec\ncomme valeur \\(\\delta \\times \\sqrt{n}\\) pour calculer la vraisemblance\nd’observer la statistique t. L’idée est de se demander quelle serait la\nvraisemblance d’avoir cette valeur de t si la taille d’effet avait\ncomme valeur \\(\\delta\\) et que ce \\(\\delta\\) se distribuait en suivant une\ndistribution Cauchy avec le paramètre rscale que nous avons\nchoisi. Il va falloir faire l’intégrale12, c’est-à-dire\nenvisager pratiquement tous les cas de figures possibles pour une taille\nd’effet variant de -=\\(\\delta = -4\\) à \\(\\delta=4\\), R requiert que la\nfonction permettant de faire des intégrales integrate ait\ncomme argument principal la fonction pour laquelle doit faire\nl’intégrale. Nous allons donc dans un premier créer une fonction\nintegrand qui pourra être utilisée pour faire l’intégrale.","code":"\nlibrary(BayesFactor)\n\ntBF.out<-ttestBF(QI, # Les données \n        mu = 100, # la norme pour fixer l'hypothèse nulle\n        rscale = sqrt(2)) # La distribution a priori pour une distribution ultrawide (vu que la taille d'effet qu'on s'attend à avoir est grande)\n\ntBF.out## Bayes factor analysis\n## --------------\n## [1] Alt., r=1.414 : 1144439 ±0%\n## \n## Against denominator:\n##   Null, mu = 100 \n## ---\n## Bayes factor type: BFoneSample, JZS\n# on commence par faire un t de Student fréquentiste\n# on extrait la valeur t \ntstat <- t.test(QI , mu = 100)$statistic\ntstat##        t \n## 10.33488\n# on récupère le nombre d'obervations (nécssaire notamment pour les ddl)\nn <- length(QI)\nrscale <- sqrt(2)\n# fonction de densité marginale sous H0\n# la fonction dt permet de calculer une densité de probabilité \n# pour une distribution t, comme dnorm le fait pour une distribution normale \n# On peut donc calculer la\n# densité sous H0 : p(D | H0)\n# ce sera le dénominateur \ndenominator <- dt(tstat, df = n - 1)\ndenominator##                t \n## 0.00000001176713\n# Il va falloir faire la même chose à présent pour H1\n# il faut calculer la densité p(D | H1)\n# nous allons devoir préciser le paramètre de non-centralité\n# c'est-a-dire notre prior \n# nous allons devoir faire l'intégrale pour les différentes valeurs possibles \n# cette intégrale a approximativement un incrément de 1/100 entre chaque valeur entre -4 et 4\n# le delta va être pondéré par la forme de la distribution Cauchy \nintegrand <- function(delta) {\n  dt(tstat, \n     df = n - 1, \n     ncp = delta * sqrt(n)) * dcauchy(delta, scale = rscale)\n}\n\n# On peut faire l'intégrale numérique de : p(D | H1)\nnumerator <- integrate(integrand, lower = -Inf, upper = Inf)$value\n\n\n\n# On  peut obtenir le facteur de Bayes\nbf_manual <- numerator / denominator\nbf_manual##       t \n## 1144439"},{"path":"le-facteur-de-bayes.html","id":"ajuster-nos-probabilités","chapter":"11 Le facteur de Bayes","heading":"11.2 Ajuster nos probabilités","text":"Dans la section d’introduction aux facteurs de Bayes, nous avons évoqué le fait que le facteur de Bayes permettait d’ajuster de manière continue notre probabilité.Un outil intéressant pour comprendre cette idée et pour identifier la direction que prend le facteur de Bayes est de faire des analyses séquentielles. L’idée est qu’va estimer le facteur de bayes pour un échantillon qui va d’un petit échantillon à la taille complète de l’échantillon dont dispose, en choisissant de manière aléatoire les observations tant qu’n’pas atteint une taille d’échantillon N égale à la taille de l’échantillon pour lequel recueilli les données.Cette analyse permet de voir si le facteur de Bayes est dépendant de quelques observations où s’il s’agit d’une tendance générale qui se dessine.Nou pouvons reprendre notre exemple sur le QI pour illustrer cette idée. Pour pouvoir faire ces analyses séquentielles, nous devons utiliser le package changeofevidence (Dechamps, 2025) qui intègre cette possibilité, ce qui à ma connaissance n’est pas le cas avec le package BayesFactor (Morey & Rouder, 2024). Dans le package changeofevidence, obtient la facteur de Bayes pour un test t avec la fonction bfttest. Il suffit ensuite de faire une représentation graphique de la sortie de résultats (voir Figure 11.1)\nFigure 11.1: Représentation graphique des facteurs de Bayes séquentiels\nPour comprendre l’intérêt de ce type d’analyse, il suffit de rajouter une observation qui serait aberrante, par exemple un QI à 40 et voir comment le facteur de Bayes évolue (voir Figure 11.2).\nFigure 11.2: Représentation graphique des facteurs de Bayes séquentiels\nse rend compte ici que la valeur aberrante va drastiquement influencer la valeur du facteur du Bayes (à la baisse). Ainsi, peut savoir quelles sont les observations qui sont influentes et si le facteur de Bayes été modifié par quelques observations uniquement.Cette manière d’analyser les données vous permet donc de vous assurer que votre facteur de Bayes ne dépend pas que de quelques observations qui feraient pencher la vraisemblance d’un côté ou de l’autre.","code":"\nlibrary(changeofevidence)\n\nbf.exp <- bfttest(QI, mu = 100, alternative = \"two.sided\", prior.loc = 0, prior.r = sqrt(2))##   |                                                                              |                                                                      |   0%  |                                                                              |=====                                                                 |   7%  |                                                                              |=========                                                             |  13%  |                                                                              |==============                                                        |  20%  |                                                                              |===================                                                   |  27%  |                                                                              |=======================                                               |  33%  |                                                                              |============================                                          |  40%  |                                                                              |=================================                                     |  47%  |                                                                              |=====================================                                 |  53%  |                                                                              |==========================================                            |  60%  |                                                                              |===============================================                       |  67%  |                                                                              |===================================================                   |  73%  |                                                                              |========================================================              |  80%  |                                                                              |=============================================================         |  87%  |                                                                              |=================================================================     |  93%  |                                                                              |======================================================================| 100%\nplot(bf.exp)\nQI2<-c(QI, 40)\nbf.exp2 <- bfttest(QI2, mu = 100, alternative = \"two.sided\", \n                   prior.loc = 0, prior.r = sqrt(2))##   |                                                                              |                                                                      |   0%  |                                                                              |====                                                                  |   6%  |                                                                              |=========                                                             |  12%  |                                                                              |=============                                                         |  19%  |                                                                              |==================                                                    |  25%  |                                                                              |======================                                                |  31%  |                                                                              |==========================                                            |  38%  |                                                                              |===============================                                       |  44%  |                                                                              |===================================                                   |  50%  |                                                                              |=======================================                               |  56%  |                                                                              |============================================                          |  62%  |                                                                              |================================================                      |  69%  |                                                                              |====================================================                  |  75%  |                                                                              |=========================================================             |  81%  |                                                                              |=============================================================         |  88%  |                                                                              |==================================================================    |  94%  |                                                                              |======================================================================| 100%\nplot(bf.exp2)"},{"path":"le-facteur-de-bayes.html","id":"tester-une-hypothèse-nulle","chapter":"11 Le facteur de Bayes","heading":"11.3 Tester une hypothèse nulle","text":"Une des raisons principales en faveur de l’utilisation de l’approche bayésienn est que le facteur de Bayes permet de tester une hypothèse nulle car la vraisemblance peut être plus élevée pour l’hypothèse nulle que pour l’hypothèse alternative, ce qui n’était pas le cas pour l’approche de Neyman-Pearson (Neyman & Pearson, 1933) car, non seulement, il y avait le risque de faux positifs à 5%, mais surtout parce que, dès lors que la taille d’échantillon augmente, aura un effet significatif même pour de petits effets.Nous allons examiner ces deux cas de figures sous l’angle bayésiens en utilisant les mêmes paramètres que ceux utilisés précédemment. La seule différence est que nous allons travailler avec 20 000 échantillons plutôt que 200 000 car les temps de calculs sont considérablement allongés pour l’approche bayésienne.constate que, avec ces paramètres, l’analyse va indiquer la plupart du temps (dans 66% des situations) que l’expérience manquent de sensibilité pour prendre une décision. Par ailleurs, l’hypothèse nulle est rejetée à tort avec un taux d’erreur inférieur au 5% des tests d’hypothèse nulle ( 1.93 % des situations). Enfin, le taux d’erreur est plus élevée pour la situation où la taille d’effet est de 0.2 et que le facteur de Bayes nous indique que nous avons des preuves en faveur de l’hypothèse nulle ( 28.53 %). Si ce taux d’erreur est loin d’être négligeable, il faut noter que ce taux d’erreur reste considérablement plus faible que celui observé avec l’approche fréquentiste (pour rappel, tolérait l’hypothèse nulle dans 91% des situations). Par ailleurs, le fait d’observer plus de situations où une différence alternative sera considérée comme une hypothèse nulle est un phénomène tout à fait cohérent avec l’approche bayésienne.En effet, il faut garder à l’esprit que l’absence totale d’effet n’existe jamais réellement mais que ce sont des approximations d’invariance (Cohen, 1994). Si une absence totale de différence est quasiment impossible, le fait est que certaines tailles d’effet sont tellement négligeables qu’ne peut pas décemment avancer qu’elles représentent quelque chose qui ait du sens pour le domaine de recherche exploré. Il faut comprendre ici, que presque paradoxalement, cette même taille d’effet pourrait être d’un intérêt substantiel dans un autre domaine. Il faut donc pouvoir mettre aussi en évidence cet effet minimal. Par exemple, en psychologie, considérerait sans intérêt un effet qui ne toucherait par exemple qu’une personne sur 10000 mais il s’agit de la fréquence avec laquelle un jeune vacciné contre la covid développe une myocardite. Il s’agit donc d’un risque identifié pour le vaccin de la covid chez les jeunes et que ce risque est effectivement considéré comme un effet indésirable potentiel du vaccin contre la covid.La question qui se pose donc est de savoir si le facteur de Bayes fournit la décision appropriée dans ce genre de situations, à savoir un facteur de Bayes supérieur à 3 à la condition d’avoir un très grand échantillon tout en restant en-dessous de 1/3 pour les échantillons de petites et moyennes tailles. Pour illustrer cette question, nous allons faire une simulation similaire (les changements ont surtout vocation à réduire les temps de calcul) à celle relative sur une différence de 0.1 point sur un test de QI entre deux populations.se rend compte qu’avec la même simulation que celle que nous avons utilisée précédemment, le facteur de Bayes pour des tailles d’échantillon modérée, voire grande, va favoriser l’hypothèse nulle mais, avec des échantillons énormes, le facteur de Bayes va pencher en faveur d’un effet réel. Remarquez la différence de comportement par rapport à l’approche fréquentiste où le nombre d’effets significatifs augmentait de manière proportionnelle à la taille de l’échantillon.Qu’est-ce que cela signifie : si s’intéresse à des effets raisonnablement importants, des tailles d’échantillons de quelques dizaines, voire de quelques centaines de participants vont favoriser l’hypothèse nulle si la taille d’effet observée est effectivement ridicule. En revanche, si s’intéresse à de toutes petites tailles d’effet, sait qu’il faudra un échantillon conséquent pour le mettre en évidence (sans doute plusieurs milliers de données) et, dans ce cas, le FB sera en mesure de le mettre en évidence.Pour Rouder et al. (2009), ce comportement est idéal : avec les petites tailles d’échantillon, n’pas assez d’informations pour distinguer une absence totale d’effet d’un effet extrêmement petit, ce qui permettra au chercheur et à la chercheuse d’accumuler des preuves en faveur de l’hypothèse nulle, et avec de très larges échantillons, le facteur de Bayes permet de découvrir de très petits effets. Pour le formuler autrement : le facteur de Bayes favorise un modèle plus parcimonieux, à savoir l’absence de différence, à moins que l’échantillon soit si large que même des petits effets ne sont pas compatibles avec l’hypothèse nulle.Dans la section sur les effets négligeables, nous avions donné l’exemple d’une étude publiée où une corrélation de 0.08 était significative parce que l’échantillon était tout de même conséquent. Si essaie de reproduire au mieux les données, qu’observe-t-avec une approche bayésienne ?voit ici qu’avec un facteur de Bayes de 0.375 quasiment un rapport de 1/3, donc des preuves en faveur de l’hypothèse nulle. Ces données sont beaucoup plus cohérentes pour interpréter une validité divergente.","code":"\n# le fait de mettre une graine assure une reproductibilité des résultats \n\nset.seed(1234) \n# on va créer une fonction qui compare deux moyennes qui sont strictement égales lorsque la condition vaut 0 et\n# dont les moyennes se différencient de 0,2 écart-type (d = 0.2) quand la condition vaut 1\n# La fonction renvoie la probabilité du test t \n\nF2<-function(cond = 0){ \n  if(cond==0){\n  # on fait une comparaison de deux populations dont les moyennes sont strictement égales \n  t.out<-ttestBF(rnorm(n = 20, # taille de l'échantillon 1\n                      mean = 0, # moyenne du groupe 1\n                      sd = 1), # écart-type de l'échantillon 1\n                rnorm(n = 20, # taille de l'échantillon 2\n                      mean = 0,# moyenne du groupe 2\n                      sd = 1) )# écart-type de l'échantillon 2\n  }else{ \n                        t.out<-ttestBF(rnorm(n = 20, # taille de l'échantillon 1\n                                            mean = 0, # moyenne du groupe 1\n                                            sd = 1), # écart-type de l'échantillon 1\n                                      rnorm(n = 20, # taille de l'échantillon 2\n                                            mean = 0.2,# moyenne du groupe 2\n                                            sd = 1) ) # écart-type de l'échantillon 2\n                      }\n  \n  return(extractBF(t.out)$bf) # renvoie le FB \n  \n}\n\n# on crée des données (200 000) : pour créer de manière aléatoire nos conditions. Elles sont au nombre de 200 000\n# ici l'échantillonnage se fait de manière équiprobable avec approximativement autant de situations pour la\n# condition différence qu'absence de différence \ndf<-data.frame(condition = sample(0:1, \n                                  20000, #20000, \n                                  replace=T )) \n\n# on applique la fonction F pour chacune des lignes du jeu de données (variable condition)\ndf$BF<-apply(df, 1, F2)\n\n\ndf$sig1<-if_else(df$condition==1 & df$BF>3 | \n                   df$condition==0 & df$BF<1/3, \"correct\",\n                 if_else(df$condition==1 & df$BF<1/3 |  \n                           df$condition==0 & df$BF>3, \"incorrect\",\n                 \"manque de sensibilité\"))\n\n\nT1<-table(df$condition, df$sig1)\nT1  ##    \n##     correct incorrect manque de sensibilité\n##   0    3416       193                  6411\n##   1     428      2847                  6705\nlibrary(BayesFactor)\nF1<-function(n){\n  t.out<-ttestBF(rnorm(n, 100,15), \n                rnorm(n, 100.1,15))\n  return(extractBF(t.out)$bf)\n}\n\ndf<-data.frame(n = rep(2^(1:20), 100))\n\ndf$bf<-apply(df, 1, F1)\n\ndf$Decision<-if_else(df$bf>3, \"Preuves en faveur de l'alternative\",\n                    if_else(df$bf<1/3, \"Preuves en faveur de l'hypothèse nulle\",\n                    \"Manque de sensibilité\"))\n\ndf2<-df %>% group_by(n, Decision) %>% summarize(Nombre= n())\n\n\n\n\n\nggplot(df2, aes(x=n, y=Nombre, colour =Decision))+geom_line()+\n  ylab(\"Nombre de décision précise (sur 100)\")\nlibrary(BayesFactor)\nlibrary(MASS)\nlibrary(tidyverse)\nset.seed(46)\n# create the variance covariance matrix\nsigma<-rbind(c(1,0.08), c(0.08,1))\n# create the mean vector\nmu<-c(76.51, 51.45 ) \n# generate the multivariate normal distribution\ndf<-as.data.frame(mvrnorm(n=526, mu=mu, Sigma=sigma))\n\ncor.test(df[,1], df[,2])## \n##  Pearson's product-moment correlation\n## \n## data:  df[, 1] and df[, 2]\n## t = 1.9706, df = 524, p-value = 0.04929\n## alternative hypothesis: true correlation is not equal to 0\n## 95 percent confidence interval:\n##  0.0002779501 0.1700172554\n## sample estimates:\n##        cor \n## 0.08576994\ncorrBF<-correlationBF(\ny= df[,1],\nx=df[,2],\nrscale = \"ultrawide\"\n)\ncorrBF## Bayes factor analysis\n## --------------\n## [1] Alt., r=1 : 0.3752612 ±0%\n## \n## Against denominator:\n##   Null, rho = 0 \n## ---\n## Bayes factor type: BFcorrelation, Jeffreys-beta*"},{"path":"le-facteur-de-bayes.html","id":"rôle-de-la-priori-sur-le-bayes-factor","chapter":"11 Le facteur de Bayes","heading":"11.4 Rôle de l’a priori sur le Bayes factor","text":"Nous avons évoqué le fait que certaines personnes pouvaient être mal à l’aise avec l’idée que les résultats puissent dépendre de notre opinion plutôt que des faits objectifs.Une manière simple de répondre à ce problème est de mener un analyse robuste. Concrètement, celle-ci consiste à examiner la valeur de facteur de Bayes pour différentes hypothèses priori et s’assurer que le choix que vous avez fait n’influence pas de manière drastique vos résultats.Le package BayesFactor (Morey & Rouder, 2024) ne fournit pas de fonction permettant d’obtenir directement l’analyse robuste. Cependant, cela ne représente pas quelque chose de très difficile à faire. Le code annoté explique étape par étape la procédure à suivre.\nFigure 11.3: Graphique représentant les facteurs de Bayes calculés pour différents prior. Cette analyse est connue sous le nom d’analyse de robustesse.\nDans ce graphique, observe que, peu importe la distribution priori choisie parmi les priord par défaut du package BayesFactor (Morey & Rouder, 2024), dispose de preuves substantielles en faveur de l’existence d’une différence.Si le code ci-dessus est directement adaptable en fonction des situations, dans le package changeofevidence (Dechamps, 2025), Moritz développé des fonctions qui permettaient de le faire soit pour un test t ou pour une corrélation.Comme nous avions déjà utilisé ce package précédemment, peut réutiliser l’objet créé et le passer directement à la fonction bfRobustness.\nFigure 11.4: Analyses de robustesse avec le package changeofevidence\nLes réultats ne sont pas identique à l’analyse précédente car la fonction permet d’utiliser deux paramètres pour préciser la distribution priori : la variance du prior, comme dans le package BayesFactor mais également la localisation de la taille d’effet, ce qui n’est pas le cas dans le package BayesFactor. La bande représente la zone dans laquelle les BayesFactor peut se situer en fonction de la combinaison des deux paramètres.\nPour reproduire le même graphique que celui qui été obtenu précédemment, peut préciser que prior.loc est égal à 0, comme dans le package BayesFactor.\nFigure 11.5: Analyses de robustesse avec le package changeofevidence pour un prior de localisation fixé à 0.\n","code":"\n# on commencer par établir la liste de priors que nous souhaitons tester\n# ici c'est une séquence qui va de 0.05 à 2, avec un accent particulier \n# sur les priors prédéfinis dans le package BayesFactor (0.5,0.707, 1,1.41)\nrs <- c(seq(from = .05, to =2, by = 0.05), 0.5, 0.707, 1, 1.41)\n\n# on veut pouvoir les calculer tous en même temps. \n# pour cela, on va utiliser la fonction sapply qui va \n# calculer le Bayes Factor pour tous les priors qu'on va lui donner (stockés dans rs)\nbfs <- sapply(rs, \n              function(r) { # on crée un fonction spécifiquement pour notre propos\n  # on utilise exactement la même fonction que celle qu'on utilise pour un seul BF\n  # mais au lieu de donner une valeur au rscale, on lui donne l'argument r\n  # qui seront fournis par tous les rs              \n  bf <- ttestBF(x = QI, mu = 100, rscale = r)\n  # on extrait les facteurs de Bayes\n  extractBF(bf)$bf\n})\n\n# on crée un data.frame pour faire le graphique \nrobust<-data.frame(rs, bfs) \n# on réalise le graphique \n\n# note les Bayes Factor sont sur une échelle qui permet de les représenter \n#en valeur \n#brute. Il peut être utile de faire une transformation logarithmique lorque \n# leur valeur est très élevée. \n\n# on fait la ligne qui touche tous les points\nggplot(robust, aes(x=rs, y=bfs))+geom_line()+ \n  # on donne le titre à l'axe des x\n  xlab(\"Choix de la distribution a priori\")+\n  # on donne le titre à l'axe des y\n  ylab(\"Valeur du facteur de Bayes\")+\n  # on met en valeur les points des priors prédéfinis dans BayesFactor\n  geom_point(data=robust[41:44,], colour=\"blue\")+\n  # On indique sur le graphique à quel prior chaque point correspond \n  # en faisant un petit décalage afin d'éviter une superposition avec le point\n  annotate(\"text\", label = robust$rs[41:44], \n           x = robust$rs[41:44],\n           y = robust$bfs[41:44]+1, colour =\"blue\", check_overlap = TRUE)\nbf.robust <- bfRobustness(bf.exp2)## Highest BF = 102.73 with prior: Cauchy(0.85, 0.05)\nplot(bf.robust)\nbf.robust <- bfRobustness(bf.exp2, prior.loc=0)## Highest BF = 16.27 with prior: Cauchy(0, 0.7)\nplot(bf.robust)"},{"path":"comparaison-avec-lapproche-fréquentiste.html","id":"comparaison-avec-lapproche-fréquentiste","chapter":"12 Comparaison avec l’approche fréquentiste","heading":"12 Comparaison avec l’approche fréquentiste","text":"Dans la partie consacrée au rappel sur l’approche de Neyman-Pearson(Neyman & Pearson, 1933), nous avons vu que nous connaissions le taux d’erreurs de Type ou de Type II que nous allions commettre. Ces taux d’erreurs sont connus dès lors que nous connaissons les conditions exactes de l’expérimentation mais toute modification qui n’pas été annoncée va modifier ce taux d’erreurs. Parmi les facteurs (et sans doute sans être exhaustif) qui vont changer les choses, :le rajout d’observations ;des changements dans le plan d’analyse ;le fait de faire des analyses multiples sans corriger la probabilité ;le moment de l’explication, à savoir si l’hypothèse été faite avant ou après avoir regardé les données ;un changement dans la règle d’arrêt.Dans l’approche bayésienne, ne connait pas le taux d’erreur exact car il dépend de plusieurs paramètres comme la taille de l’échantillon, la distribution priori, ou encore des seuils utilisés pour interpréter le facteur de Bayes13. En revanche, le fait de modifier le plan d’analyse, de fournir une explication avant ou après avoir recueilli les données ou encore de rajouter des observations quand l’expérimentation n’est pas assez disriminante sont des élements qui n’ont aucune importance sur les décisions qu’va prendre. Tout est dans les données.Reprenons l’exemple du lancer de dé : eu 10 fois 6 sur 20 lancers, est-ce que faire l’hypothèse après avoir vu le résultat ou avant d’avoir lancé le dé change réellement le fait que le dé est probablement pipé ? Pour les Bayésiens, ce n’est pas le cas. Pour l’approche de Neyman-Pearson, cela de l’importance.Une difficulté qui freine souvent des personnes à adopter une approche bayésienne est qu’le sentiment que cette approche dépend des opinions qu’peut avoir concernant une hypothèse. Si ce n’est pas tout à fait faux, il faut se rappeler que la vraisemblance va au final dominer et que, même dans l’approche de Neyman-Pearson vous devez le faire : quand vous calculez la puissance de votre étude, vous devez vous faire une idée de la taille d’effet que vous devriez ou aimeriez avoir pour que l’étude ait du sens. Finalement, est-ce réellement différent ?Dans l’approche de Neyman-Pearson, le niveau de précision est apporté par l’intervalle de confiance. L’équivalent dans l’approche bayésienne est l’intervalle de crédibilité.Au final, les deux approches ont des avantages et des inconvénients à vous d’identifier leur complémentarité ou de savoir quelle approche vous convient le mieux.","code":""},{"path":"exercices.html","id":"exercices","chapter":"13 Exercices","heading":"13 Exercices","text":"","code":""},{"path":"exercices.html","id":"exemples-de-démonstration","chapter":"13 Exercices","heading":"13.1 Exemples de démonstration","text":"Dans le cadre de cet atelier, nous allons montrer comment faire un t de Student, un corrélation, une analyse de variance et un modèle linéaire.Pour chaque analyse, un exemple (qui peut être fictif) qui servira à illustrer la manière dont les fonctions doivent être utilisées.\nLes données de ces exemples sont disponibles dans le fichier données Demo.xls","code":""},{"path":"exercices.html","id":"le-t-de-student","chapter":"13 Exercices","heading":"13.1.1 Le t de Student","text":"Des chercheurs se sont demandé si le TOLD-P:3 permettait de discriminer des enfants présentant différentes formes de dysphasies. Ils ont comparé les scores obtenus par 50 enfants présentant une dysphasie phonologico-syntaxique (PS, les enfants présentent des difficultés pour s’exprimer) aux scores obtenus par 50 enfants présentant une dysphasie sémantique pragmatique (SP, les enfants présentent des troubles lexicaux) à ce tests.\nLes données sont disponibles sur la feuille TOLD.","code":""},{"path":"exercices.html","id":"avec-r","chapter":"13 Exercices","heading":"13.1.1.1 Avec R","text":"suppose que les packages sont chargés. commence par importer les données avec la fonction read_xlsx du package readxl (Wickham & Bryan, 2025).vérifie le jeu de données. En particulier, s’assure que les données soient considérées comme un data.frame et que les variablesEn l’occurrence, le jeu de données est à la fois un tibble et un data.frame. Cela ne devrait pas poser de souci. En revanche, le fait que la variable groupe soit considérée comme du caractère risque de générer un message d’erreur. la transforme en facteur grâce à la fonction .factor.regarde les statistiques descriptives pour pouvoir interpréter les données. Il y de nombreuses manière de le faire. J’utilise généralement la fonction describe du package psych (Revelle, 2025) mais n’importe quelle autre fonction fournissant les statistiques descriptives fait l’affaire.utilise la fonction ttestBF du package BayesFactor (Morey & Rouder, 2024) pour obtenir le facteur de Bayes. Les différents arguments sont expliqués par des comentaires dans le code.Il est à noter qu’peut également utiliser la fonction bfttest du package changeofprediction (Dechamps, 2025) Son mode de fonctionnement est assez similaire. Il y deux différences : il est possible de préciser si veut une hypothèse unilatérale ou bilatérale et peut fixer un priori sur la localisation de la taille d’effet.L’intérêt de cette dernière fonction est qu’elle permet d’obtenir directement les analyses séquentielles grâce à la fonction plot.et de robustesse avec la fonction bfRobustness.Il est également possible d’adapter le code que j’ai utilisé dans le chapitre sur le Facteur de Bayes","code":"\nTOLD<-read_xlsx(\"./Exercices/Demo.xlsx\", sheet=\"TOLD\")\nstr(TOLD)## tibble [100 × 3] (S3: tbl_df/tbl/data.frame)\n##  $ groupe: chr [1:100] \"PS\" \"PS\" \"PS\" \"PS\" ...\n##  $ TOLD  : num [1:100] 93 117 113 102 91 89 83 109 100 86 ...\n##  $ CASL  : num [1:100] 44 65 54 50 42 48 52 64 57 57 ...\nTOLD$groupe<-as.factor(TOLD$groupe)\nstr(TOLD)## tibble [100 × 3] (S3: tbl_df/tbl/data.frame)\n##  $ groupe: Factor w/ 2 levels \"PS\",\"SP\": 1 1 1 1 1 1 1 1 1 1 ...\n##  $ TOLD  : num [1:100] 93 117 113 102 91 89 83 109 100 86 ...\n##  $ CASL  : num [1:100] 44 65 54 50 42 48 52 64 57 57 ...\npsych::describeBy(TOLD ~groupe, data= TOLD,mat=T)##       item group1 vars  n  mean       sd median trimmed     mad min max range\n## TOLD1    1     PS    1 50 97.70 8.944842     98  97.425 10.3782  83 117    34\n## TOLD2    2     SP    1 50 86.62 8.886794     85  86.300 10.3782  73 103    30\n##            skew  kurtosis       se\n## TOLD1 0.1361170 -1.024715 1.264992\n## TOLD2 0.2100576 -1.126223 1.256782\nt.out<-ttestBF(# formule du type VD ~ VI\n              formula =TOLD ~groupe, \n               # nom du jeu de données\n               data=TOLD, \n               paired =F, \n              # l'argument mu permet d'indiquer une norme, notamment dans\n              # les t avec un seul échantillon\n              # cet argument n'est pas pris en compte si on a une formule\n              # et que la valeur vaut 0\n               mu = 0,\n               # distribution a priori à .707\n               rscale = .707,\n               # faut il calculer la distribution a posteriori (F =non)\n               posterior = F) \nt.out## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 : 796968 ±0%\n## \n## Against denominator:\n##   Null, mu1-mu2 = 0 \n## ---\n## Bayes factor type: BFindepSample, JZS\nbf.exp <- bfttest(TOLD ~groupe, , \n                  data= TOLD, \n                  alternative = \"two.sided\", \n                  prior.loc = 0, \n                  prior.r = sqrt(2))##   |                                                                              |                                                                      |   0%  |                                                                              |=                                                                     |   2%  |                                                                              |===                                                                   |   4%  |                                                                              |====                                                                  |   6%  |                                                                              |======                                                                |   8%  |                                                                              |=======                                                               |  10%  |                                                                              |=========                                                             |  12%  |                                                                              |==========                                                            |  14%  |                                                                              |===========                                                           |  16%  |                                                                              |=============                                                         |  18%  |                                                                              |==============                                                        |  20%  |                                                                              |================                                                      |  22%  |                                                                              |=================                                                     |  24%  |                                                                              |===================                                                   |  27%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  31%  |                                                                              |=======================                                               |  33%  |                                                                              |========================                                              |  35%  |                                                                              |==========================                                            |  37%  |                                                                              |===========================                                           |  39%  |                                                                              |=============================                                         |  41%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  45%  |                                                                              |=================================                                     |  47%  |                                                                              |==================================                                    |  49%  |                                                                              |====================================                                  |  51%  |                                                                              |=====================================                                 |  53%  |                                                                              |=======================================                               |  55%  |                                                                              |========================================                              |  57%  |                                                                              |=========================================                             |  59%  |                                                                              |===========================================                           |  61%  |                                                                              |============================================                          |  63%  |                                                                              |==============================================                        |  65%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  69%  |                                                                              |==================================================                    |  71%  |                                                                              |===================================================                   |  73%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  78%  |                                                                              |========================================================              |  80%  |                                                                              |=========================================================             |  82%  |                                                                              |===========================================================           |  84%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  88%  |                                                                              |===============================================================       |  90%  |                                                                              |================================================================      |  92%  |                                                                              |==================================================================    |  94%  |                                                                              |===================================================================   |  96%  |                                                                              |===================================================================== |  98%  |                                                                              |======================================================================| 100%\nplot(bf.exp)\nbf.robust <- bfRobustness(bf.exp,prior.loc =0 )## Highest BF = 886969.2 with prior: Cauchy(0, 1)\nplot(bf.robust)"},{"path":"exercices.html","id":"avec-jamovi","chapter":"13 Exercices","heading":"13.1.1.2 Avec Jamovi","text":"Pour faire un t de Student avec Jamovi, clique sur le menu t et choisit le type de t de l’approche bayésienne qui nous convient.choisit les variables de façon similaire à ce qui est fait pour l’approche de Neyman-Pearson.Et fixe la valeur pour la distribution priori.Pour les résultats, ils sont théoriquement identiques (ou très proches à ceux présentés dans la section R).","code":""},{"path":"exercices.html","id":"la-corrélation","chapter":"13 Exercices","heading":"13.1.2 La corrélation","text":"Kainafets et Relfihcs (5022) se sont intéressés à l’impact de la télévision sur les stéréotypes. Ils émettent l’hypothèse selon laquelle un programme de télévision peut avoir un impact prosocial. Pour tester leur hypothèse, ils proposent à leurs participants de regarder une fiction dans laquelle des personnes issues de différentes minorités voyagent dans l’espace à la recherche d’une planète qui permettrait à l’espèce humaine de survivre. Durant la fiction, plusieurs difficultés s’opposent à cet objectif. Les protagonistes arrivent néanmoins à résoudre ces problèmes, mais uniquement lorsque les différentes minorités agissent de concert avec le groupe majoritaire. Après la fiction, les chercheurs demandent aux participants de choisir parmi 50 descriptions de personnes (dont la moitié sont issues de minorités et l’autre moitié du groupe majoritaire), celles avec lesquelles elles voudraient collaborer pour construire une maison. Sur chacune des descriptions, une photo de la personne décrite était présentée en plus des habiletés et des diplômes obtenus. Après avoir décidé quelles étaient les personnes avec lesquelles elles aimeraient collaborer pour la construction d’une maison, les participants étaient invités à évaluer sur une échelle de 1 à 7 (de pas du tout probable à très probable), la plausibilité de la fiction présentée dans la première phase de l’étude. L’hypothèse des chercheurs est que les personnes qui trouveront la fiction plausible seront plus enclines à choisir des collaborateurs issus de minorités pour la construction de la maison. En plus de l’évaluation de la plausibilité, les chercheurs ont recueilli le nombre de personnes issues de minorités dans le choix des collaborateurs choisis par les 35 participants qui ont pris part à l’étude.Les données sont présentées sur la feuille plausibilite.\nPour cet exercice, nous illustrerons comment obtenir une distribution posteriori. Le raisonnement vaut également pour les autres fonctions décrites dans ce tutoriel.","code":""},{"path":"exercices.html","id":"avec-r-1","chapter":"13 Exercices","heading":"13.1.2.1 Avec R","text":"commence par importer les donnéesOn vérifie la structure des données.peut se faire une représentation graphique pour avoir une idée de l’existe ou non d’une corrélation et éventuellement identifier des valeurs influentes.fait l’analyse l’analyse avec la fonction correlationBF pour laquelle les arguments sont expliqués dans le code.peut à présent calculer l’intervalle de crédibilité.\nDeux méthodes peuvent être utilisées pour atteindre cet objectif.peut également utiliser le package bayestestR (Makowski et al., 2019)Il est tout à fait normal que les résultats ne soient pas identiques, les méthodes pour les calculer peuvent être sensiblement différentes et parce que les résultats sont obtenus en utilisant un chaîne de Monte-Carlo, c’est-à-dire une simulation.Il est à noter qu’peut adapter le code présenté dans la section relative aux analyses de robustesse pour l’appliquer à ce contexte.Notez qu’ici, utiliser une échelle logarithmique sur le graphique aurait pu faire sens.","code":"\nplausib<-read_xlsx(\"./Exercices/Demo.xlsx\", sheet=\"plausibilite\")\nstr(plausib)## tibble [35 × 2] (S3: tbl_df/tbl/data.frame)\n##  $ Plaus : num [1:35] 6 5 3 3 5 1 3 6 6 3 ...\n##  $ collab: num [1:35] 30 28 17 34 25 10 16 32 31 17 ...\nggplot(plausib, aes(x = Plaus , y =collab) )+\n  geom_point()+\n  stat_smooth(method = \"lm\",\n              formula = y ~ x,\n              geom = \"smooth\")\ncorr.out<-correlationBF(\n  # la variable sur l'ordonnée\n  y=plausib$Plaus,\n  # la variable en abcisse\n  x=plausib$collab,\n  # la distribution a priori\n  rscale = \"medium\",\n  # les limites inférieures et supérieures \n  # d'un intervalle à l'intérieur duquel \n  # on pense que se trouve la corrélation \n  nullInterval = NULL,\n  # Faut il calculer la distribution a posteriori\n  posterior = F)\ncorr.out## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.333 : 1477275 ±0%\n## \n## Against denominator:\n##   Null, rho = 0 \n## ---\n## Bayes factor type: BFcorrelation, Jeffreys-beta*\n# calcul de la distribution a posteriori\npost<-posterior(corr.out, iterations = 1000)\nplot(post)\nsummary(post)## \n## Iterations = 1:1000\n## Thinning interval = 1 \n## Number of chains = 1 \n## Sample size per chain = 1000 \n## \n## 1. Empirical mean and standard deviation for each variable,\n##    plus standard error of the mean:\n## \n##        Mean      SD Naive SE Time-series SE\n## rho  0.7385 0.08045 0.002544       0.007256\n## zeta 0.9706 0.17905 0.005662       0.014835\n## \n## 2. Quantiles for each variable:\n## \n##        2.5%    25%   50%    75%  97.5%\n## rho  0.5429 0.6888 0.750 0.8005 0.8622\n## zeta 0.6083 0.8456 0.973 1.1000 1.3020\nlibrary(bayestestR)\nci_hdi <- ci(post, method = \"HDI\")\nci_hdi## Highest Density Interval\n## \n## Parameter |      95% HDI\n## ------------------------\n## rho       | [0.60, 0.89]\n## zeta      | [0.60, 1.26]\n#les 4 dernières valeurs sont les valeurs \"réduite\", \n#\"moyenne\", \"large\" et \"ultra large\"\nrs <- c(seq(from = .05, to =2, by = 0.05), \n        1/sqrt(27), 1/3, 1/sqrt(3), 1)\n\n# on veut pouvoir les calculer tous en même temps. \n# pour cela, on va utiliser la fonction sapply qui va \n# calculer le Bayes Factor pour tous les priors qu'on va lui donner (stockés dans rs)\nbfs <- sapply(rs, \n              function(r) { # on crée un fonction spécifiquement pour notre propos\n                # on utilise exactement la même fonction que celle qu'on utilise pour un seul BF\n                # mais au lieu de donner une valeur au rscale, on lui donne l'argument r\n                # qui seront fourni par tous les rs              \n                bf <- correlationBF(y=plausib$collab,\n                                    x=plausib$Plaus,\n                                    rscale = r,\n                                    nullInterval = NULL,\n                                    posterior = F)\n                # on extrait les facteurs de Bayes\n                extractBF(bf)$bf\n              })\n\n# on crée un data.frame pour faire le graphique \nrobust<-data.frame(rs, bfs) \n# on réalise le graphique \nrobust$bfs<-round(robust$bfs, 3)\nrobust$rs<-round(robust$rs, 3)\n# on fait la ligne qui touche tous les points\nggplot(robust, aes(x=rs, y=bfs))+geom_line()+ \n  # on donne le titre à l'axe des x\n  xlab(\"Choix de la distribution a priori\")+\n  # on donne le titre à l'axe des y\n  ylab(\"Valeur du facteur de Bayes\")+\n  # on met en valeur les points des priors prédéfinis dans BayesFactor\n  geom_point(data=robust[41:44,], colour=\"blue\")+\n  # On indique sur le graphique à quel prior chaque point correspond *\n  # en faisant un petit décalage afin d'éviter une superposition avec le point\n  annotate(\"text\", label = robust$rs[41:44], \n           x = robust$rs[41:44]+0.2,\n           y = robust$bfs[41:44]+0.2, colour =\"blue\", check_overlap = TRUE)"},{"path":"exercices.html","id":"avec-jamovi-1","chapter":"13 Exercices","heading":"13.1.2.2 Avec Jamovi","text":"commence par choisir le menu corrélation bayésienne par paire.indique les variables d’intérêt.coche tous les options en n’oubliant pas de préciser la distribution priori. Dans le package BayesFactor, une distrubtion étroite vaut \\(1/\\sqrt{27}\\), une moyenne vaut 1/3, une large vaut \\(1/\\sqrt{3}\\) et une ultra large vaut 1. Pour répliquer les résultats, il faut une distribution de 1/3.","code":""},{"path":"exercices.html","id":"la-régression","chapter":"13 Exercices","heading":"13.1.3 La régression","text":"Faire une régression sous l’angle bayésien ne présente pas de réelle particularité par rapport au fait de faire une corrélation ou un test t.Des chercheurs s’intéressent au niveau de détresse émotionnelle et formulent l’hypothèse selon laquelle la détresse serait inversement reliée à l’adoption de stratégies de coping. Ces chercheurs demandent à leurs participants d’évaluer sur une échelle de 1 (pas du tout) à 7 (en totale détresse) leur niveau de détresse émotionnelle. Ils leur demandent ensuite d’expliquer les comportements qu’ils adoptent lorsqu’ils ne se sentent pas bien. Les chercheurs attendent 30 réponses. Une fois, les réponses récoltées, ils comptent le nombre de comportements de coping. Par ailleurs, les chercheurs ont également utilisé une échelle d’anxiété sur 50 et ont demandé l’âge des participants.","code":""},{"path":"exercices.html","id":"avec-r-2","chapter":"13 Exercices","heading":"13.1.3.1 Avec R","text":"commence par importer les donnéesOn vérifie la structure des données.peut se faire une représentation graphique pour avoir une idée de l’existe ou non d’une corrélation et éventuellement identifier des valeurs influentes. Le package olsrr permet d’obtenir des graphiques des effets conditionnels dans les modèles linéaires fréquentistes. La représentation graphique n’étant pas dépendante de l’approche, peut l’utiliser sans souci.fait l’analyse l’analyse avec la fonction lmBF pour laquelle les arguments sont expliqués dans le code.observe que nous avons le facteur de Bayes pour l’ensemble des effets du modèle. Pour avoir les effets séparément et voir dans quelle mesure une variable apporte quelque chose au modèle, il faut modéliser chacun des modèles. Par exemple, quand veut savoir si l’âge apporte quelque chose de plus que le coping, peut faire :En l’occurrence, le facteur de Bayes est très largement supérieur à 100, sait que l’âge un apport important au modèle.","code":"\ndetresse<-read_xlsx(\"./Exercices/Demo.xlsx\", sheet=\"detresse\")\nstr(detresse)## tibble [69 × 3] (S3: tbl_df/tbl/data.frame)\n##  $ detresse: num [1:69] 4 5 3 4 5 3 4 4 7 1 ...\n##  $ coping  : num [1:69] 7 6 10 7 8 9 4 5 27 11 ...\n##  $ age     : num [1:69] 70 56 76 75 84 54 55 54 66 59 ...\nlibrary(olsrr)\nmodel<-lm(detresse~coping+age, detresse)\n\nols_plot_added_variable(model)\nlm.out<-lmBF(\n    # on précise le modèle du type VD ~VI1+VI2\n    # on peut mettre des interactions VD ~VI1+VI2+VI1:VI2\n     formula = detresse~coping+age,\n     # on précise le jeu de données \n     data = detresse,\n     # on peut préciser la variable aléatoire\n     # sous forme de caractère comme \"ID\"\n    whichRandom = NULL,\n    # on peut préciser les ditributions pour les effets d'intérêts\n    rscaleFixed = \"medium\",\n    # et contrôler la distribution de la variable aléatoire\n    # on peut toujours laisser la valeur par défaut\n    rscaleRandom = \"nuisance\",\n    # il s'agit du prior sur la pente\n    # mais la différence par rapport à rscaleFixed n'est pas claire. \n    # il est possible que rscaleFixed s'applique à tout\n    # et que rscalecont et rscaleRandom permet de dissocier les deux\n    rscaleCont = \"medium\",\n    # il est possible de préciser des prior pour chaque effet\n    # par exemple c(coping = 0.5, age =0.3)\n    # on ne précise pas ici\n    rscaleEffects = NULL,\n    # la distribution a posteriori doit elle être calculée. \n    posterior = FALSE)\n  \n  \n  lm.out## Bayes factor analysis\n## --------------\n## [1] coping + age : 5902276 ±0%\n## \n## Against denominator:\n##   Intercept only \n## ---\n## Bayes factor type: BFlinearModel, JZS\nlm.out1<-lmBF(\n     formula = detresse~coping,\n     data = detresse,\n    whichRandom = NULL,\n    rscaleFixed = \"medium\",\n    rscaleRandom = \"nuisance\",\n    rscaleCont = \"medium\",\n    rscaleEffects = NULL,\n    posterior = FALSE)\n  \nlm.out2<-lmBF(\n     formula = detresse~coping+age,\n     data = detresse,\n    whichRandom = NULL,\n    rscaleFixed = \"medium\",\n    rscaleRandom = \"nuisance\",\n    rscaleCont = \"medium\",\n    rscaleEffects = NULL,\n    posterior = FALSE)\n  \n  lm.out2/lm.out1## Bayes factor analysis\n## --------------\n## [1] coping + age : 448076.1 ±0%\n## \n## Against denominator:\n##   detresse ~ coping \n## ---\n## Bayes factor type: BFlinearModel, JZS"},{"path":"exercices.html","id":"avec-jamovi-2","chapter":"13 Exercices","heading":"13.1.3.2 Avec Jamovi","text":"Dans Jamovi, peut faire des modèles linéaires avec l’approche bayésienne en cliquant sur Bayesian Linear Regression.Il permet de faire des modèles simples (sans interaction) en entrant les variables du côté de la variable dépendante et des covariables.Les résultats permettent de comparer le facteur de Bayes d’un modèle donné par rapport au modèle où il n’y que la variable aléatoire (non spécifiée) ou par rapport au meilleur modèle. En réalité, dans l’approche bayésienne, veut pouvoir savoir si une variable particulière apporte quelque chose par rapport à des variables qu’impose dans le modèle. Il faut donc pouvoir faire le rapport des facteurs de Bayes (ce qui donne également un facteur de Bayes) mais ce n’est pas possible dans Jamovi. Jamovi propose de montrer les 10 meilleurs modèles pour ne pa montrer tous les modèles car le nombre de modèles augmente de manière exponentielle avec le nombre de variables (en suivant la règle \\(n^2-1\\) où n est le nombre de variables)","code":""},{"path":"exercices.html","id":"lanalyse-de-variance","chapter":"13 Exercices","heading":"13.1.4 L’analyse de variance","text":"Stefaniak et al. (Stefaniak et al., 2008) se sont intéressés aux mécanismes d’apprentissage implicite. Ils ont administré à leurs participants une tâche de temps de réaction sériel. Dans cette tâche, demande aux participants de répondre le plus rapidement et le plus précisément possible aux stimuli qui apparaissent à différentes localisation sur l’écran. Les stimuli n’apparaissent pas de manière aléatoire mais suivent, à l’insu des participants, une séquence. Cette séquence suit une structure probabilité (85% de régularités et 15% d’irrégularités) La tâche est composée de 15 blocs dans lesquels la séquence est présentée à 8 reprises. Les blocs 1 à 12 sont des blocs d’apprentissage. Le bloc 13 est un bloc dans lequel une autre séquence que la séquence d’apprentissage est utilisée et le bloc 14 est à nouveau un bloc où la séquence d’apprentissage initiale est utilisée. L’apprentissage se manifeste par des temps de réaction de plus en plus courts entre les blocs 1 à 12 et un ralentissement de la vitesse de réponse pour le bloc 13.\nLeur objectif était de voir si une connaissance explicite de la séquence améliorait l’apprentissage. Ils ont donc comparé l’apprentissage pour un groupe en condition incidente, un groupe dont les connaissances se limitait à la séquence régulière et un groupe qui avait non seulement la connaissance de la séquence régulière mais également de la manière dont les irrégularités étaient construites.","code":""},{"path":"exercices.html","id":"avec-r-3","chapter":"13 Exercices","heading":"13.1.4.1 Avec R","text":"Nous n’allons pas reprendre les étapes de bases et les réexpliquer. Ce sont toujours les mêmes. Nous focaliserons sur la préparation du jeu de données et sur la réalisation de l’analyse.Tout d’abord, il faut préparer les données car, pour des mesures répétées, R besoin d’un format long et non d’un format large14. Pour ce faire, va sélectionner les variables d’intérêt avec le package dplyr (Wickham et al., 2023) et sa fonctioin select et utiliser la fonction melt du package reshape2 (Wickham, 2007).important : comme plusieurs fonction dans R s’appelle ‘select’, il peut être bon de préciser dans quelle package il faut aller chercher cette fonction entre tapant le nom du package suivi de deux fois deux points dplyr::select.Il est souvent bon d’être explicite sur la variable aléatoire quand fait des anovas, en particulier des anovas à mesure répétées. Nous allons donc rajouter une variable identifiant les participants.peut à présent réaliser l’analysePour savoir si l’effet d’interaction apporte quelque chose au modèle, compare le modèle avec l’interaction (modèle 4) avec le modèle le plus proche sans l’interaction (modèle 3)Ici, l’interaction tend plutôt à favoriser l’hypothèse nulle.Il est à noter qu’il est possible de contrôler les distributions priori exactement de la même manière que celle qui été décrite pour lmBFPour réaliser les contrastes sous un angle bayésien, vous pouvez réaliser une anova dans une perspective fréquentiste, faire les contrastes et utiliser la valeur du t du contraste avec l fonction ttest.tstat. Si je voulais comparer mon groupe incident aux deux autres groupes et que la valeur du contraste valeur 1.2, utiliserait la fonction ainsi :","code":"\nlibrary(reshape2)\nAI2<-AI %>% dplyr::select(TYPE, BLOC1, BLOC12, BLOC13)\n\nAI.long<-melt(AI2,id.vars=\"TYPE\")\nnames(AI.long)<-c(\"TYPE\", \"BLOC\", \"Temps\")\nAI.long$TYPE<-as.factor(AI.long$TYPE)\nAI.long$ID<-rep(paste0(\"p\",1:60), 3)\nAI.long$ID<-as.factor(AI.long$ID)\naov.out<- generalTestBF(# on précise le modèle\n   # remarquez la présence de l'identifiant dans le modèle\n   # R en a besoin pour identifier que c'est une mesure répétée \n                        Temps ~ TYPE*BLOC + ID, \n                        data = AI.long,\n                        # on explicite ici que ID est le facteur aléatoire\n                        whichRandom = \"ID\",\n                        # pour éviter de multiplier les modèle calculés\n                        # on va conserver la variable aléatoire dans tous\n                        # les modèles\n                        # cela évite d'avoir VD~ID, VD~VI1, VD~ID+VI1\n                        \n                        neverExclude=\"ID\")\naov.out## Bayes factor analysis\n## --------------\n## [1] TYPE + ID                    : 62469120306                 ±0.71%\n## [2] BLOC + ID                    : 867788093218138308002666860 ±0.95%\n## [3] TYPE + BLOC + ID             : 647737570786917884260024882 ±3.79%\n## [4] TYPE + BLOC + TYPE:BLOC + ID : 247996970907350544346868868 ±1.5%\n## [5] ID                           : 102575400468                ±0%\n## \n## Against denominator:\n##   Intercept only \n## ---\n## Bayes factor type: BFlinearModel, JZS\naov.out[4]/aov.out[3]## Bayes factor analysis\n## --------------\n## [1] TYPE + BLOC + TYPE:BLOC + ID : 0.3828664 ±4.08%\n## \n## Against denominator:\n##   Temps ~ TYPE + BLOC + ID \n## ---\n## Bayes factor type: BFlinearModel, JZS\nttest.tstat(1.2, n1 =20, n2 = 40, rscale = \"medium\")## $bf\n## [1] -0.696399\n## \n## $properror\n## [1] 0.00007990923\n## \n## $method\n## [1] \"quadrature\""},{"path":"exercices.html","id":"avec-jamovi-3","chapter":"13 Exercices","heading":"13.1.4.2 Avec Jamovi","text":"Pour faire une anova bayésienne mixte, il faut choisir le module anova à meure répétée bayésienne.Il faut préciser les nom des modalités à mesure répétées dans la section ‘Repeated Measures Factors’ et placer dans la section ‘Repeated Measures Cells’ les variables de votre jeu de données correspondant à ce l’ordre ‘Repeated Measures Factors’ et vous obtenez vos résultats.Pour terminer, vous pouvez obtenir les comparaison 2 à 2 en cliquant sur ‘post-hoc test’.Pour les plus avertis, il est possible de contrôler la distribution priori en cliquant sur “options avancées”.","code":""},{"path":"exercices.html","id":"exercice-2","chapter":"13 Exercices","heading":"13.2 Exercice 2","text":"Priolo et ses collaborateur (Priolo et al., 2023) ont cherché à repliqué les effets des nudges sur l’efficacité comportementale et l’acceptabilité dans le cadre d’une expérience de terrain en contexte naturel. Le nudge étudié consiste à définir par défaut l’option « zéro sucre » dans les distributeurs de boissons chaudes d’une université française. Deux campus ont été comparés : le campus (option par défaut : 0 sucre) et le campus B (option par défaut : 3 sucres). L’efficacité du nudge été mesurée en observant la quantité de sucre effectivement choisie par les participants, et son acceptabilité été évaluée au moyen d’un questionnaire.Les données (généreusement mises à disposition par Daniel Priolo) sont disponibles dans le fichier Nudge.Voici la description des variables (d’intérêt)Participants : Identifiant du participantCampus : Campus (qui 0 sucres par défaut) et campus B (3 sucrus pas défaut)Gender : genre du / de la participant·eAge : age du du / de la participant·eCSP : catégorie socioprofessionnelleDiscipline_Cat : UFR de l’étudiant·eDiscipline : formation de l’étudiant·eSaw_Sugar : est-ce que la personne vu ou non la valeur en sucre par défaut (0 =non, 1 = oui)UC = combien de sucres met la personne d’habitudeOC = combien de sucres la personne misOC_B = -t-elle mis du sucre ? (0 = non, 1 = oui)UC_B = met-elle du sucre d’habitude (0 = non, 1 = oui)MOY_ACC = acceptabilité d’être nudgé - d’avoir une option par défaut pour réduire la consommation de sucreMOY_FORCE = quel point est-ce que la personne était favorable à l’idée de réduire sa consommation en sucreLes autres variables ne seront pas utilisées.Les données sont disponibles ici.Importer les données.Vérifiez si l’effet du nudge fonction en montrant que les étudiant·e du campus consommé moins de sucre que ceux du campus B.Pour mener votre analyse :\n- identifier l’analyse que vous allez faire\n- établissez la distribution priori en vous appuyant sur les données de (Mertens et al., 2021) disponibles ici\n- Interpétez les résultats\n- Vérifiez que vos résultats sont robustes à différents prior et qu’ils ne sont pas dépendants de quelques observations seulement.Puisque dans la méta-analyse, la taille d’effet est 0.43, nous allons fixé le prior à “medium”.\nL’analyse qu’il faut réaliser est un test t de Student.Le facteur de Bayes indique que nous avons des preuves extrêmes en faveur d’une différence de consommation de surces entre les deux campsus, où les étudiant·es sur le campus B, avec une moyenne à 2.3 sucres, consomment plus de sucres que ceux sur le campus , avec une moyenne de 0.82 sucres.\nL’analyse séquentielle indique que la tendance est globalement toujours ascendante au fur et à mesure que l’échantillon grandit et nos résultats ne semblent pas être influencés par le choix du prior puisque les analyses de robustesses montrent que les facteurs bayésiens sont supérieur à \\(10^6\\) pour l’ensemble des distributions priori examinées.","code":"\nlibrary(readxl)\nlibrary(BayesFactor)\nlibrary(changeofevidence)\nlibrary(bayestestR)\npriolo<-read_xlsx(\"./Exercices/Nudge.xlsx\")\n\npriolo <-as.data.frame(priolo)\nt.out<-ttestBF(formula =OC ~Campus, \n               data=priolo, paired =F, \n               rscale = .707) # prior à .707\nt.out## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 : 23796524 ±0%\n## \n## Against denominator:\n##   Null, mu1-mu2 = 0 \n## ---\n## Bayes factor type: BFindepSample, JZS\nbf.exp <- bfttest(OC ~Campus, \n                  data= priolo, \n                  alternative = \"two.sided\", \n                  prior.loc = 0, \n                  prior.r = sqrt(2))##   |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |==                                                                    |   4%  |                                                                              |===                                                                   |   4%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |==============================                                        |  44%  |                                                                              |===============================                                       |  44%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  56%  |                                                                              |========================================                              |  56%  |                                                                              |========================================                              |  57%  |                                                                              |========================================                              |  58%  |                                                                              |=========================================                             |  59%  |                                                                              |==========================================                            |  59%  |                                                                              |==========================================                            |  60%  |                                                                              |==========================================                            |  61%  |                                                                              |===========================================                           |  61%  |                                                                              |============================================                          |  62%  |                                                                              |============================================                          |  63%  |                                                                              |============================================                          |  64%  |                                                                              |=============================================                         |  64%  |                                                                              |==============================================                        |  65%  |                                                                              |==============================================                        |  66%  |                                                                              |===============================================                       |  67%  |                                                                              |================================================                      |  68%  |                                                                              |================================================                      |  69%  |                                                                              |=================================================                     |  70%  |                                                                              |==================================================                    |  71%  |                                                                              |==================================================                    |  72%  |                                                                              |===================================================                   |  73%  |                                                                              |====================================================                  |  74%  |                                                                              |====================================================                  |  75%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  76%  |                                                                              |======================================================                |  77%  |                                                                              |======================================================                |  78%  |                                                                              |=======================================================               |  79%  |                                                                              |========================================================              |  79%  |                                                                              |========================================================              |  80%  |                                                                              |========================================================              |  81%  |                                                                              |=========================================================             |  81%  |                                                                              |==========================================================            |  82%  |                                                                              |==========================================================            |  83%  |                                                                              |==========================================================            |  84%  |                                                                              |===========================================================           |  84%  |                                                                              |============================================================          |  85%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  87%  |                                                                              |==============================================================        |  88%  |                                                                              |==============================================================        |  89%  |                                                                              |===============================================================       |  90%  |                                                                              |================================================================      |  91%  |                                                                              |================================================================      |  92%  |                                                                              |=================================================================     |  93%  |                                                                              |==================================================================    |  94%  |                                                                              |==================================================================    |  95%  |                                                                              |===================================================================   |  96%  |                                                                              |====================================================================  |  96%  |                                                                              |====================================================================  |  97%  |                                                                              |====================================================================  |  98%  |                                                                              |===================================================================== |  99%  |                                                                              |======================================================================|  99%  |                                                                              |======================================================================| 100%\nplot(bf.exp)\nbf.robust <- bfRobustness(bf.exp,prior.loc =0 )## Highest BF = 25788787 with prior: Cauchy(0, 1)\nplot(bf.robust)\npsych::describe(OC ~Campus, data= priolo)## \n##  Descriptive statistics by group \n## Campus: A\n##    vars  n mean   sd median trimmed mad min max range skew kurtosis   se\n## OC    1 78 0.82 1.33      0    0.58   0   0   5     5 1.45     1.13 0.15\n## ------------------------------------------------------------ \n## Campus: B\n##    vars  n mean  sd median trimmed mad min max range  skew kurtosis   se\n## OC    1 67  2.3 1.3      3    2.33   0   0   5     5 -0.47    -0.65 0.16"},{"path":"exercices.html","id":"exercice-3","chapter":"13 Exercices","heading":"13.3 Exercice 3","text":"Testez si l’acceptabilité du nudge dépend de la force de l’attitude.\nVous n’avez pas d’étude qui vous offre des balises. Adoptez une attitude qui vous permettra de justifier vos résultats.Vérifiez entre quelles valeurs se situent l’intervalle de crédibilité.L’analyse que nous devons réaliser est une corrélation. Il est raisonnable de penser que la force de l’attitude favorisent l’acceptabilité du nudge mais peut difficilement imaginer qu’une personne s’oppose farouchement à la mise en place d’une politique visant à adopter des comportements (alimentaires) plus sains. peut imaginer une corrélation moyenne au maximum.En l’occurence le facteur de Bayes indique des preuves en faveur d’une corrélation. Néanmoins cette corrélation est faible car pour des prior supérieur à medium, le facteur de Bayes tend vers une zone d’incertitude.","code":"\nlibrary(bayestestR)\ncorr.out<-correlationBF(\ny=priolo$MOY_ACC,\nx=priolo$MOY_FORCE,\nrscale = \"medium\",\nnullInterval = NULL,\nposterior = F)\n\n# calcul de l'intervalle de crédibilité \npost<-posterior(corr.out, iterations = 1000)\npost2 = recompute(post, iterations = 10000)\nplot(post2)\nsummary(post2)## \n## Iterations = 1:10000\n## Thinning interval = 1 \n## Number of chains = 1 \n## Sample size per chain = 10000 \n## \n## 1. Empirical mean and standard deviation for each variable,\n##    plus standard error of the mean:\n## \n##        Mean      SD  Naive SE Time-series SE\n## rho  0.1857 0.07901 0.0007901      0.0008677\n## zeta 0.1891 0.08232 0.0008232      0.0009015\n## \n## 2. Quantiles for each variable:\n## \n##         2.5%    25%    50%    75%  97.5%\n## rho  0.02499 0.1328 0.1874 0.2391 0.3374\n## zeta 0.02500 0.1336 0.1896 0.2439 0.3511\nplot(post2[,1:2])\n\n\n\n## OU\ncorr.out.post<-correlationBF(\ny=priolo$MOY_ACC,\nx=priolo$MOY_FORCE,\nrscale = \"medium\",\nnullInterval = NULL,\nposterior = T, iterations =1000)\n\n\nci_hdi <- ci(corr.out.post, method = \"HDI\")\nci_hdi## Highest Density Interval\n## \n## Parameter |      95% HDI\n## ------------------------\n## rho       | [0.03, 0.33]\n## zeta      | [0.03, 0.34]\nggplot(priolo, aes(x = MOY_FORCE, y =MOY_ACC) )+\n  geom_point()+\n  stat_smooth(method = \"lm\",\n              formula = y ~ x,\n              geom = \"smooth\")\nrs <- c(seq(from = .05, to =2, by = 0.05), 1/sqrt(27), 1/3, 1/sqrt(3), 1)\n\n# on veut pouvoir les calculer tous en même temps. \n# pour cela, on va utiliser la fonction sapply qui va \n# calculer le Bayes Factor pour tous les priors qu'on va lui donner (stockés dans rs)\nbfs <- sapply(rs, \n              function(r) { # on crée un fonction spécifiquement pour notre propos\n                # on utilise exactement la même fonction que celle qu'on utilise pour un seul BF\n                # mais au lieu de donner une valeur au rscale, on lui donne l'argument r\n                # qui seront fourni par tous les rs              \n                bf <- correlationBF(y=priolo$MOY_ACC,\n                                    x=priolo$MOY_FORCE,\n                                    rscale = r,\n                                    nullInterval = NULL,\n                                    posterior = F)\n                # on extrait les facteurs de Bayes\n                extractBF(bf)$bf\n              })\n\n# on crée un data.frame pour faire le graphique \nrobust<-data.frame(rs, bfs) \n# on réalise le graphique \nrobust$bfs<-round(robust$bfs, 3)\nrobust$rs<-round(robust$rs, 3)\n# on fait la ligne qui touche tous les points\nggplot(robust, aes(x=rs, y=bfs))+geom_line()+ \n  # on donne le titre à l'axe des x\n  xlab(\"Choix de la distribution a priori\")+\n  # on donne le titre à l'axe des y\n  ylab(\"Valeur du facteur de Bayes\")+\n  # on met en valeur les points des priors prédéfinis dans BayesFactor\n  geom_point(data=robust[41:44,], colour=\"blue\")+\n  # On indique sur le graphique à quel prior chaque point correspond *\n  # en faisant un petit décalage afin d'éviter une superposition avec le point\n  annotate(\"text\", label = robust$rs[41:44], \n           x = robust$rs[41:44]+0.2,\n           y = robust$bfs[41:44]+0.2, colour =\"blue\", check_overlap = TRUE)"},{"path":"exercices.html","id":"exercice-4","chapter":"13 Exercices","heading":"13.4 Exercice 4","text":"Vérifiez si l’écart sur la consommation observée de sucres entre les deux campus ne peut pas s’expliquer par des différences de consommations entre les étudiant·es qui préexistaient.Soyez cohérent·e dans le choix du prior\nAttention, le jeu de données doit être préparé pour pouvoir réaliser l’analyse correctement.Les moyennes indiquent que les personnes sur le campus consomment moins de sucre que celles sur le campus B et que cette différence est d’autant plus marquée sur la différence observée par rapport à la différence rapportée de leur consommation habituelle. Le rapport entre le facteur de Bayes avec l’interaction et sans l’interaction est de 287, ce qui représente des preuves extrêmes en faveur de la présence de l’interaction.","code":"\nrequire(reshape2)\nrequire(dplyr)\n priolo2<-priolo %>% dplyr::select( Participants, Campus, UC, OC)\n priolo.long<-melt(priolo2, id.vars = c(\"Participants\", \"Campus\"), variable.name=\"Localisation\", value.name=\"Quantite\")\n \npriolo.long$Participants<-as.factor(priolo.long$Participants)\n \npriolo.long$Campus<-as.factor(priolo.long$Campus)\n \naov.out<- generalTestBF(Quantite ~ Campus*Localisation + Participants, data = priolo.long, whichRandom = \"Participants\",\nneverExclude=\"Participants\", progress=FALSE)\naov.out## Bayes factor analysis\n## --------------\n## [1] Campus + Participants                                      : 28426215199734063104   ±1.11%\n## [2] Localisation + Participants                                : 947828574210654        ±1.15%\n## [3] Campus + Localisation + Participants                       : 20219846208840953856   ±1.45%\n## [4] Campus + Localisation + Campus:Localisation + Participants : 6785407505150435655680 ±4.63%\n## [5] Participants                                               : 1322151571553891       ±0%\n## \n## Against denominator:\n##   Intercept only \n## ---\n## Bayes factor type: BFlinearModel, JZS\naov.out[4]/aov.out[3]## Bayes factor analysis\n## --------------\n## [1] Campus + Localisation + Campus:Localisation + Participants : 335.5816 ±4.85%\n## \n## Against denominator:\n##   Quantite ~ Campus + Localisation + Participants \n## ---\n## Bayes factor type: BFlinearModel, JZS\npsych::describeBy(Quantite ~ Campus*Localisation, data=priolo.long,mat=T)##           item group1 group2 vars  n      mean       sd median  trimmed    mad\n## Quantite1    1      A     UC    1 78 1.0000000 1.338734      0 0.828125 0.0000\n## Quantite2    2      B     UC    1 67 1.6567164 1.492935      1 1.527273 1.4826\n## Quantite3    3      A     OC    1 78 0.8205128 1.326489      0 0.578125 0.0000\n## Quantite4    4      B     OC    1 67 2.2985075 1.302851      3 2.327273 0.0000\n##           min max range       skew     kurtosis        se\n## Quantite1   0   5     5  0.9938842 -0.006426413 0.1515817\n## Quantite2   0   5     5  0.4270383 -0.942605220 0.1823911\n## Quantite3   0   5     5  1.4468359  1.127781997 0.1501953\n## Quantite4   0   5     5 -0.4731558 -0.651910476 0.1591686"},{"path":"exercices.html","id":"exercice-5","chapter":"13 Exercices","heading":"13.5 Exercice 5","text":"Drouillet et al. (2018) ont voulu savoir dans quelle mesure les capacités d’apprentissage procédural étaient impliqués dans la compréhension des métaphores.\nDans cette étude, les participants devaient décider si une phrase avait du sens ou non. Les participant·es étaient amené·es à traiter des expressions littérales (balayer la poussière), métaphorique (balayer ses soucis) ou pour lesquels il était très difficile de trouver un sens (balayer les nuages).\nD’après Ullman (2001), la mémoire déclarative est impliquée dans le lexique (et donc dans la compréhension) tandis que la mémoire procédurale devrait être impliquée dans la grammaire. Ainsi, la mémoire procédurale ne devrait pas être impliqué dans la compréhension des métaphores.\nVérifiez si la mémoire déclarative (évaluée par le Mill Hill), les capacités d’apprentissage implicite (indice_app_impl) ou leur interaction permet de prédire la difficulté que représente de traiter une métaphore par rapport à une phrase littérale (indice1.meta.baseline) et la faciliter que représente de traiter une métaphore par rapport à une phrase qui n’pas sens (indice2.meta.baseline).Les données sont disponibles dans le fichier “Drouillet2018.xlsx”Réalisez l’analyse adaptée et interpréter les résultats.Ces analyses montrent que la difficulté que rencontrent les personnes pour comprendre une métaphore par rapport à du langage littéral s’explique par l’interaction entre la mémoire procédurale et la mémoire déclarative. Tous les autres modèles ne sont pas discriminants.","code":"\ndrouillet<-read_xlsx(\"./Exercices/Drouillet2018.xlsx\")\n\ndrouillet$participant<-as.factor(drouillet$participant)\nlm.out1.1<-lmBF(indice1.meta.baseline ~  Mill_Hill + participant, \n             data = drouillet, whichRandom = \"participant\")\nlm.out1.2<-lmBF(indice1.meta.baseline ~ indice_app_impl+ Mill_Hill + participant, \n             data = drouillet, whichRandom = \"participant\")\nlm.out1.3<-lmBF(indice1.meta.baseline ~ indice_app_impl+ Mill_Hill +\n                indice_app_impl:Mill_Hill+ participant, \n             data = drouillet, whichRandom = \"participant\")\n\n\nlm.out2.1<-lmBF(indice2.meta.baseline ~  Mill_Hill + participant, \n             data = drouillet, whichRandom = \"participant\")\nlm.out2.2<-lmBF(indice2.meta.baseline ~ indice_app_impl+ Mill_Hill + participant, \n             data = drouillet, whichRandom = \"participant\")\nlm.out2.3<-lmBF(indice2.meta.baseline ~ indice_app_impl+ Mill_Hill +\n                indice_app_impl:Mill_Hill+ participant, \n             data = drouillet, whichRandom = \"participant\")"},{"path":"conclusions.html","id":"conclusions","chapter":"14 Conclusions","heading":"14 Conclusions","text":"Vous connaissez à présent les principes sous-jacents l’approche bayésienne et vous connaissez ses avantages. Sans doute, vous connaissez un peu moins ses limites car nous ne les avons pas réellement abordées vu qu’elles sont un peu techniques et que ce n’est pas nécessairement des limites (mais pour une discussion sur ce point, voir Dienes, 2008). Á vous de décider si la manière dont vous voulez réaliser vos statistiques tendent plutôt vers une approche bayésienne ou une approche fréquentiste.Les deux approches ont leurs avantages et leurs inconvénients. Une solution peut aussi être de ne pas choisir (notamment si vous avez peur que des experts vous titillent sur vos analyses ou que votre article soit refusé en raison de l’utilisation de l’approche bayésienne). Á titre personnel, c’est la voie que j’ai choisie et qui est cohérente avec une approche multivers de l’analyse des données (Steegen et al., 2016), qui consiste à analyser les données de différentes manières afin de s’assurer de la robustesse des résultats. Si vos résultats n’ont pas la même interprétation en fonction de la manière dont vous avez analyé les données, alors sans doute qu’il faut s’interroger sur ce que veulent vraiment dire vos données.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
